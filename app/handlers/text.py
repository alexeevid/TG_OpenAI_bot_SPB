# app/handlers/text.py
from __future__ import annotations

import logging
from typing import Any, Dict, List

from telegram import Update
from telegram.ext import Application, ContextTypes, MessageHandler, filters

from ..services.authz_service import AuthzService
from ..services.dialog_service import DialogService
from ..services.gen_service import GenService
from ..services.rag_service import RagService
from ..core.types import RetrievedChunk
from ..core.response_modes import build_system_prompt

log = logging.getLogger(__name__)


def _format_kb_context(results: List[RetrievedChunk]) -> str:
    parts: List[str] = []
    for r in results:
        title = r.get("title") or r.get("source") or "Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚"
        path = r.get("path") or ""
        score = r.get("score")
        text = r.get("text") or ""
        hdr = f"- [{title}] {path}"
        if score is not None:
            try:
                hdr += f" (score={float(score):.3f})"
            except Exception:
                pass
        parts.append(hdr + "\n" + text.strip())
    return "\n\n".join(parts)


def _system_prompt(mode: str) -> str:
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð²Ð½ÐµÑˆÐ½Ð¸Ð¹ ÐºÐ¾Ð½Ñ‚Ñ€Ð°ÐºÑ‚ Ñ„Ð°Ð¹Ð»Ð° (Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð½Ð¸Ð¶Ðµ),
    # Ð½Ð¾ Ð²ÑÑŽ Ð»Ð¾Ð³Ð¸ÐºÑƒ Ñ€ÐµÐ¶Ð¸Ð¼Ð¾Ð² Ð´ÐµÑ€Ð¶Ð¸Ð¼ Ð² Ð¾Ð´Ð½Ð¾Ð¼ Ð¼ÐµÑÑ‚Ðµ: app/core/response_modes.py
    return build_system_prompt(mode)


async def process_text(update: Update, context: ContextTypes.DEFAULT_TYPE, text: str) -> None:
    msg = update.effective_message
    if not msg or not update.effective_user:
        return

    az: AuthzService | None = context.bot_data.get("svc_authz")
    if az and not az.is_allowed(update.effective_user.id):
        await msg.reply_text("â›” Ð”Ð¾ÑÑ‚ÑƒÐ¿ Ð·Ð°Ð¿Ñ€ÐµÑ‰ÐµÐ½.")
        return

    ds: DialogService | None = context.bot_data.get("svc_dialog")
    gs: GenService | None = context.bot_data.get("svc_gen")
    rag: RagService | None = context.bot_data.get("svc_rag")
    cfg = context.bot_data.get("settings")

    if not ds or not gs or not cfg:
        await msg.reply_text("âš ï¸ Ð¡ÐµÑ€Ð²Ð¸ÑÑ‹ Ð½Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ñ‹.")
        return

    d = ds.ensure_active_dialog(update.effective_user.id)
    settings: Dict[str, Any] = ds.get_active_settings(update.effective_user.id) or {}

    mode = str(settings.get("mode") or "professional")
    sys = _system_prompt(mode)

    results: List[RetrievedChunk] = []
    kb_min_score = float(getattr(cfg, "kb_min_score", 0.35))
    kb_top_k = int(getattr(cfg, "max_kb_chunks", 6))
    kb_debug = bool(getattr(cfg, "kb_debug", False))

    try:
        if rag:
            results = rag.retrieve(
                query=text,
                dialog_id=d.id,
                top_k=kb_top_k,
                min_score=kb_min_score,
            )
    except Exception as e:
        log.warning("RAG retrieve failed: %s", e)
        results = []

    kb_ctx = ""
    if results:
        kb_ctx = _format_kb_context(results)

        sys = (
            sys
            + "\n\n"
            + "Ð’ÐÐ–ÐÐž: ÐÐ¸Ð¶Ðµ Ð¿Ñ€Ð¸Ð²ÐµÐ´ÐµÐ½Ñ‹ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ñ‹ Ð¸Ð· Ð±Ð°Ð·Ñ‹ Ð·Ð½Ð°Ð½Ð¸Ð¹. "
              "Ð•ÑÐ»Ð¸ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¼Ð¾Ð¶Ð½Ð¾ Ð¿Ð¾ÐºÑ€Ñ‹Ñ‚ÑŒ ÑÑ‚Ð¸Ð¼Ð¸ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ð°Ð¼Ð¸ â€” Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ð¹ Ð¢ÐžÐ›Ð¬ÐšÐž Ð½Ð° Ð¸Ñ… Ð¾ÑÐ½Ð¾Ð²Ðµ. "
              "ÐÐµ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐ¹ Ð²Ð½ÐµÑˆÐ½Ð¸Ðµ ÑÐ²ÐµÐ´ÐµÐ½Ð¸Ñ. "
              "Ð•ÑÐ»Ð¸ Ð² Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ð°Ñ… Ð½ÐµÑ‚ Ð¾Ñ‚Ð²ÐµÑ‚Ð° â€” Ð¿Ñ€ÑÐ¼Ð¾ ÑÐºÐ°Ð¶Ð¸, Ñ‡Ñ‚Ð¾ Ð² Ð±Ð°Ð·Ðµ Ð·Ð½Ð°Ð½Ð¸Ð¹ Ð½ÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ…, Ð¸ Ð¿Ð¾Ð¿Ñ€Ð¾ÑÐ¸ ÑƒÑ‚Ð¾Ñ‡Ð½ÐµÐ½Ð¸Ðµ.\n"
              "Ð¦Ð¸Ñ‚Ð°Ñ‚Ñ‹ Ð¿Ñ€Ð¸Ð²Ð¾Ð´Ð¸ Ð´Ð¾ÑÐ»Ð¾Ð²Ð½Ð¾ Ð¸ ÑƒÐºÐ°Ð·Ñ‹Ð²Ð°Ð¹ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº (Ð¿ÑƒÑ‚ÑŒ/Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°).\n\n"
              "Ð”Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð· Ð±Ð°Ð·Ñ‹ Ð·Ð½Ð°Ð½Ð¸Ð¹:\n"
            + kb_ctx
        )

    history_rows = ds.history(d.id, limit=24)
    history: List[Dict[str, str]] = [{"role": m.role, "content": m.content} for m in history_rows]

    meta: Dict[str, Any] = {}

    try:
        answer = await gs.chat(
            user_msg=text,
            history=history,
            model=None,
            system_prompt=sys,
            temperature=cfg.openai_temperature,
            dialog_settings=settings,
            out_meta=meta,
        )
    except Exception as e:
        log.exception("GenService.chat failed: %s", e)
        await msg.reply_text("âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸.")
        return

    try:
        used_model = meta.get("used_model")
        if used_model and isinstance(used_model, str):
            current_model = settings.get("text_model")
            if current_model != used_model:
                ds.update_active_settings(update.effective_user.id, {"text_model": used_model})
                settings["text_model"] = used_model
    except Exception as e:
        log.warning("Failed to sync used text model to dialog settings: %s", e)

    try:
        ds.add_message(d.id, role="user", content=text)
    except Exception:
        pass

    try:
        ds.add_message(d.id, role="assistant", content=answer or "")
    except Exception:
        pass

    if kb_debug and results:
        try:
            await msg.reply_text(f"ðŸ”Ž KB chunks: {len(results)} (top_k={kb_top_k}, min_score={kb_min_score})")
        except Exception:
            pass

    await msg.reply_text(answer or "âš ï¸ ÐŸÑƒÑÑ‚Ð¾Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚.")


async def on_text(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    msg = update.effective_message
    if not msg or not update.message:
        return

    text = (update.message.text or "").strip()
    if not text:
        return

    # Ð¿Ð¾Ð´Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð½Ð° Ð²Ð²Ð¾Ð´ Ð¸Ð¼ÐµÐ½Ð¸ Ð¿Ñ€Ð¸ Ð¿ÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½Ð¸Ð¸
    try:
        suppress_id = context.user_data.get("suppress_text_message_id")
        if suppress_id and int(suppress_id) == int(update.message.message_id):
            context.user_data.pop("suppress_text_message_id", None)
            return
    except Exception:
        pass

    await process_text(update, context, text)


def register(app: Application) -> None:
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_text), group=10)
