
# bot/telegram_bot.py
from __future__ import annotations

import asyncio
import hashlib
import logging
import os
import re
import sys
import tempfile
from datetime import datetime
from io import BytesIO
from typing import List
from urllib.parse import urlparse

import tiktoken
from openai import OpenAI
from sqlalchemy import text as sa_text

# PTB 20.x
try:
    from telegram import (
        Update,
        InlineKeyboardButton,
        InlineKeyboardMarkup,
        BufferedInputFile,
        InputFile,
    )
    HAS_BUFFERED = True
except Exception:  # —Å—Ç–∞—Ä—ã–µ —Å–±–æ—Ä–∫–∏ PTB
    from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, InputFile  # type: ignore
    HAS_BUFFERED = False

from telegram.ext import (
    Application,
    ApplicationBuilder,
    CallbackQueryHandler,
    CommandHandler,
    ContextTypes,
    MessageHandler,
    filters,
)

# == –ù–ê–°–¢–†–û–ô–ö–ò / –ë–î ==
from bot.settings import load_settings
from bot.db.session import SessionLocal  # engine –ø–æ–¥—Ç—è–≥–∏–≤–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ Alembic –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏

log = logging.getLogger(__name__)
settings = load_settings()
_OA = OpenAI(api_key=settings.openai_api_key)

# ---------- SINGLETON LOCK (–∏—Å–∫–ª—é—á–∞–µ–º –¥–≤–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö poller-–∞) ----------
import psycopg2

_singleton_conn = None  # –¥–µ—Ä–∂–∏–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∂–∏–≤—ã–º (–¥–µ—Ä–∂–∏—Ç advisory_lock)

def _ensure_single_instance() -> None:
    """–ë–µ—Ä—ë–º pg_advisory_lock –Ω–∞ –ø—Ä–æ—Ü–µ—Å—Å. –ï—Å–ª–∏ –∑–∞–Ω—è—Ç ‚Äî –≤—ã—Ö–æ–¥–∏–º, —á—Ç–æ–±—ã –Ω–µ –ª–æ–≤–∏—Ç—å Conflict –æ—Ç Telegram."""
    global _singleton_conn
    if _singleton_conn is not None:
        return
    dsn = settings.database_url
    if not dsn:
        log.warning("DATABASE_URL –Ω–µ –∑–∞–¥–∞–Ω ‚Äî singleton-lock –ø—Ä–æ–ø—É—â–µ–Ω (—Ä–∏—Å–∫ Conflict).")
        return
    try:
        key_src = f"{dsn}|{settings.telegram_bot_token}"
        lock_key = int(hashlib.sha1(key_src.encode("utf-8")).hexdigest()[:15], 16) % (2**31)
        _singleton_conn = psycopg2.connect(dsn)
        _singleton_conn.autocommit = True
        with _singleton_conn.cursor() as cur:
            cur.execute("SELECT pg_try_advisory_lock(%s)", (lock_key,))
            ok = cur.fetchone()[0]
        if not ok:
            log.error("‚ÄºÔ∏è –£–∂–µ –∑–∞–ø—É—â–µ–Ω –¥—Ä—É–≥–æ–π —ç–∫–∑–µ–º–ø–ª—è—Ä –±–æ—Ç–∞ (advisory-lock –∑–∞–Ω—è—Ç). –ó–∞–≤–µ—Ä—à–∞—é—Å—å.")
            sys.exit(0)
        log.info("‚úÖ –ü–æ–ª—É—á–µ–Ω singleton pg_advisory_lock.")
    except Exception:
        log.exception("–ù–µ —É–¥–∞–ª–æ—Å—å –≤–∑—è—Ç—å singleton-lock ‚Äî –ø—Ä–æ–¥–æ–ª–∂–∞—é –±–µ–∑ –Ω–µ–≥–æ (—Ä–∏—Å–∫ Conflict).")

# ---------- post_init: –æ—á–∏—â–∞–µ–º webhook –ø–µ—Ä–µ–¥ polling ----------
async def _post_init(app: "Application"):
    try:
        await app.bot.delete_webhook(drop_pending_updates=True)
        log.info("‚úÖ Webhook —É–¥–∞–ª—ë–Ω –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –æ—á–∏—â–µ–Ω—ã.")
    except Exception:
        log.exception("–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å webhook")

# ---------- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–û–ï ----------
TELEGRAM_CHUNK = 3500

def _split_for_tg(text: str, limit: int = TELEGRAM_CHUNK) -> List[str]:
    out, s = [], (text or "").strip()
    while len(s) > limit:
        cut = s.rfind("\n\n", 0, limit)
        if cut == -1: cut = s.rfind("\n", 0, limit)
        if cut == -1: cut = s.rfind(" ", 0, limit)
        if cut == -1: cut = limit
        out.append(s[:cut].rstrip())
        s = s[cut:].lstrip()
    if s:
        out.append(s)
    return out

async def _send_long(m, text: str):
    for part in _split_for_tg(text):
        await m.reply_text(part)

def _is_admin(tg_id: int) -> bool:
    try:
        ids = [int(x.strip()) for x in (settings.admin_user_ids or "").split(",") if x.strip()]
        return tg_id in ids
    except Exception:
        return False

def _ensure_user(db, tg_id: int) -> int:
    uid = db.execute(sa_text("SELECT id FROM users WHERE tg_user_id=:tg"), {"tg": tg_id}).scalar()
    if uid:
        return int(uid)
    uid = db.execute(
        sa_text("INSERT INTO users (tg_user_id, is_admin, is_allowed, lang) VALUES (:tg,FALSE,TRUE,'ru') RETURNING id"),
        {"tg": tg_id},
    ).scalar()
    db.commit()
    return int(uid)

def _create_new_dialog_for_tg(db, tg_id: int) -> int:
    uid = _ensure_user(db, tg_id)
    today = datetime.now().date().isoformat()
    cnt = db.execute(sa_text(
        "SELECT count(*) FROM dialogs WHERE user_id=:u AND is_deleted=FALSE"
    ), {"u": uid}).scalar() or 0
    title = f"{today} | –¥–∏–∞–ª–æ–≥ {cnt+1}"
    did = db.execute(sa_text("""
        INSERT INTO dialogs (user_id, title, style, model, is_deleted, created_at)
        VALUES (:u, :t, 'pro', :m, FALSE, now()) RETURNING id
    """), {"u": uid, "t": title, "m": settings.openai_model}).scalar()
    db.commit()
    return int(did)

def _get_active_dialog_id(db, tg_id: int) -> int | None:
    row = db.execute(sa_text("""
        SELECT d.id
        FROM dialogs d
        JOIN users u ON u.id = d.user_id
        WHERE u.tg_user_id=:tg AND d.is_deleted=FALSE
        ORDER BY COALESCE(d.last_message_at, to_timestamp(0)) DESC,
                 d.created_at DESC, d.id DESC
        LIMIT 1
    """), {"tg": tg_id}).first()
    return int(row[0]) if row else None

# --- –≤ telegram_bot.py ---

from sqlalchemy import text as sa_text

_MSG_COLS_CACHE = None
def _detect_messages_layout(db):
    """–ö—ç—à–∏—Ä—É–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–æ–∫ text/content –≤ —Ç–∞–±–ª–∏—Ü–µ messages."""
    global _MSG_COLS_CACHE
    if _MSG_COLS_CACHE is not None:
        return _MSG_COLS_CACHE
    rows = db.execute(sa_text("""
        SELECT column_name
        FROM information_schema.columns
        WHERE table_name = 'messages'
    """)).all()
    cols = {r[0] for r in rows}
    _MSG_COLS_CACHE = {
        "text": "text" in cols,
        "content": "content" in cols,
    }
    return _MSG_COLS_CACHE


def _save_message(db, dialog_id: int, role: str, text: str | None, content: str | None = None):
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –≤—Å—Ç–∞–≤–∫–∞ —Å —É—á—ë—Ç–æ–º —Å—Ö–µ–º—ã.
    –ï—Å–ª–∏ –µ—Å—Ç—å –æ–±–µ –∫–æ–ª–æ–Ω–∫–∏ ‚Äî –ø–∏—à–µ–º –≤ –æ–±–µ.
    –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ text ‚Äî –ø–∏—à–µ–º –≤ text.
    –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ content ‚Äî –ø–∏—à–µ–º –≤ content.
    """
    cols = _detect_messages_layout(db)
    payload = {"d": dialog_id, "r": role}

    # –ù–µ–ª—å–∑—è –≤—Å—Ç–∞–≤–ª—è—Ç—å NULL –≤ text –ø—Ä–∏ —Ç–≤–æ–µ–π —Å—Ö–µ–º–µ, –ø–æ—ç—Ç–æ–º—É –ø–æ–¥—Å—Ç—Ä–∞—Ö—É–µ–º—Å—è
    txt = (text or "")[:65535]  # —á—Ç–æ–±—ã —Ç–æ—á–Ω–æ –Ω–µ —É–ø–µ—Ä–µ—Ç—å—Å—è –≤ –ª–∏–º–∏—Ç—ã
    cnt = content if content is not None else txt

    if cols["text"] and cols["content"]:
        payload.update({"t": txt, "c": cnt})
        db.execute(sa_text(
            "INSERT INTO messages (dialog_id, role, text, content) "
            "VALUES (:d, :r, :t, :c)"
        ), payload)
    elif cols["text"]:
        payload.update({"t": txt})
        db.execute(sa_text(
            "INSERT INTO messages (dialog_id, role, text) "
            "VALUES (:d, :r, :t)"
        ), payload)
    elif cols["content"]:
        payload.update({"c": cnt})
        db.execute(sa_text(
            "INSERT INTO messages (dialog_id, role, content) "
            "VALUES (:d, :r, :c)"
        ), payload)
    else:
        # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π ‚Äî —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ –µ—Å—Ç—å text.
        payload.update({"t": txt})
        db.execute(sa_text(
            "INSERT INTO messages (dialog_id, role, text) "
            "VALUES (:d, :r, :t)"
        ), payload)

    db.commit()


# --- helpers ---
def _is_nonempty(s: str | None) -> bool:
    return bool(s and s.strip())

async def _maybe_await(v):
    # —á—Ç–æ–±—ã –Ω–µ –ø–∞–¥–∞—Ç—å, –µ—Å–ª–∏ _chat_* –≤–¥—Ä—É–≥ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
    import asyncio
    if asyncio.iscoroutine(v):
        return await v
    return v

# --- main ---
async def _process_user_text(update, context, text: str):
    """
    –ï–¥–∏–Ω–∞—è —Ç–æ—á–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ (–≤–∫–ª. –≥–æ–ª–æ—Å -> —Ç–µ–∫—Å—Ç).
    - —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –ë–î
    - –≤—ã–±–∏—Ä–∞–µ—Ç —Ä–µ–∂–∏–º (RAG / –æ–±—ã—á–Ω—ã–π)
    - –¥–æ–∂–∏–¥–∞–µ—Ç—Å—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (await!)
    - –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –¥–ª–∏–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã —á–∞—Å—Ç—è–º–∏
    """
    m = update.effective_message
    user = update.effective_user

    db = session_factory()  # –∫–∞–∫ —É —Ç–µ–±—è —Å–æ–∑–¥–∞—ë—Ç—Å—è —Å–µ—Å—Å–∏—è (Session/ScopedSession) ‚Äî –æ—Å—Ç–∞–≤–∏—Ç—å –ø—Ä–µ–∂–Ω–µ–µ –∏–º—è
    try:
        # 1) –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –∞–∫—Ç–∏–≤–Ω—ã–π –¥–∏–∞–ª–æ–≥ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        did = ensure_active_dialog(db, user.id)           # –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–≤–æ–π —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π helper (–∏–º–µ–Ω–∞ –Ω–µ –º–µ–Ω—è–ª)
        _save_message(db, did, "user", text)              # –∫–∞–∫ —É —Ç–µ–±—è —É–∂–µ –±—ã–ª–æ

        # 2) –î–æ—Å—Ç–∞—ë–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞: –º–æ–¥–µ–ª—å/—Å—Ç–∏–ª—å/–ø—Ä–∏–≤—è–∑–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ kb_top_k
        state = get_dialog_state(db, did)                 # —Ç–≤–æ–π helper: {model, style, kb_docs, kb_top_k}
        kb_docs   = state.get("kb_docs") or []
        kb_top_k  = int(state.get("kb_top_k") or getattr(settings, "KB_TOP_K", 5))

        # 3) –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        if kb_docs:
            # RAG-–≤–µ—Ç–∫–∞: –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∂–¥—ë–º –∫–æ—Ä—É—Ç–∏–Ω—É
            resp = _chat_rag(db=db, dialog_id=did, user_text=text, kb_doc_ids=kb_docs, top_k=kb_top_k)
            answer, used_chunks = await _maybe_await(resp)
            # —Ñ–æ—Ä–º–∏—Ä—É–µ–º ¬´–ò—Å—Ç–æ—á–Ω–∏–∫–∏: ‚Ä¶¬ª
            tail = _format_citations(used_chunks) if used_chunks else ""
            full_answer = f"{answer}{tail}"
        else:
            # –û–±—ã—á–Ω–∞—è –≤–µ—Ç–∫–∞: —Ç–æ–∂–µ –∂–¥—ë–º
            resp = _chat_full(db=db, dialog_id=did, user_text=text)
            answer = await _maybe_await(resp)
            full_answer = answer

        # 4) –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —á–∞—Å—Ç—è–º–∏ (—á—Ç–æ–±—ã –æ—Ç–≤–µ—Ç—ã –Ω–µ ¬´–æ–±—Ä—É–±–∞–ª–∏—Å—å¬ª)
        await _send_long(m, full_answer)

        # 5) –õ–æ–≥–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –≤ –ë–î
        _save_message(db, did, "assistant", full_answer)

    except Exception:
        log.exception("process_user_text failed")
        await m.reply_text("‚ö† –ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
    finally:
        db.close()

# ---------- OpenAI / RAG ----------
def _get_embedding_model() -> str:
    return settings.embedding_model

def _embed_query(text: str) -> List[float]:
    resp = _OA.embeddings.create(model=_get_embedding_model(), input=[text])
    return resp.data[0].embedding

def _kb_embedding_column_kind(db) -> str:
    try:
        t = db.execute(sa_text("SELECT pg_typeof(embedding)::text FROM kb_chunks LIMIT 1")).scalar()
        if t:
            t = str(t).lower()
            if "vector" in t: return "vector"
            if "bytea"  in t: return "bytea"
        t = db.execute(sa_text("""
            SELECT COALESCE(udt_name, data_type)
            FROM information_schema.columns
            WHERE table_name='kb_chunks' AND column_name='embedding'
            LIMIT 1
        """)).scalar()
        t = (t or "").lower()
        if "vector" in t: return "vector"
        if "bytea"  in t: return "bytea"
    except Exception:
        pass
    return "none"

def _vec_literal(vec: List[float]) -> tuple[dict, str]:
    arr = "[" + ",".join(f"{x:.6f}" for x in (vec or [])) + "]"
    return {"q": arr}, "CAST(:q AS vector)"

def _retrieve_chunks(db, dialog_id: int, question: str, k: int = 6) -> List[dict]:
    if _kb_embedding_column_kind(db) != "vector":
        return []
    q = _embed_query(question)
    params, qexpr = _vec_literal(q)
    rows = db.execute(sa_text(f"""
        SELECT c.content, c.meta, d.path
        FROM kb_chunks c
        JOIN kb_documents d    ON d.id=c.document_id AND d.is_active
        JOIN dialog_kb_links l ON l.document_id=d.id
        WHERE l.dialog_id=:did
        ORDER BY c.embedding <=> {qexpr}
        LIMIT :k
    """), dict(params, did=dialog_id, k=k)).mappings().all()
    return [dict(r) for r in rows]

def _build_prompt_with_style(ctx_blocks: List[str], user_q: str, dialog_style: str) -> str:
    style_map = {
        "pro":   "–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —ë–º–∫–æ –∏ –ø–æ –¥–µ–ª—É, —à–∞–≥–∏ –∏ —á–µ–∫-–ª–∏—Å—Ç.",
        "expert":"–≠–∫—Å–ø–µ—Ä—Ç: –ø–æ–¥—Ä–æ–±–Ω–æ, –ø—Ä–∏—á–∏–Ω—ã/—Å–ª–µ–¥—Å—Ç–≤–∏—è, –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã, –≤—ã–≤–æ–¥—ã. –¶–∏—Ç–∞—Ç—ã ‚Äî –≤ –∫–æ–Ω—Ü–µ.",
        "user":  "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏, –ø—Ä–∏–º–µ—Ä—ã –∏ –∞–Ω–∞–ª–æ–≥–∏–∏.",
        "ceo":   "CEO: –±–∏–∑–Ω–µ—Å-—Ü–µ–Ω–Ω–æ—Å—Ç—å, ROI, —Ä–∏—Å–∫–∏, —Å—Ä–æ–∫–∏, –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏ trade-offs.",
    }
    style_line = style_map.get((dialog_style or "pro").lower(), style_map["pro"])
    header = (
        "–¢—ã ‚Äî –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –ë–ó, –Ω–æ –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–π—Å—è —Ü–∏—Ç–∞—Ç–∞–º–∏: "
        "—Å–∏–Ω—Ç–µ–∑–∏—Ä—É–π —Ü–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —Å—Ç–∏–ª–µ. –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–µ—Ç ‚Äî —É—Ç–æ—á–Ω–∏."
    )
    ctx = "\n\n".join([f"[–§—Ä–∞–≥–º–µ–Ω—Ç #{i+1}]\n{t}" for i, t in enumerate(ctx_blocks)])
    return f"{header}\n–°—Ç–∏–ª—å: {style_line}\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{ctx}\n\n–í–æ–ø—Ä–æ—Å: {user_q}"

def _format_citations(chunks: List[dict]) -> str:
    def short(p: str) -> str:
        return (p or "").split("/")[-1].split("?")[0]
    uniq = []
    for r in chunks:
        name = short(r.get("path") or (r.get("meta") or {}).get("path", ""))
        if name and name not in uniq:
            uniq.append(name)
    return ("\n\n–ò—Å—Ç–æ—á–Ω–∏–∫–∏: " + "; ".join(f"[{i+1}] {n}" for i, n in enumerate(uniq[:5]))) if uniq else ""

async def _chat_full(model: str, messages: list, temperature: float = 0.3, max_turns: int = 6) -> str:
    hist = list(messages)
    full = ""
    turns = 0
    while turns < max_turns:
        turns += 1
        resp = _OA.chat.completions.create(
            model=model,
            messages=hist,
            temperature=temperature,
            max_tokens=1024,
        )
        choice = resp.choices[0]
        piece = choice.message.content or ""
        full += piece
        if choice.finish_reason != "length":
            break
        hist.append({"role": "assistant", "content": piece})
        hist.append({"role": "user", "content": "–ü—Ä–æ–¥–æ–ª–∂–∞–π —Å —Ç–æ–≥–æ –º–µ—Å—Ç–∞. –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π—Å—è."})
    return full

# ---------- –ö–û–ú–ê–ù–î–´ ----------
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    await m.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! –Ø –ø–æ–º–æ–≥—É –∏—Å–∫–∞—Ç—å –æ—Ç–≤–µ—Ç—ã –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –∏–∑ –ë–ó –∏ –≤–µ—Å—Ç–∏ –¥–∏–∞–ª–æ–≥–∏ –≤ —Ä–∞–∑–Ω—ã—Ö —Å—Ç–∏–ª—è—Ö.\n"
        "–ü–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥ ‚Äî /help"
    )

async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    await m.reply_text(
        "/start ‚Äî –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ\n"
        "/help ‚Äî —Å–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥\n"
        "/dialogs ‚Äî —Å–ø–∏—Å–æ–∫ –¥–∏–∞–ª–æ–≥–æ–≤ (–æ—Ç–∫—Ä—ã—Ç—å/–ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å/—ç–∫—Å–ø–æ—Ä—Ç/—É–¥–∞–ª–∏—Ç—å)\n"
        "/dialog <id> ‚Äî —Å–¥–µ–ª–∞—Ç—å –¥–∏–∞–ª–æ–≥ –∞–∫—Ç–∏–≤–Ω—ã–º\n"
        "/dialog_new ‚Äî —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥\n"
        "/kb ‚Äî –º–µ–Ω—é –ë–ó (–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ/–æ—Ç–∫–ª—é—á–µ–Ω–∏–µ –¥–æ–∫–æ–≤)\n"
        "/kb_sync ‚Äî —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ë–ó (–∞–¥–º–∏–Ω)\n"
        "/kb_diag ‚Äî –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ë–ó\n"
        "/stats ‚Äî –∫–∞—Ä—Ç–æ—á–∫–∞ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞\n"
        "/web <–∑–∞–ø—Ä–æ—Å> ‚Äî –≤–µ–±-–ø–æ–∏—Å–∫ (–µ—Å–ª–∏ –≤–∫–ª—é—á—ë–Ω)\n"
        "/repair_schema ‚Äî –ø–æ—á–∏–Ω–∫–∞ —Å—Ö–µ–º—ã –ë–î (–∞–¥–º–∏–Ω)\n"
        "/dbcheck ‚Äî –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ç–∞–±–ª–∏—Ü\n"
        "/migrate ‚Äî –ø—Ä–∏–º–µ–Ω–∏—Ç—å Alembic –º–∏–≥—Ä–∞—Ü–∏–∏ (–∞–¥–º–∏–Ω)\n"
        "/pgvector_check ‚Äî –Ω–∞–ª–∏—á–∏–µ/—É—Å—Ç–∞–Ω–æ–≤–∫–∞ pgvector\n"
        "/whoami ‚Äî –º–æ–∏ –ø—Ä–∞–≤–∞\n"
    )

async def whoami(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        tg = update.effective_user.id
        with SessionLocal() as db:
            row = db.execute(sa_text("SELECT is_admin, is_allowed, lang FROM users WHERE tg_user_id=:tg"), {"tg": tg}).first()
        is_admin = bool(row[0]) if row else False
        is_allowed = bool(row[1]) if row else True
        lang = (row[2] or "ru") if row else "ru"
        await (update.message or update.effective_message).reply_text(
            f"whoami: tg={tg}, role={'admin' if is_admin else ('allowed' if is_allowed else 'guest')}, lang={lang}"
        )
    except Exception:
        log.exception("whoami failed")
        await (update.message or update.effective_message).reply_text("‚ö† –û—à–∏–±–∫–∞ whoami")

# ---- –î–∏–∞–ª–æ–≥–∏: —Å–ø–∏—Å–æ–∫/–Ω–æ–≤—ã–π/–ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ/—ç–∫—Å–ø–æ—Ä—Ç/–ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ ----
KB_PAGE_SIZE = 10

# telegram_bot.py
async def dialogs(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        with SessionLocal() as db:
            uid = _ensure_user(db, update.effective_user.id)
            rows = db.execute(sa_text("""
                SELECT d.id, COALESCE(NULLIF(d.title,''), CONCAT('–î–∏–∞–ª–æ–≥ ', d.id)) AS title
                FROM dialogs d
                WHERE d.user_id = :u AND d.is_deleted = FALSE
                ORDER BY COALESCE(d.last_message_at, d.created_at) DESC, d.id DESC
                LIMIT 50
            """), {"u": uid}).all()

        kb_rows = []
        for did, title in rows:
            kb_rows.append([
                InlineKeyboardButton(title, callback_data=f"dlg:open:{did}"),
                InlineKeyboardButton("‚úèÔ∏è",  callback_data=f"dlg:rename:{did}"),
                InlineKeyboardButton("üì§",  callback_data=f"dlg:export:{did}"),
                InlineKeyboardButton("üóëÔ∏è",  callback_data=f"dlg:delete:{did}"),
            ])
        kb_rows.append([InlineKeyboardButton("‚ûï –ù–æ–≤—ã–π –¥–∏–∞–ª–æ–≥", callback_data="dlg:new")])

        await m.reply_text("–ú–æ–∏ –¥–∏–∞–ª–æ–≥–∏:", reply_markup=InlineKeyboardMarkup(kb_rows))
    except Exception:
        log.exception("dialogs failed")
        await m.reply_text("‚ö† –û—à–∏–±–∫–∞ /dialogs")


async def dialog_cb(update: Update, context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    await q.answer()
    try:
        data = q.data or ""
        if data == "dlg:nop":
            return
        if data.startswith("dlg:page:"):
            page = int(data.split(":")[-1])
            context.user_data["dlg_page"] = page
            await q.message.delete()
            return await dialogs(update, context)
        if data == "dlg:new":
            with SessionLocal() as db:
                did = _create_new_dialog_for_tg(db, update.effective_user.id)
            await q.edit_message_text(f"‚úÖ –°–æ–∑–¥–∞–Ω –¥–∏–∞–ª–æ–≥ #{did}")
            return
        if data.startswith("dlg:open:"):
            did = int(data.split(":")[-1])
            context.user_data["active_dialog_id"] = did
            return await q.edit_message_text(f"–û—Ç–∫—Ä—ã—Ç –¥–∏–∞–ª–æ–≥ #{did}")
        if data.startswith("dlg:rename:"):
            did = int(data.split(":")[-1])
            context.user_data["rename_dialog_id"] = did
            return await q.edit_message_text("–í–≤–µ–¥–∏—Ç–µ –Ω–æ–≤–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞:")
        if data.startswith("dlg:export:"):
            did = int(data.split(":")[-1])
            with SessionLocal() as db:
                msgs = db.execute(sa_text("""
                    SELECT role, content, created_at
                    FROM messages
                    WHERE dialog_id=:d ORDER BY created_at
                """), {"d": did}).all()
            lines = ["# –≠–∫—Å–ø–æ—Ä—Ç –¥–∏–∞–ª–æ–≥–∞", ""]
            for role, content, _ in msgs:
                who = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if role == "user" else "–ë–æ—Ç"
                lines.append(f"**{who}:**\n{content}\n")
            data_bytes = "\n".join(lines).encode("utf-8")
            file = BufferedInputFile(data_bytes, filename=f"dialog_{did}.md") if HAS_BUFFERED else InputFile(data_bytes, filename=f"dialog_{did}.md")  # type: ignore
            await q.message.reply_document(document=file, caption="–≠–∫—Å–ø–æ—Ä—Ç –≥–æ—Ç–æ–≤")
            return
        if data.startswith("dlg:delete:"):
            did = int(data.split(":")[-1])
            with SessionLocal() as db:
                db.execute(sa_text("UPDATE dialogs SET is_deleted=TRUE WHERE id=:d"), {"id": did})
                db.commit()
            return await q.edit_message_text(f"–î–∏–∞–ª–æ–≥ #{did} —É–¥–∞–ª—ë–Ω")
    except Exception:
        log.exception("dialog_cb failed")
        try:
            await q.message.reply_text("‚ö† –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ /dialogs.")
        except Exception:
            pass

async def dialog_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    args = context.args or []
    if not args:
        return await dialogs(update, context)
    try:
        did = int(args[0])
    except Exception:
        return await m.reply_text("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /dialog <id>")
    context.user_data["active_dialog_id"] = did
    await m.reply_text(f"‚úÖ –ê–∫—Ç–∏–≤–Ω—ã–π –¥–∏–∞–ª–æ–≥: {did}")
    return await stats(update, context)

async def dialog_new(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        with SessionLocal() as db:
            did = _create_new_dialog_for_tg(db, update.effective_user.id)
        await m.reply_text(f"‚úÖ –°–æ–∑–¥–∞–Ω –¥–∏–∞–ª–æ–≥ #{did}")
    except Exception:
        log.exception("dialog_new failed")
        await m.reply_text("‚ö† –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞")

# ---- KB / SYNC / DIAG ----
def ya_download(path: str) -> bytes:
    import requests
    YA_API = "https://cloud-api.yandex.net/v1/disk"
    headers = {"Authorization": f"OAuth {settings.yandex_disk_token}"}
    r = requests.get(f"{YA_API}/resources/download", headers=headers, params={"path": path}, timeout=60)
    r.raise_for_status()
    href = (r.json() or {}).get("href")
    if not href:
        raise RuntimeError("download href not returned by Yandex Disk")
    f = requests.get(href, timeout=300)
    f.raise_for_status()
    return f.content

def _ya_list_files(root_path: str):
    import requests
    YA_API = "https://cloud-api.yandex.net/v1/disk"
    headers = {"Authorization": f"OAuth {settings.yandex_disk_token}"}
    out = []
    limit, offset = 200, 0
    while True:
        r = requests.get(
            f"{YA_API}/resources",
            headers=headers,
            params={
                "path": root_path,
                "limit": limit,
                "offset": offset,
                "fields": "_embedded.items.name,_embedded.items.path,_embedded.items.type,_embedded.items.mime_type,_embedded.items.size,_embedded.items.md5",
            },
            timeout=30,
        )
        r.raise_for_status()
        items = (r.json().get("_embedded") or {}).get("items") or []
        for it in items:
            if it.get("type") == "file":
                out.append(it)
        if len(items) < limit:
            break
        offset += limit
    return out

def _pdf_extract_text(pdf_bytes: bytes) -> tuple[str, int, bool]:
    import fitz  # PyMuPDF
    with fitz.open(stream=pdf_bytes, filetype="pdf") as doc:
        is_prot = bool(doc.is_encrypted)
        if is_prot:
            try:
                if doc.authenticate(""):
                    is_prot = False
            except Exception:
                pass
        if is_prot:
            return ("", 0, True)
        pages = doc.page_count
        out = []
        for i in range(pages):
            try:
                out.append(doc.load_page(i).get_text("text") or "")
            except Exception:
                out.append("")
        txt = "\n".join(out)
    if not txt.strip():
        try:
            from pdfminer.high_level import extract_text
            txt = extract_text(BytesIO(pdf_bytes)) or ""
        except Exception:
            pass
    return (txt, pages, False)

def _chunk_text(text: str, max_tokens: int = 2000, overlap: int = 0) -> List[str]:
    enc = tiktoken.get_encoding("cl100k_base")
    toks = enc.encode(text or "")
    out = []
    i = 0
    while i < len(toks):
        part = enc.decode(toks[i:i+max_tokens]).strip()
        if part:
            out.append(part)
        i = i + max_tokens if overlap <= 0 else i + max_tokens - overlap
    return out

async def kb_sync(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    if not _is_admin(update.effective_user.id):
        return await m.reply_text("‚õî –î–æ—Å—Ç—É–ø —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∞–º.")
    await m.reply_text("üîÑ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–ø—É—â–µ–Ω–∞...")
    try:
        import inspect
        from bot.knowledge_base import indexer
        entry = getattr(settings, "kb_sync_entrypoint", None) or os.getenv("KB_SYNC_ENTRYPOINT", None)
        fn = getattr(indexer, entry, None) if entry else None
        if not fn:
            for cand in ("sync_kb","sync_all","sync_from_yandex","sync","run_sync","full_sync","reindex","index_all","ingest_all","ingest","main"):
                if hasattr(indexer, cand) and callable(getattr(indexer, cand)):
                    fn = getattr(indexer, cand); break
        if not fn:
            raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω entrypoint –≤ indexer.py. –£–∫–∞–∂–∏—Ç–µ KB_SYNC_ENTRYPOINT –∏–ª–∏ —Ä–µ–∞–ª–∏–∑—É–π—Ç–µ sync_kb(session).")

        sig = inspect.signature(fn)
        kwargs, to_close = {}, None
        for p in sig.parameters.values():
            nm = p.name.lower()
            if nm in ("session","db","dbsession","conn","connection"):
                sess = SessionLocal(); kwargs[p.name] = sess; to_close = sess
            elif nm in ("sessionlocal","session_factory","factory","engine"):
                kwargs[p.name] = SessionLocal
            elif nm in ("settings","cfg","config","conf"):
                kwargs[p.name] = settings

        def _call():
            try: return fn(**kwargs)
            finally:
                if to_close is not None:
                    try: to_close.close()
                    except Exception: pass

        res = await asyncio.to_thread(_call)
        if isinstance(res, dict):
            upd = res.get("updated"); skp = res.get("skipped"); tot = res.get("total")
            msg = "‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞."
            if any(v is not None for v in (upd, skp, tot)):
                msg += f" –û–±–Ω–æ–≤–ª–µ–Ω–æ: {upd or 0}, –ø—Ä–æ–ø—É—â–µ–Ω–æ: {skp or 0}, –≤—Å–µ–≥–æ: {tot or 0}."
            return await m.reply_text(msg)
        elif isinstance(res, (tuple, list)) and len(res) >= 2:
            return await m.reply_text(f"‚úÖ –ì–æ—Ç–æ–≤–æ: –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ {res[0]}, —á–∞–Ω–∫–æ–≤ {res[1]}")
        else:
            return await m.reply_text("‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
    except Exception as e:
        log.exception("kb_sync failed")
        return await m.reply_text(f"‚ö† –û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}")

async def kb_diag(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        with SessionLocal() as db:
            docs = db.execute(sa_text("SELECT count(*) FROM kb_documents WHERE is_active")).scalar() or 0
            chunks = db.execute(sa_text("SELECT count(*) FROM kb_chunks")).scalar() or 0
            links = db.execute(sa_text("SELECT count(*) FROM dialog_kb_links")).scalar() or 0
        await m.reply_text(f"–ë–ó: –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∞–∫—Ç–∏–≤–Ω—ã—Ö ‚Äî {docs}, —á–∞–Ω–∫–æ–≤ ‚Äî {chunks}, –ø—Ä–∏–≤—è–∑–æ–∫ –∫ –¥–∏–∞–ª–æ–≥–∞–º ‚Äî {links}")
    except Exception:
        log.exception("kb_diag failed")
        await m.reply_text("‚ö† –û—à–∏–±–∫–∞ kb_diag")

async def kb_cmd(update, context):
    m = update.effective_message
    db = session_factory()
    try:
        # —Å—á–∏—Ç–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Ü–∏—Ñ—Ä—ã
        doc_cnt   = db.execute(sa_text("SELECT count(*) FROM kb_documents WHERE is_active = true")).scalar_one()
        chunk_cnt = db.execute(sa_text("SELECT count(*) FROM kb_chunks")).scalar_one()
        link_cnt  = db.execute(sa_text("SELECT count(*) FROM dialog_kb_links")).scalar_one()

        # –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º ¬´—à–∞–ø–∫—É¬ª
        await m.reply_text(f"–ë–ó: –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∞–∫—Ç–∏–≤–Ω—ã—Ö ‚Äî {doc_cnt}, —á–∞–Ω–∫–æ–≤ ‚Äî {chunk_cnt}, –ø—Ä–∏–≤—è–∑–æ–∫ –∫ –¥–∏–∞–ª–æ–≥–∞–º ‚Äî {link_cnt}")

        # –∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞
        kb = [
            [InlineKeyboardButton("üóò –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è", callback_data="kb:sync")],
            [InlineKeyboardButton("üìä –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞",   callback_data="kb:diag")],
        ]
        await m.reply_text("–ú–µ–Ω—é –ë–ó:", reply_markup=InlineKeyboardMarkup(kb))
    except Exception:
        log.exception("kb_cmd failed")
        await m.reply_text("‚ö† –û—à–∏–±–∫–∞ /kb")
    finally:
        db.close()

async def kb_cb(update: Update, context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    await q.answer()
    data = q.data or ""
    if data == "kb:sync":
        await q.edit_message_text("üîÑ –°—Ç–∞—Ä—Ç—É—é —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é –ë–ó‚Ä¶")
        return await kb_sync(update, context)
    if data == "kb:diag":
        await kb_diag(update, context)
        try:
            await q.delete_message()
        except Exception:
            pass
        return

# ---- WEB ----
async def web_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    parts = (m.text or "").split(maxsplit=1)
    if len(parts) < 2:
        return await m.reply_text("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /web <–∑–∞–ø—Ä–æ—Å>")
    query = parts[1].strip()

    # –ï—Å–ª–∏ –µ—Å—Ç—å –∫–ª—é—á–∏ –∏ –º–æ–¥—É–ª—å web_search ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫
    try:
        from bot.web_search import web_search_digest, sources_footer
        answer, sources = await web_search_digest(query, max_results=6, openai_api_key=settings.openai_api_key)
        footer = ("\n\n–ò—Å—Ç–æ—á–Ω–∏–∫–∏:\n" + sources_footer(sources)) if sources else ""
        await _send_long(m, (answer or "–ì–æ—Ç–æ–≤–æ.") + footer)
        if sources:
            buttons = [[InlineKeyboardButton(f"[{i+1}] {urlparse(s['url']).netloc}", url=s['url'])] for i, s in enumerate(sources)]
            await m.reply_text("–û—Ç–∫—Ä—ã—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏:", reply_markup=InlineKeyboardMarkup(buttons), disable_web_page_preview=True)
    except Exception as e:
        await m.reply_text(
            "üîé –í–µ–±-–ø–æ–∏—Å–∫ –ø–æ–∫–∞ –æ—Ç–∫–ª—é—á—ë–Ω –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–Ω–µ—Ç –∫–ª—é—á–µ–π Tavily/SerpAPI/Bing).\n"
            "–Ø –º–æ–≥—É –æ—Ç–≤–µ—Ç–∏—Ç—å —Å–≤–æ–∏–º–∏ –∑–Ω–∞–Ω–∏—è–º–∏ –∏–ª–∏ –Ω–∞–π—Ç–∏ –≤ –ë–ó —á–µ—Ä–µ–∑ /kb.\n"
            f"–î–µ—Ç–∞–ª–∏: {e}"
        )

# ---- –°–¢–ê–¢–ò–°–¢–ò–ö–ê ----
async def stats(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        with SessionLocal() as db:
            did = context.user_data.get("active_dialog_id") or _get_active_dialog_id(db, update.effective_user.id)
            if not did:
                return await m.reply_text("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞. –°–æ–∑–¥–∞–π—Ç–µ —á–µ—Ä–µ–∑ /dialog_new –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ /dialogs.")

            row = db.execute(sa_text(
                "SELECT id, title, model, style, created_at, last_message_at FROM dialogs WHERE id=:d"
            ), {"d": did}).first()

            msgs = db.execute(sa_text("SELECT count(*) FROM messages WHERE dialog_id=:d"), {"d": did}).scalar() or 0
            docs = db.execute(sa_text("""
                SELECT d.path
                FROM kb_documents d
                JOIN dialog_kb_links l ON l.document_id=d.id
                WHERE l.dialog_id=:d ORDER BY d.path
            """), {"d": did}).fetchall()
            total_dialogs = db.execute(sa_text("""
                SELECT count(*) FROM dialogs WHERE user_id=(
                    SELECT id FROM users WHERE tg_user_id=:tg LIMIT 1
                ) AND is_deleted=FALSE
            """), {"tg": update.effective_user.id}).scalar() or 0

        title = row[1] if row else "-"
        model = row[2] if row else settings.openai_model
        style = row[3] if row else "pro"
        created = row[4] if row else "-"
        changed = row[5] if row else "-"
        doc_list = "\n".join(f"‚Ä¢ {r[0]}" for r in docs) or "‚Äî"

        text = (
            f"–î–∏–∞–ª–æ–≥: {did} ‚Äî {title}\n"
            f"–ú–æ–¥–µ–ª—å: {model} | –°—Ç–∏–ª—å: {style}\n"
            f"–°–æ–∑–¥–∞–Ω: {created or '-'} | –ò–∑–º–µ–Ω—ë–Ω: {changed or '-'}\n"
            f"–ü–æ–¥–∫–ª—é—á—ë–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã ({len(docs)}):\n{doc_list}\n\n"
            f"–í—Å–µ–≥–æ —Ç–≤–æ–∏—Ö –¥–∏–∞–ª–æ–≥–æ–≤: {int(total_dialogs)} | –°–æ–æ–±—â–µ–Ω–∏–π –≤ —ç—Ç–æ–º –¥–∏–∞–ª–æ–≥–µ: {int(msgs)}"
        )
        return await m.reply_text(text)
    except Exception:
        log.exception("/stats failed")
        return await m.reply_text("‚ö† –û—à–∏–±–∫–∞ /stats")

# ---- –¢–ï–ö–°–¢ / –ì–û–õ–û–° ----
async def on_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    text = (m.text or "").strip()
    if not text:
        return
    try:
        with SessionLocal() as db:
            tg = update.effective_user.id
            _ensure_user(db, tg)
            did = context.user_data.get("active_dialog_id") or _get_active_dialog_id(db, tg) or _create_new_dialog_for_tg(db, tg)

            row = db.execute(sa_text("SELECT model, style FROM dialogs WHERE id=:d"), {"d": did}).first()
            model = (row[0] if row and row[0] else settings.openai_model)
            style = (row[1] if row and row[1] else "pro")

            _save_message(db, did, "user", text)

            top_k = int(settings.kb_top_k)
            rows = _retrieve_chunks(db, did, text, k=top_k)

        ctx_blocks = [r["content"] for r in rows]
        prompt = _build_prompt_with_style(ctx_blocks, text, style)
        messages = [{"role":"system","content":"RAG assistant"}, {"role":"user","content":prompt}]

        answer = await _chat_full(model, messages, temperature=0.3, max_turns=6)
        cites = _format_citations(rows)
        final = answer + (cites if cites else "")

        await _send_long(m, final)

        with SessionLocal() as db:
            _save_message(db, did, "assistant", final)

    except Exception:
        log.exception("on_text failed")
        await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")

async def on_voice(update, context):
    m = update.effective_message
    v = m.voice or m.audio
    if not v:
        return await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")

    try:
        # 1) –°–∫–∞—á–∏–≤–∞–µ–º –≤ .ogg (—É —Ç–µ–ª–µ–≥–∏ –≥–æ–ª–æ—Å –∫–∞–∫ –ø—Ä–∞–≤–∏–ª–æ OGG/OPUS)
        ogg = await v.get_file()
        tmp_path = Path(tempfile.mkstemp(suffix=".ogg")[1])
        await ogg.download_to_drive(str(tmp_path))

        # 2) –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º
        with open(tmp_path, "rb") as fh:
            # –æ—Å—Ç–∞–≤–ª—è—é —Ç–≤–æ–π –∫–ª–∏–µ–Ω—Ç –∏ –º–æ–¥–µ–ª—å, —Ç–æ–ª—å–∫–æ –±–µ–∑ —ç–∫–∑–æ—Ç–∏–∫–∏:
            tr = openai.audio.transcriptions.create(
                model = getattr(settings, "ASR_MODEL", "gpt-4o-transcribe"),
                file  = fh,
                # –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å language="ru" –µ—Å–ª–∏ —Ö–æ—á–µ—à—å –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ
            )
        text = (tr.text or "").strip()
        if not _is_nonempty(text):
            return await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –°–∫–∞–∂–∏—Ç–µ –µ—â—ë —Ä–∞–∑, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞.")

        # 3) –û—Ç–¥–∞—ë–º –≤ –æ–±—â–∏–π –ø–∞–π–ø–ª–∞–π–Ω (–ù–ï –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–µ–º m.text!)
        return await _process_user_text(update, context, text)

    except openai.BadRequestError as e:
        # —Ç–∏–ø–∏—á–Ω—ã–µ 400 ‚Äî –Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç/–±–∏—Ç—ã–π —Ñ–∞–π–ª
        log.error("ASR BadRequest: %s", e, exc_info=True)
        return await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ (—Ñ–æ—Ä–º–∞—Ç/–∫–∞—á–µ—Å—Ç–≤–æ). –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
    except Exception:
        log.exception("on_voice failed")
        return await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
    finally:
        try:
            if tmp_path and Path(tmp_path).exists():
                Path(tmp_path).unlink(missing_ok=True)
        except Exception:
            pass

# ---- –°–ï–†–í–ò–°–ù–´–ï ----
async def dbcheck(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        with SessionLocal() as db:
            rows = db.execute(sa_text("""
                select 'users' as t, to_regclass('public.users') is not null
                union all select 'dialogs',          to_regclass('public.dialogs') is not null
                union all select 'messages',         to_regclass('public.messages') is not null
                union all select 'kb_documents',     to_regclass('public.kb_documents') is not null
                union all select 'kb_chunks',        to_regclass('public.kb_chunks') is not null
                union all select 'dialog_kb_links',  to_regclass('public.dialog_kb_links') is not null
                union all select 'pdf_passwords',    to_regclass('public.pdf_passwords') is not null
                union all select 'audit_log',        to_regclass('public.audit_log') is not null
            """)).all()
        lines = ["–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∞–±–ª–∏—Ü:"]
        for t, ok in rows:
            lines.append(f"{'‚úÖ' if ok else '‚ùå'} {t}")
        await (update.effective_message or update.message).reply_text("\n".join(lines))
    except Exception:
        log.exception("dbcheck failed")
        await (update.effective_message or update.message).reply_text("‚ö† –û—à–∏–±–∫–∞ dbcheck")

async def migrate(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        if not _is_admin(update.effective_user.id):
            return await (update.effective_message or update.message).reply_text("–¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞.")
        await (update.effective_message or update.message).reply_text("üîß –ó–∞–ø—É—Å–∫–∞—é –º–∏–≥—Ä–∞—Ü–∏–∏...")
        from alembic.config import Config
        from alembic import command
        os.environ["DATABASE_URL"] = settings.database_url
        cfg = Config("alembic.ini")
        command.upgrade(cfg, "head")
        await (update.effective_message or update.message).reply_text("‚úÖ –ú–∏–≥—Ä–∞—Ü–∏–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã.")
    except Exception:
        log.exception("migrate failed")
        await (update.effective_message or update.message).reply_text("‚ö† –û—à–∏–±–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏.")

# --- /repair_schema (–∞–¥–º–∏–Ω) ---
async def repair_schema(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    if not _is_admin(update.effective_user.id):
        return await m.reply_text("‚õî –¢–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∞–º.")
    await m.reply_text("üß± –†–µ–º–æ–Ω—Ç —Å—Ö–µ–º—ã –Ω–∞—á–∞—Ç...")

    try:
        with SessionLocal() as db:
            # users
            db.execute(sa_text("""
            CREATE TABLE IF NOT EXISTS users(
                id BIGSERIAL PRIMARY KEY,
                tg_id BIGINT UNIQUE NOT NULL,
                role TEXT DEFAULT 'allowed',
                lang TEXT DEFAULT 'ru',
                created_at TIMESTAMP WITH TIME ZONE DEFAULT now()
            )"""))

            # dialogs
            db.execute(sa_text("""
            CREATE TABLE IF NOT EXISTS dialogs(
                id BIGSERIAL PRIMARY KEY,
                user_id BIGINT NOT NULL REFERENCES users(id) ON DELETE CASCADE,
                title TEXT,
                model TEXT,
                style TEXT,
                created_at TIMESTAMP WITH TIME ZONE DEFAULT now(),
                updated_at TIMESTAMP WITH TIME ZONE DEFAULT now(),
                last_message_at TIMESTAMP WITH TIME ZONE,
                is_deleted BOOLEAN DEFAULT FALSE
            )"""))

            # messages (–ø–æ–¥–¥–µ—Ä–∂–∫–∞ –∏ content, –∏ text)
            db.execute(sa_text("""
            CREATE TABLE IF NOT EXISTS messages(
                id BIGSERIAL PRIMARY KEY,
                dialog_id BIGINT NOT NULL REFERENCES dialogs(id) ON DELETE CASCADE,
                role TEXT NOT NULL,
                content TEXT,
                text TEXT,
                created_at TIMESTAMP WITH TIME ZONE DEFAULT now()
            )"""))

            # kb_documents
            db.execute(sa_text("""
            CREATE TABLE IF NOT EXISTS kb_documents(
                id BIGSERIAL PRIMARY KEY,
                path TEXT UNIQUE NOT NULL,
                etag TEXT,
                mime TEXT,
                pages INT,
                bytes BIGINT,
                updated_at TIMESTAMP WITH TIME ZONE DEFAULT now(),
                is_active BOOLEAN DEFAULT TRUE
            )"""))

            # pgvector (–µ—Å–ª–∏ –Ω–µ—Ç ‚Äî –∫–æ–º–∞–Ω–¥–∞ /pgvector_check –ø–æ—Å—Ç–∞–≤–∏—Ç)
            # kb_chunks —Å vector(3072) –ø–æ–¥ text-embedding-3-large
            db.execute(sa_text("""
            DO $$
            BEGIN
              IF NOT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'vector') THEN
                RAISE NOTICE 'pgvector –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî –∫–æ–ª–æ–Ω–∫–∞ embedding –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞ –∫–∞–∫ double precision[]';
                IF NOT EXISTS (
                  SELECT 1 FROM information_schema.tables
                  WHERE table_name='kb_chunks'
                ) THEN
                  CREATE TABLE kb_chunks(
                    id BIGSERIAL PRIMARY KEY,
                    document_id BIGINT NOT NULL REFERENCES kb_documents(id) ON DELETE CASCADE,
                    chunk_index INT NOT NULL,
                    content TEXT NOT NULL,
                    embedding DOUBLE PRECISION[]
                  );
                  CREATE INDEX idx_chunks_doc_ix ON kb_chunks(document_id, chunk_index);
                END IF;
              ELSE
                CREATE TABLE IF NOT EXISTS kb_chunks(
                    id BIGSERIAL PRIMARY KEY,
                    document_id BIGINT NOT NULL REFERENCES kb_documents(id) ON DELETE CASCADE,
                    chunk_index INT NOT NULL,
                    content TEXT NOT NULL,
                    embedding VECTOR(3072)
                );
                CREATE INDEX IF NOT EXISTS idx_chunks_doc_ix ON kb_chunks(document_id, chunk_index);
                CREATE INDEX IF NOT EXISTS kb_chunks_vec_idx ON kb_chunks USING ivfflat (embedding vector_cosine_ops) WITH (lists=100);
              END IF;
            END$$;"""))

            # —Å–≤—è–∑–∫–∞ –¥–∏–∞–ª–æ–≥–æ–≤ –∏ –¥–æ–∫–æ–≤
            db.execute(sa_text("""
            CREATE TABLE IF NOT EXISTS dialog_kb_links(
                dialog_id BIGINT NOT NULL REFERENCES dialogs(id) ON DELETE CASCADE,
                document_id BIGINT NOT NULL REFERENCES kb_documents(id) ON DELETE CASCADE,
                PRIMARY KEY(dialog_id, document_id)
            )"""))

            # –ø–∞—Ä–æ–ª–∏ pdf
            db.execute(sa_text("""
            CREATE TABLE IF NOT EXISTS pdf_passwords(
                user_id BIGINT NOT NULL REFERENCES users(id) ON DELETE CASCADE,
                doc_path TEXT NOT NULL,
                password TEXT NOT NULL,
                created_at TIMESTAMP WITH TIME ZONE DEFAULT now(),
                PRIMARY KEY(user_id, doc_path)
            )"""))

            # –∞—É–¥–∏—Ç
            db.execute(sa_text("""
            CREATE TABLE IF NOT EXISTS audit_log(
                id BIGSERIAL PRIMARY KEY,
                at TIMESTAMP WITH TIME ZONE DEFAULT now(),
                user_id BIGINT,
                action TEXT,
                payload JSONB
            )"""))

            db.commit()

        await m.reply_text("‚úÖ –†–µ–º–æ–Ω—Ç –∑–∞–≤–µ—Ä—à—ë–Ω. –°–æ–∑–¥–∞–Ω–æ/–ø—Ä–æ–≤–µ—Ä–µ–Ω–æ: users, dialogs, messages, kb_documents, kb_chunks, dialog_kb_links, pdf_passwords, audit_log")
    except Exception:
        log.exception("repair_schema failed")
        await m.reply_text("‚ö† –û—à–∏–±–∫–∞ /repair_schema")

async def pgvector_check(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        with SessionLocal() as db:
            avail = db.execute(sa_text("SELECT EXISTS(SELECT 1 FROM pg_available_extensions WHERE name='vector')")).scalar()
            installed = db.execute(sa_text("SELECT EXISTS(SELECT 1 FROM pg_extension WHERE extname='vector')")).scalar()
        await (update.effective_message or update.message).reply_text(
            f"pgvector –¥–æ—Å—Ç—É–ø–Ω–æ: {'‚úÖ' if avail else '‚ùå'}\n"
            f"pgvector —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ: {'‚úÖ' if installed else '‚ùå'}"
        )
    except Exception:
        log.exception("pgvector_check failed")
        await (update.effective_message or update.message).reply_text("‚ö† –û—à–∏–±–∫–∞ pgvector_check")
# --- singleton lock –Ω–∞ –ë–î (–æ–¥–Ω–∞ –∫–æ–ø–∏—è –±–æ—Ç–∞) ---
from sqlalchemy import text as sa_text

def _singleton_lock_or_exit():
    try:
        with SessionLocal() as db:
            ok = db.execute(sa_text("SELECT pg_try_advisory_lock(:k)"), {"k": 937451}).scalar()
            if not ok:
                log.error("‚ùå –ù–∞–π–¥–µ–Ω –¥—Ä—É–≥–æ–π —ç–∫–∑–µ–º–ø–ª—è—Ä –±–æ—Ç–∞ (pg_advisory_lock). –ó–∞–≤–µ—Ä—à–∞—é –ø—Ä–æ—Ü–µ—Å—Å.")
                import sys
                sys.exit(0)
    except Exception:
        log.exception("singleton lock failed (–ø—Ä–æ–¥–æ–ª–∂–∞—é –±–µ–∑ –≤—ã—Ö–æ–¥–∞)")

async def _post_init(app: "Application"):
    # –°–±—Ä–∞—Å—ã–≤–∞–µ–º webhook –∏ —Ö–≤–æ—Å—Ç—ã –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –ø–µ—Ä–µ–¥ polling
    try:
        await app.bot.delete_webhook(drop_pending_updates=True)
        log.info("‚úÖ Webhook —É–¥–∞–ª—ë–Ω, pending updates —Å–±—Ä–æ—à–µ–Ω—ã.")
    except Exception:
        log.exception("drop_webhook failed")

# ---------- –°–ë–û–†–ö–ê –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø ----------
def build_app() -> Application:
    _singleton_lock_or_exit()
    app = Application.builder().token(settings.telegram_bot_token).post_init(_post_init).build()
    _ensure_single_instance()
    app = ApplicationBuilder().token(settings.telegram_bot_token).post_init(_post_init).build()

    # –ö–æ–º–∞–Ω–¥—ã
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_cmd))
    app.add_handler(CommandHandler("whoami", whoami))

    app.add_handler(CommandHandler("dialogs", dialogs))
    app.add_handler(CallbackQueryHandler(dialog_cb, pattern=r"^dlg:"))

    app.add_handler(CommandHandler("dialog", dialog_cmd))
    app.add_handler(CommandHandler("dialog_new", dialog_new))

    app.add_handler(CommandHandler("kb", kb_cmd))
    app.add_handler(CallbackQueryHandler(kb_cb, pattern=r"^kb:"))
    app.add_handler(CommandHandler("kb_sync", kb_sync))
    app.add_handler(CommandHandler("kb_diag", kb_diag))

    app.add_handler(CommandHandler("stats", stats))
    app.add_handler(CommandHandler("web", web_cmd))

    app.add_handler(CommandHandler("repair_schema", repair_schema))
    app.add_handler(CommandHandler("dbcheck", dbcheck))
    app.add_handler(CommandHandler("migrate", migrate))
    app.add_handler(CommandHandler("pgvector_check", pgvector_check))

    # –°–æ–æ–±—â–µ–Ω–∏—è
    app.add_handler(MessageHandler(filters.VOICE | filters.AUDIO, on_voice))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_text))

    return app
