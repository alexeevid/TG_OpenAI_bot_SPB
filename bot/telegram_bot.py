from __future__ import annotations
import tiktoken
from openai import OpenAI

import logging
from datetime import datetime
from io import BytesIO
# ==== KB RAG helpers (safe define if missing) ====
import json

# PTB 20.4 –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç BufferedInputFile. –î–µ–ª–∞–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π –∏–º–ø–æ—Ä—Ç.
try:
    from telegram import (
        Update, InlineKeyboardButton, InlineKeyboardMarkup, BufferedInputFile, InputFile
    )
    HAS_BUFFERED = True
except Exception:  # pragma: no cover
    from telegram import (  # type: ignore
        Update, InlineKeyboardButton, InlineKeyboardMarkup, InputFile
    )
    HAS_BUFFERED = False

from telegram.ext import (
    ApplicationBuilder, Application, CommandHandler, ContextTypes,
    MessageHandler, CallbackQueryHandler, filters
)
from sqlalchemy import text as sa_text

from bot.settings import load_settings
from bot.db.session import SessionLocal  # engine –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤–Ω—É—Ç—Ä–∏ apply_migrations_if_needed

log = logging.getLogger(__name__)
settings = load_settings()

# --- –ê–≤—Ç–æ-–º–∏–≥—Ä–∞—Ü–∏—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ (–µ—Å–ª–∏ –Ω–µ—Ç —Ç–∞–±–ª–∏—Ü) ---
def apply_migrations_if_needed(force: bool = False) -> None:
    """
    –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç (–∏–ª–∏ force=True), –∑–∞–ø—É—Å–∫–∞–µ–º alembic upgrade head.
    –†–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ –∫–æ–Ω—Å–æ–ª–∏ Railway.
    """
    try:
        from sqlalchemy import text as sa_text
        from bot.db.session import engine
        need = True
        if not force:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤–æ–π —Ç–∞–±–ª–∏—Ü—ã
            with engine.connect() as conn:
                exists = conn.execute(sa_text("SELECT to_regclass('public.users')")).scalar()
                need = not bool(exists)

        if need:
            log.info("Auto-migrate: applying Alembic migrations...")
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º Alembic –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ
            import os
            import time
            from alembic.config import Config
            from alembic import command

            cfg = Config("alembic.ini")  # —Ñ–∞–π–ª –ª–µ–∂–∏—Ç –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞
            os.environ["DATABASE_URL"] = settings.database_url  # —á—Ç–æ–±—ã Alembic –∑–Ω–∞–ª, –∫—É–¥–∞ –ø–æ–¥–∫–ª—é—á–∞—Ç—å—Å—è
            command.upgrade(cfg, "head")
            log.info("Auto-migrate: done")
        else:
            log.info("Auto-migrate: tables already present")
    except Exception:
        log.exception("Auto-migrate failed")

# ---------- helpers ----------
def _exec_scalar(db, sql: str, **params):
    return db.execute(sa_text(sql), params).scalar()

def _exec_all(db, sql: str, **params):
    return db.execute(sa_text(sql), params).all()

def _ensure_user(db, tg_id: int) -> int:
    uid = _exec_scalar(db, "SELECT id FROM users WHERE tg_user_id=:tg", tg=tg_id)
    if uid:
        return uid
    uid = _exec_scalar(
        db,
        """
        INSERT INTO users (tg_user_id, is_admin, is_allowed, lang)
        VALUES (:tg, FALSE, TRUE, 'ru')
        RETURNING id
        """, tg=tg_id,
    )
    db.commit()
    return uid

def _ensure_dialog(db, user_id: int) -> int:
    did = _exec_scalar(
        db,
        """
        SELECT id FROM dialogs
        WHERE user_id=:u AND is_deleted=FALSE
        ORDER BY created_at DESC
        LIMIT 1
        """, u=user_id,
    )
    if did:
        return did
    did = _exec_scalar(
        db,
        """
        INSERT INTO dialogs (user_id, title, style, model, is_deleted)
        VALUES (:u, :t, 'expert', :m, FALSE)
        RETURNING id
        """, u=user_id, t=datetime.now().strftime("%Y-%m-%d | –¥–∏–∞–ª–æ–≥"), m=settings.openai_model,
    )
    db.commit()
    return did

def _is_admin(tg_id: int) -> bool:
    try:
        ids = [int(x.strip()) for x in (settings.admin_user_ids or "").split(",") if x.strip()]
        return tg_id in ids
    except Exception:
        return False

# ---------- commands ----------
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        chat_id = update.effective_chat.id if update.effective_chat else None
        user = update.effective_user
        if user:
            with SessionLocal() as db:
                uid = _ensure_user(db, user.id)
                _ensure_dialog(db, uid)
        text = (
            "–ü—Ä–∏–≤–µ—Ç! –Ø –ø–æ–º–æ–≥—É –∏—Å–∫–∞—Ç—å –æ—Ç–≤–µ—Ç—ã –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –∏–∑ –ë–ó.\n"
            "–û—Ç–∫—Ä–æ–π—Ç–µ /kb (–∫–Ω–æ–ø–∫–∏ –≤–Ω—É—Ç—Ä–∏) –∏–ª–∏ –∑–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å.\n\n"
            "/help ‚Äî —Å–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥."
        )
        if update.message:
            await update.message.reply_text(text)
        elif chat_id is not None:
            await context.bot.send_message(chat_id, text)
    except Exception:
        log.exception("start failed")

async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "/start /help /reset /stats\n"
        "/dialogs, /dialog <id>\n"
        "/kb, /kb_diag\n"
        "/model, /mode\n"
        "/img <prompt>\n"
        "/web <query>\n"
        "/whoami, /grant <id>, /revoke <id>"
    )

async def on_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç voice/audio, —Ä–∞—Å–ø–æ–∑–Ω–∞—ë—Ç —Ä–µ—á—å (OpenAI), –∑–∞—Ç–µ–º —Ç–æ—Ç –∂–µ RAG-–ø–∞–π–ø–ª–∞–π–Ω, —á—Ç–æ –∏ on_text.
    –î–µ–ª–∞–µ—Ç –ø–æ–¥—Å–∫–∞–∑–∫—É –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ –∏ –∏–º–µ–µ—Ç —Ñ–æ–ª–±—ç–∫-–º–æ–¥–µ–ª—å, –µ—Å–ª–∏ whisper –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ.
    """
    from openai import OpenAI  # –ª–æ–∫–∞–ª—å–Ω—ã–π –∏–º–ø–æ—Ä—Ç –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
    m = update.effective_message or update.message
    try:
        voice = getattr(m, "voice", None)
        audio = getattr(m, "audio", None)
        tg_file = voice or audio
        if not tg_file:
            return await m.reply_text("–ì–æ–ª–æ—Å–æ–≤–æ–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")

        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        dur = int(getattr(tg_file, "duration", 0) or 0)
        if dur > 180:
            return await m.reply_text("–ê—É–¥–∏–æ –¥–ª–∏–Ω–Ω–µ–µ 3 –º–∏–Ω—É—Ç. –ü—Ä–∏—à–ª–∏—Ç–µ –∫–æ—Ä–æ—á–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞.")

        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª –∏–∑ Telegram
        file = await context.bot.get_file(tg_file.file_id)
        audio_bytes = await file.download_as_bytearray()

        buf = BytesIO(audio_bytes)
        # –ò–º—è —Ñ–∞–π–ª–∞ –ø–æ–º–æ–≥–∞–µ—Ç SDK –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ñ–æ—Ä–º–∞—Ç; .oga / .ogg –¥–ª—è voice –∏–∑ TG –æ–∫
        buf.name = "voice.ogg"

        client = OpenAI(api_key=settings.openai_api_key)

        # 1) –û—Å–Ω–æ–≤–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ ‚Äî whisper-1 —Å –ø–æ–¥—Å–∫–∞–∑–∫–æ–π —è–∑—ã–∫–∞
        tr = client.audio.transcriptions.create(
            model="whisper-1",
            file=buf,
            language="ru"
        )
        text = getattr(tr, "text", None) or (tr.get("text") if isinstance(tr, dict) else None)

        # 2) –§–æ–ª–±—ç–∫: –µ—Å–ª–∏ –ø—É—Å—Ç–æ ‚Äî –ø—Ä–æ–±—É–µ–º –≤—Ç–æ—Ä—É—é –º–æ–¥–µ–ª—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        if not (text or "").strip():
            buf.seek(0)
            tr2 = client.audio.transcriptions.create(
                model="gpt-4o-mini-transcribe",
                file=buf,
                language="ru"
            )
            text = getattr(tr2, "text", None) or (tr2.get("text") if isinstance(tr2, dict) else None)

        if not (text or "").strip():
            return await m.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")

        q = text.strip()

        # --- –î–∞–ª–µ–µ –∫–∞–∫ on_text: RAG-–ø–∞–π–ø–ª–∞–π–Ω ---
        with SessionLocal() as db:
            tg_id = update.effective_user.id
            user_id = _ensure_user(db, tg_id)
            dialog_id = _ensure_dialog(db, user_id)

            chunks = _retrieve_chunks(db, dialog_id, q, k=6)

            if chunks:
                ctx_blocks = [r["content"][:800] for r in chunks]
                prompt = _build_prompt(ctx_blocks, q)
            else:
                prompt = q

            resp = client.chat.completions.create(
                model=settings.openai_model,
                messages=[
                    {"role": "system", "content": "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
            )
            answer = resp.choices[0].message.content or "‚Ä¶"
            if chunks:
                answer += _format_citations(chunks)

        # –û—Ç–¥–∞—ë–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è + –æ—Ç–≤–µ—Ç
        await m.reply_text(f"üó£Ô∏è –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ:\n{q}")
        await m.reply_text(answer)

    except Exception:
        log.exception("on_voice failed")
        await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")


def ya_download(path: str) -> bytes:
    """
    –°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª —Å –Ø.–î–∏—Å–∫–∞ –ø–æ –∞–±—Å–æ–ª—é—Ç–Ω–æ–º—É –ø—É—Ç–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'disk:/–ë–∞–∑–∞ –ó–Ω–∞–Ω–∏–π/file.pdf').
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –±–∏–Ω–∞—Ä–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞.
    """
    import requests
    YA_API = "https://cloud-api.yandex.net/v1/disk"
    headers = {"Authorization": f"OAuth {settings.yandex_disk_token}"}

    # 1) –ø–æ–ª—É—á–∞–µ–º href –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    r = requests.get(
        f"{YA_API}/resources/download",
        headers=headers,
        params={"path": path},
        timeout=60,
    )
    r.raise_for_status()
    href = (r.json() or {}).get("href")
    if not href:
        raise RuntimeError("download href not returned by Yandex Disk")

    # 2) —Å–∫–∞—á–∏–≤–∞–µ–º —Å–∞–º —Ñ–∞–π–ª
    f = requests.get(href, timeout=300)
    f.raise_for_status()
    return f.content

async def rag_selftest(update, context):
    from sqlalchemy import text as sa_text
    m = update.effective_message or update.message
    try:
        with SessionLocal() as db:
            t = db.execute(sa_text("SELECT pg_typeof(embedding)::text FROM kb_chunks LIMIT 1")).scalar()
            d = db.execute(sa_text("SELECT (embedding <=> embedding) FROM kb_chunks LIMIT 1")).scalar()
        await m.reply_text(f"pg_typeof(embedding) = {t}\n(embedding <=> embedding) = {d}")
    except Exception as e:
        log.exception("rag_selftest failed")
        await m.reply_text(f"‚ùå rag_selftest: {e}")

# ---- RAG helpers ----
from typing import List, Tuple

def _vec_literal(vec: list[float]) -> tuple[dict, str]:
    # –ø–æ–¥–∞—ë–º —Å—Ç—Ä–æ–∫—É –≤–∏–¥–∞ "[0.1,0.2,...]" –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–µ q
    arr = "[" + ",".join(f"{x:.6f}" for x in (vec or [])) + "]"
    return {"q": arr}, "CAST(:q AS vector)"   # <- –≤–æ–∑–≤—Ä–∞—â–∞–µ–º params –∏ SQL-–≤—ã—Ä–∞–∂–µ–Ω–∏–µ

def _embed_query(text: str) -> List[float]:
    from openai import OpenAI
    client = OpenAI(api_key=settings.openai_api_key)
    return client.embeddings.create(model=settings.embedding_model, input=[text]).data[0].embedding

def _retrieve_chunks(db, dialog_id: int, question: str, k: int = 6) -> List[dict]:
    # –µ—Å–ª–∏ —Å—Ç–æ–ª–±–µ—Ü embedding –Ω–µ –≤ vector-—Ç–∏–ø–µ ‚Äî –ø—Ä–æ—Å—Ç–æ –≤–µ—Ä–Ω—ë–º –ø—É—Å—Ç–æ (RAG –æ—Ç–∫–ª—é—á–∏—Ç—Å—è)
    kind = _kb_embedding_column_kind(db)
    if kind != "vector":
        return []

    q = _embed_query(question)
    params, qexpr = _vec_literal(q)
    
    sql = f"""
        SELECT c.content, c.meta, d.path
        FROM kb_chunks c
        JOIN kb_documents d    ON d.id = c.document_id AND d.is_active = TRUE
        JOIN dialog_kb_links l ON l.document_id = c.document_id
        WHERE l.dialog_id = :did
        ORDER BY c.embedding <=> {qexpr}
        LIMIT :k
    """
    p = {"did": dialog_id, "k": k}
    p.update(params)
    rows = db.execute(sa_text(sql), p).mappings().all()
    return [dict(r) for r in rows]

def _build_prompt(context_blocks: List[str], question: str) -> str:
    ctx = "\n\n".join(f"[{i+1}] {b}" for i, b in enumerate(context_blocks))
    return (
        "–¢—ã –æ—Ç–≤–µ—á–∞–µ—à—å –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–∏–∂–µ. "
        "–ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞, —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º.\n\n"
        f"–ö–û–ù–¢–ï–ö–°–¢:\n{ctx}\n\n"
        f"–í–û–ü–†–û–°: {question}\n–û–¢–í–ï–¢:"
    )

def _format_citations(chunks: List[dict]) -> str:
    # –ë–µ—Ä—ë–º –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
    def short(p: str) -> str:
        return (p or "").split("/")[-1].split("?")[0]
    uniq = []
    for r in chunks:
        name = short(r.get("path") or (r.get("meta") or {}).get("path", ""))
        if name and name not in uniq:
            uniq.append(name)
    if not uniq: 
        return ""
    return "\n\n–ò—Å—Ç–æ—á–Ω–∏–∫–∏: " + "; ".join(f"[{i+1}] {n}" for i, n in enumerate(uniq[:5]))

async def on_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    q = (m.text or "").strip()
    if not q:
        return

    try:
        with SessionLocal() as db:
            tg_id = update.effective_user.id
            user_id = _ensure_user(db, tg_id)
            dialog_id = _ensure_dialog(db, user_id)  # –∞–∫—Ç–∏–≤–Ω—ã–π –¥–∏–∞–ª–æ–≥

            # 1) –ø—Ä–æ–±—É–µ–º –¥–æ—Å—Ç–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–æ–¥–∫–ª—é—á—ë–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            chunks = _retrieve_chunks(db, dialog_id, q, k=6)

            from openai import OpenAI
            client = OpenAI(api_key=settings.openai_api_key)

            if chunks:
                ctx_blocks = [r["content"][:800] for r in chunks]  # –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–∏–º
                prompt = _build_prompt(ctx_blocks, q)
            else:
                # –±–µ–∑ RAG ‚Äî –æ–±—ã—á–Ω—ã–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
                prompt = q

            resp = client.chat.completions.create(
                model=settings.openai_model,
                messages=[{"role":"system","content":"–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫."},
                          {"role":"user","content": prompt}],
                temperature=0.2,
            )
            answer = resp.choices[0].message.content or "‚Ä¶"

            # –¥–æ–±–∞–≤–∏–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏, –µ—Å–ª–∏ –±—ã–ª –∫–æ–Ω—Ç–µ–∫—Å—Ç
            if chunks:
                answer += _format_citations(chunks)

            await m.reply_text(answer)
    except Exception:
        log.exception("on_text failed")
        await m.reply_text("‚ö† –ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")

# === DIAG: –ø–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å –≤—Å–µ—Ö PDF –Ω–∞ –¥–∏—Å–∫–µ –∏ —á—Ç–æ —Å –Ω–∏–º–∏ –ø—Ä–∏ —Ä–∞–∑–±–æ—Ä–µ ===
async def kb_pdf_diag(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        if not _is_admin(update.effective_user.id):
            return await m.reply_text("–¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞.")

        root = settings.yandex_root_path
        files = [f for f in _ya_list_files(root) if (f.get("name") or "").lower().endswith(".pdf")]

        lines = []
        for it in files:
            path = it.get("path") or it.get("name")
            try:
                blob = ya_download(path)
                txt, pages, is_prot = _pdf_extract_text(blob)
                sample = (txt or "").strip().replace("\n", " ")
                sample = (sample[:120] + "‚Ä¶") if len(sample) > 120 else sample
                lines.append(f"‚Ä¢ {path.split('/')[-1]} | pages={pages} | prot={'yes' if is_prot else 'no'} | text_len={len(txt or '')} | sample='{sample}'")
            except Exception as e:
                lines.append(f"‚Ä¢ {path.split('/')[-1]} | ERROR: {e}")
        if not lines:
            lines = ["(PDF –Ω–µ –Ω–∞–π–¥–µ–Ω—ã)"]
        await m.reply_text("PDF DIAG:\n" + "\n".join(lines[:30]))
    except Exception:
        log.exception("kb_pdf_diag failed")
        await m.reply_text("‚ö† kb_pdf_diag: –æ—à–∏–±–∫–∞. –°–º–æ—Ç—Ä–∏ –ª–æ–≥–∏.")

async def rag_diag(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    q = " ".join(context.args) if context.args else ""
    if not q:
        return await m.reply_text("–ù–∞–ø–∏—à–∏—Ç–µ –∑–∞–ø—Ä–æ—Å: /rag_diag –≤–∞—à –≤–æ–ø—Ä–æ—Å")
    try:
        with SessionLocal() as db:
            uid = _ensure_user(db, update.effective_user.id)
            did = _ensure_dialog(db, uid)
            rows = _retrieve_chunks(db, did, q, k=5)
            if not rows:
                return await m.reply_text("–ù–∏—á–µ–≥–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –Ω–µ –Ω–∞—à–ª–∏ —Å—Ä–µ–¥–∏ –ø–æ–¥–∫–ª—é—á—ë–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.")
            out = []
            for i, r in enumerate(rows, 1):
                path = (r.get("path") or (r.get("meta") or {}).get("path", "")).split("/")[-1]
                sample = (r["content"] or "")[:140].replace("\n", " ")
                out.append(f"[{i}] {path} ‚Äî ‚Äú{sample}‚Ä¶‚Äù")
            await m.reply_text("\n".join(out))
    except Exception:
        log.exception("rag_diag failed")
        await m.reply_text("‚ö† rag_diag: –æ—à–∏–±–∫–∞. –°–º–æ—Ç—Ä–∏ –ª–æ–≥–∏.")

# ---- PDF helpers ----
def _pdf_extract_text(pdf_bytes: bytes) -> tuple[str, int, bool]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (—Ç–µ–∫—Å—Ç, pages, is_protected).
    1) PyMuPDF
    2) Fallback –Ω–∞ pdfminer.six, –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –ø—É—Å—Ç–æ–π –∏ –Ω–µ –∑–∞—â–∏—â—ë–Ω
    """
    import fitz  # PyMuPDF
    with fitz.open(stream=pdf_bytes, filetype="pdf") as doc:
        is_prot = bool(doc.is_encrypted)
        if is_prot:
            try:
                if doc.authenticate(""):
                    is_prot = False
            except Exception:
                pass
        if is_prot:
            return ("", 0, True)

        pages = doc.page_count
        out = []
        for i in range(pages):
            try:
                text = doc.load_page(i).get_text("text") or ""
            except Exception:
                text = ""
            out.append(text)
        txt = "\n".join(out)

    # Fallback: –µ—Å–ª–∏ –ø—É—Å—Ç–æ, –ø–æ–ø—Ä–æ–±—É–µ–º pdfminer
    if not txt.strip():
        try:
            from io import BytesIO
            from pdfminer.high_level import extract_text
            txt = extract_text(BytesIO(pdf_bytes)) or ""
        except Exception:
            pass

    return (txt, pages, False)


# 0) –∫–∞–∫–æ–≥–æ —Ç–∏–ø–∞ –∫–æ–ª–æ–Ω–∫–∞ embedding –≤ kb_chunks: 'vector' | 'bytea' | 'none'
try:
    _kb_embedding_column_kind
except NameError:
    def _kb_embedding_column_kind(db) -> str:
        try:
            t = db.execute(sa_text("SELECT pg_typeof(embedding)::text FROM kb_chunks LIMIT 1")).scalar()
            if t:
                t = str(t).lower()
                if "vector" in t:
                    return "vector"
                if "bytea" in t:
                    return "bytea"
            # fallback —á–µ—Ä–µ–∑ information_schema
            t = db.execute(sa_text("""
                SELECT COALESCE(udt_name, data_type)
                FROM information_schema.columns
                WHERE table_name='kb_chunks' AND column_name='embedding'
                LIMIT 1
            """)).scalar()
            t = (t or "").lower()
            if "vector" in t:
                return "vector"
            if "bytea" in t:
                return "bytea"
        except Exception:
            pass
        return "none"

# 1) upsert –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ kb_documents (–≤–æ–∑–≤—Ä–∞—â–∞–µ–º id)
try:
    _kb_upsert_document
except NameError:
    def _kb_upsert_document(db, path: str, mime: str, size: int, etag: str) -> int:
        sql = sa_text("""
            INSERT INTO kb_documents (path, mime, bytes, etag, updated_at, is_active)
            VALUES (:p, :m, :b, :e, now(), TRUE)
            ON CONFLICT (path) DO UPDATE
              SET mime = EXCLUDED.mime,
                  bytes = EXCLUDED.bytes,
                  etag  = EXCLUDED.etag,
                  updated_at = now(),
                  is_active = TRUE
            RETURNING id
        """)
        doc_id = db.execute(sql, {"p": path, "m": mime, "b": size, "e": etag}).scalar()
        db.commit()
        return int(doc_id)

# 2) –æ—á–∏—Å—Ç–∫–∞ —á–∞–Ω–∫–æ–≤ –ø–æ document_id
try:
    _kb_clear_chunks
except NameError:
    def _kb_clear_chunks(db, document_id: int):
        db.execute(sa_text("DELETE FROM kb_chunks WHERE document_id=:d"), {"d": document_id})
        db.commit()

# 3) –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —Å –Ø.–î–∏—Å–∫–∞ –ø–æ –ø—É—Ç–∏
try:
    _ya_download
except NameError:
    def _chunk_text(text: str, max_tokens: int = 2000, overlap: int = 0):
        """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –∫—É—Å–∫–∏ –ø–æ max_tokens –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º overlap"""
        enc = tiktoken.get_encoding("cl100k_base")
        tokens = enc.encode(text)
    
        chunks = []
        i = 0
        while i < len(tokens):
            chunk_tokens = tokens[i:i+max_tokens]
            chunk_text = enc.decode(chunk_tokens)
            chunks.append(chunk_text.strip())
            if overlap > 0:
                i += max_tokens - overlap
            else:
                i += max_tokens
    
        return chunks

# 4) –ø—Ä–æ—Å—Ç–∞—è —Ä–µ–∑–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞–Ω–∫–∏
try:
    _chunk_text
except NameError:
    def _chunk_text(text: str, max_tokens: int = 2000):
        """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –∫—É—Å–∫–∏ –ø–æ max_tokens –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        enc = tiktoken.get_encoding("cl100k_base")
        tokens = enc.encode(text)
    
        chunks = []
        for i in range(0, len(tokens), max_tokens):
            chunk_tokens = tokens[i:i+max_tokens]
            chunk_text = enc.decode(chunk_tokens)
            chunks.append(chunk_text.strip())
    
        return chunks

# 5) —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –ø–∞—á–∫–æ–π (OpenAI)
try:
    _get_embeddings
except NameError:
    def _get_embeddings(chunks: list[str]) -> list[list[float]]:
        """
        –°—á–∏—Ç–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ, –±–∞—Ç—á–∞–º–∏:
        - –ª–∏–º–∏—Ç –ø–æ —Å—É–º–º–∞—Ä–Ω—ã–º —Ç–æ–∫–µ–Ω–∞–º ~250k –Ω–∞ –∑–∞–ø—Ä–æ—Å (–∑–∞–ø–∞—Å –æ—Ç 300k);
        - –¥–æ–ø. –ª–∏–º–∏—Ç –Ω–∞ —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —ç–ª–µ–º–µ–Ω—Ç–æ–≤, —á—Ç–æ–±—ã –Ω–µ —Ä–∞–∑–¥—É–≤–∞—Ç—å payload.
        """
        if not chunks:
            return []
    
        enc = tiktoken.get_encoding("cl100k_base")
        from openai import OpenAI
        client = OpenAI(api_key=settings.openai_api_key)
    
        MAX_TOKENS_PER_REQ = 250_000   # –∑–∞–ø–∞—Å –æ—Ç –ª–∏–º–∏—Ç–∞ 300k
        MAX_ITEMS_PER_REQ  = 128       # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –æ–≥—Ä–∞–Ω–∏—á–∏–º –∏ –ø–æ —á–∏—Å–ª—É —Å—Ç—Ä–æ–∫
    
        out: list[list[float]] = []
        batch: list[str] = []
        batch_tok_sum = 0
    
        def flush_batch():
            nonlocal out, batch, batch_tok_sum
            if not batch:
                return
            resp = client.embeddings.create(model=settings.embedding_model, input=batch)
            data = getattr(resp, "data", None) or resp.get("data", [])
            # order –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω, –ø—Ä–æ—Å—Ç–æ –¥–æ–ø–∏—Å—ã–≤–∞–µ–º
            out.extend([item.embedding for item in data])
            batch = []
            batch_tok_sum = 0
    
        for ch in chunks:
            t = len(enc.encode(ch or ""))
            # –µ—Å–ª–∏ –æ–¥–∏–Ω–æ—á–Ω—ã–π —á–∞–Ω–∫ –≤–¥—Ä—É–≥ –±–æ–ª—å—à–µ –ª–∏–º–∏—Ç–∞ ‚Äî —É–∂–µ –ø–æ—Ä–µ–∑–∞–Ω —Ä–∞–Ω–µ–µ; –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π:
            if t > MAX_TOKENS_PER_REQ:
                # –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞—â–∏—Ç–∞: –¥–æ—Ä–µ–∑–∞—Ç—å –Ω–∞ –ø–æ–¥—á–∞–Ω–∫–∏ –ø–æ 2000 —Ç–æ–∫–µ–Ω–æ–≤
                subchunks = []
                toks = enc.encode(ch or "")
                for i in range(0, len(toks), 2000):
                    subchunks.append(enc.decode(toks[i:i+2000]))
                # —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø—Ä–æ–≥–æ–Ω—è–µ–º –ø–æ–¥—á–∞–Ω–∫–∏ —Ç–µ–º –∂–µ –º–µ—Ö–∞–Ω–∏–∑–º–æ–º
                out.extend(_get_embeddings(subchunks))
                continue
    
            # –µ—Å–ª–∏ —Ç–µ–∫—É—â–∏–π –Ω–µ –≤–ª–µ–∑–∞–µ—Ç –≤ –±–∞—Ç—á ‚Äî —à–ª—ë–º —Ç–æ, —á—Ç–æ –Ω–∞–∫–æ–ø–ª–µ–Ω–æ
            if batch and (batch_tok_sum + t > MAX_TOKENS_PER_REQ or len(batch) >= MAX_ITEMS_PER_REQ):
                flush_batch()
    
            batch.append(ch)
            batch_tok_sum += t
    
        flush_batch()
        return out

# 6) SQL-—Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
try:
    _format_vector_sql
except NameError:
    def _format_vector_sql(vec: list[float]) -> tuple[str, dict]:
        arr = "[" + ",".join(f"{x:.6f}" for x in (vec or [])) + "]"
        return " CAST(:emb AS vector) ", {"emb": arr}

try:
    _format_bytea_sql
except NameError:
    def _format_bytea_sql(vec: list[float]) -> tuple[str, dict]:
        try:
            import struct
            from psycopg2 import Binary
            b = struct.pack(f"{len(vec)}f", *vec) if vec else b""
            return " :emb ", {"emb": Binary(b)}
        except Exception:
            return " NULL ", {}
# ==== /KB RAG helpers ====

# --- Fallback –ª–∏—Å—Ç–∏–Ω–≥ –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–∞ (–µ—Å–ª–∏ –Ω–µ—Ç —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ö–µ–ª–ø–µ—Ä–∞) ---
def _ya_list_files(root_path: str):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ –Ø.–î–∏—Å–∫–∞ —á–µ—Ä–µ–∑ REST API.
    –≠–ª–µ–º–µ–Ω—Ç—ã: name, path, type, mime_type, size, md5.
    """
    import requests
    YA_API = "https://cloud-api.yandex.net/v1/disk"
    out = []
    limit, offset = 200, 0
    headers = {"Authorization": f"OAuth {settings.yandex_disk_token}"}
    while True:
        params = {
            "path": root_path,
            "limit": limit,
            "offset": offset,
            "fields": "_embedded.items.name,_embedded.items.path,_embedded.items.type,_embedded.items.mime_type,_embedded.items.size,_embedded.items.md5",
        }
        r = requests.get(f"{YA_API}/resources", headers=headers, params=params, timeout=30)
        r.raise_for_status()
        data = r.json()
        items = (data.get("_embedded") or {}).get("items") or []
        for it in items:
            if it.get("type") == "file":
                out.append(it)
        if len(items) < limit:
            break
        offset += limit
    return out


def _kb_update_pages(db, document_id: int, pages: int | None):
    if pages is None:
        return
    db.execute(sa_text("UPDATE kb_documents SET pages=:p, updated_at=now() WHERE id=:id"), {"p": pages, "id": document_id})
    db.commit()

# –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ PDF (–±–µ–∑ –ø–∞—Ä–æ–ª—è). –ó–∞—â–∏—â—ë–Ω–Ω—ã–µ PDF —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º, –Ω–æ –Ω–µ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º.

async def kb_sync_pdf(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        if not _is_admin(update.effective_user.id):
            return await m.reply_text("–¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞.")
        await m.reply_text("üìÑ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è PDF –Ω–∞—á–∞–ª–∞—Å—å‚Ä¶")

        root = settings.yandex_root_path
        files = [f for f in _ya_list_files(root) if (f.get("name") or "").lower().endswith(".pdf")]

        touched_docs = len(files)
        indexed_docs = 0
        indexed_chunks = 0

        with SessionLocal() as db:
            emb_kind = _kb_embedding_column_kind(db)  # 'vector' | 'bytea' | 'none'

            # –î–µ–∞–∫—Ç–∏–≤–∏—Ä—É–µ–º PDF, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –Ω–∞ –¥–∏—Å–∫–µ
            present = { (f.get("path") or f.get("name")) for f in files if (f.get("path") or f.get("name")) }
            rows = db.execute(sa_text("SELECT id, path, is_active FROM kb_documents WHERE mime LIKE 'application/pdf%'")).mappings().all()
            for r in rows:
                if r["path"] not in present and r["is_active"]:
                    db.execute(sa_text("UPDATE kb_documents SET is_active=FALSE, updated_at=now() WHERE id=:id"), {"id": r["id"]})
            db.commit()

            for it in files:
                path  = it.get("path") or it.get("name")
                mime  = it.get("mime_type") or "application/pdf"
                size  = int(it.get("size") or 0)
                etag  = it.get("md5") or ""
                if not path:
                    continue

                doc_id = _kb_upsert_document(db, path=path, mime=mime, size=size, etag=etag)

                # –°–∫–∞—á–∏–≤–∞–µ–º
                try:
                    blob = ya_download(path)
                except Exception as e:
                    log.exception("pdf download failed: %s (%s)", path, e)
                    continue

                # –ü–∞—Ä—Å–∏–º
                try:
                    txt, pages, is_prot = _pdf_extract_text(blob)
                except Exception as e:
                    log.exception("pdf parse failed: %s (%s)", path, e)
                    continue

                _kb_update_pages(db, doc_id, pages if pages else None)

                # –ó–∞—â–∏—â—ë–Ω–Ω—ã–π –∏–ª–∏ –ø—É—Å—Ç–æ–π PDF ‚Äî –Ω–µ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º
                if is_prot or not txt.strip():
                    log.info("pdf skipped (protected or empty): %s", path)
                    continue

                # –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Ü–µ–ª–∏–∫–æ–º –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
                _kb_clear_chunks(db, doc_id)

                chunks = _chunk_text(txt, settings.chunk_size, settings.chunk_overlap)
                embs = _get_embeddings(chunks) if emb_kind in ("vector","bytea") else [[] for _ in chunks]

                doc_failed = False
                inserted = 0
                for idx, (ch, ve) in enumerate(zip(chunks, embs)):
                    meta = {"path": path, "mime": mime}
                    if emb_kind == "vector":
                        place, params = _format_vector_sql(ve)
                    elif emb_kind == "bytea":
                        place, params = _format_bytea_sql(ve)
                    else:
                        place, params = " NULL ", {}

                    sql = f"""
                        INSERT INTO kb_chunks (document_id, chunk_index, content, meta, embedding)
                        VALUES (:d, :i, :c, :meta, {place})
                    """
                    p = {"d": doc_id, "i": idx, "c": ch, "meta": json.dumps(meta)}
                    p.update(params)
                    try:
                        db.execute(sa_text(sql), p)
                        inserted += 1
                        if inserted % 200 == 0:
                            db.commit()
                    except Exception as e:
                        log.exception("insert pdf chunk failed (doc_id=%s, idx=%s): %s", doc_id, idx, e)
                        doc_failed = True
                        continue

                db.commit()

                if not doc_failed and inserted > 0:
                    indexed_docs += 1
                    indexed_chunks += inserted

        await m.reply_text(
            "‚úÖ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è PDF –∑–∞–≤–µ—Ä—à–µ–Ω–∞.\n"
            f"–î–æ–∫—É–º–µ–Ω—Ç–æ–≤ —É—á—Ç–µ–Ω–æ: {touched_docs}\n"
            f"–ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ: {indexed_docs} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, {indexed_chunks} —á–∞–Ω–∫–æ–≤"
        )
    except Exception as e:
        log.exception("kb_sync_pdf failed")
        await (update.effective_message or update.message).reply_text(f"‚ö† kb_sync_pdf: {e}")

async def kb_sync(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–í—Ä–µ–º–µ–Ω–Ω–∞—è –∑–∞–≥–ª—É—à–∫–∞, —á—Ç–æ–±—ã –Ω–µ –ø–∞–¥–∞–ª –∏–º–ø–æ—Ä—Ç. –ü–æ–ª–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —É –Ω–∞—Å —á–µ—Ä–µ–∑ /kb_sync_pdf."""
    try:
        if not _is_admin(update.effective_user.id):
            return await (update.effective_message or update.message).reply_text("–¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞.")
        return await (update.effective_message or update.message).reply_text(
            "‚Ñπ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /kb_sync_pdf ‚Äî –æ–Ω –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—É—é —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é PDF –∏ –¥–µ–∞–∫—Ç–∏–≤–∞—Ü–∏—é —É–¥–∞–ª—ë–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤."
        )
    except Exception:
        log.exception("kb_sync (stub) failed")

async def kb_chunks_force(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        if not _is_admin(update.effective_user.id):
            return await m.reply_text("–¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞.")

        from sqlalchemy import text as sa_text
        notes = []

        with SessionLocal() as db:
            # 0) vector –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π (–±–µ–∑ –ø–∞–Ω–∏–∫–∏ –ø—Ä–∏ –æ—à–∏–±–∫–µ)
            try:
                db.execute(sa_text("CREATE EXTENSION IF NOT EXISTS vector;"))
                db.commit()
            except Exception:
                db.rollback()
                notes.append("[warn] CREATE EXTENSION vector failed")

            # 1) –°–æ–∑–¥–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É (–µ—Å–ª–∏ vector –µ—Å—Ç—å ‚Äî —Å vector(3072), –∏–Ω–∞—á–µ fallback BYTEA)
            has_vector_type = False
            try:
                has_vector_type = db.execute(sa_text(
                    "SELECT EXISTS(SELECT 1 FROM pg_type WHERE typname='vector')"
                )).scalar()
            except Exception:
                pass

            try:
                if has_vector_type:
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS kb_chunks (
                            id           BIGSERIAL PRIMARY KEY,
                            document_id  BIGINT NOT NULL,
                            chunk_index  INTEGER NOT NULL,
                            content      TEXT NOT NULL,
                            meta         JSON,
                            embedding    vector(3072)
                        );
                    """))
                else:
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS kb_chunks (
                            id           BIGSERIAL PRIMARY KEY,
                            document_id  BIGINT NOT NULL,
                            chunk_index  INTEGER NOT NULL,
                            content      TEXT NOT NULL,
                            meta         JSON,
                            embedding    BYTEA
                        );
                    """))
                    notes.append("[info] fallback: embedding BYTEA (–Ω–µ—Ç —Ç–∏–ø–∞ vector)")
                db.commit()
            except Exception as e:
                db.rollback()
                raise RuntimeError(f"CREATE TABLE failed: {e}")

            # 2) –ü—Ä–æ—Å—Ç–µ–π—à–∏–µ –∏–Ω–¥–µ–∫—Å—ã (–±–µ–∑ ivfflat) ‚Äî –æ—Ç–¥–µ–ª—å–Ω–∞—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è
            try:
                db.execute(sa_text("CREATE INDEX IF NOT EXISTS ix_kb_chunks_document_id ON kb_chunks(document_id);"))
                db.execute(sa_text("CREATE INDEX IF NOT EXISTS ix_kb_chunks_doc_chunk ON kb_chunks(document_id, chunk_index);"))
                db.commit()
            except Exception as e:
                db.rollback()
                notes.append(f"[warn] create simple indexes failed: {e}")

            # 3) –í–Ω–µ—à–Ω–∏–π –∫–ª—é—á –Ω–∞ kb_documents ‚Äî –æ—Ç–¥–µ–ª—å–Ω–∞—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è
            try:
                db.execute(sa_text("""
                    DO $$
                    BEGIN
                        IF NOT EXISTS (
                           SELECT 1 FROM pg_constraint WHERE conname='fk_kb_chunks_docs'
                        ) THEN
                           ALTER TABLE kb_chunks
                           ADD CONSTRAINT fk_kb_chunks_docs
                           FOREIGN KEY (document_id) REFERENCES kb_documents(id) ON DELETE CASCADE;
                        END IF;
                    END $$;
                """))
                db.commit()
            except Exception as e:
                db.rollback()
                notes.append(f"[warn] add FK failed: {e}")

        await m.reply_text("‚úÖ kb_chunks —Å–æ–∑–¥–∞–Ω–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–∞ (–±–µ–∑ ivfflat).\n" + ("\n".join(notes) if notes else ""))
    except Exception as e:
        import traceback
        tb = traceback.format_exc(limit=3)
        log.exception("kb_chunks_force failed")
        await m.reply_text(f"‚ö† kb_chunks_force: {e}\n{tb}")

# –î–æ–≤–µ–¥—ë–º kb_chunks: —É–±–µ—Ä—ë–º ivfflat, –¥–æ–±–∞–≤–∏–º FK –∏ —Ç–µ—Ö.–∏–Ω–¥–µ–∫—Å—ã
async def kb_chunks_fix(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        if not _is_admin(update.effective_user.id):
            return await m.reply_text("–¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞.")
        from sqlalchemy import text as sa_text
        with SessionLocal() as db:
            # —É–¥–∞–ª–∏—Ç—å ivfflat-–∏–Ω–¥–µ–∫—Å –µ—Å–ª–∏ –æ–Ω —É—Å–ø–µ–ª —Å–æ–∑–¥–∞—Ç—å—Å—è —á–∞—Å—Ç–∏—á–Ω–æ (–Ω–∞ –≤—Å—è–∫–∏–π)
            try:
                db.execute(sa_text("DROP INDEX IF EXISTS kb_chunks_embedding_idx;"))
                db.commit()
            except Exception:
                db.rollback()
            # –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º
            db.execute(sa_text("CREATE INDEX IF NOT EXISTS ix_kb_chunks_document_id ON kb_chunks(document_id);"))
            db.execute(sa_text("CREATE INDEX IF NOT EXISTS ix_kb_chunks_doc_chunk ON kb_chunks(document_id, chunk_index);"))
            # –¥–æ–±–∞–≤–∏—Ç—å FK –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
            try:
                db.execute(sa_text("""
                    DO $$
                    BEGIN
                        IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='fk_kb_chunks_docs') THEN
                            ALTER TABLE kb_chunks
                            ADD CONSTRAINT fk_kb_chunks_docs
                            FOREIGN KEY (document_id) REFERENCES kb_documents(id) ON DELETE CASCADE;
                        END IF;
                    END $$;
                """))
            except Exception:
                pass
            db.commit()
        await m.reply_text("‚úÖ kb_chunks –ø–æ—á–∏–Ω–µ–Ω–∞: –±–µ–∑ ivfflat, —Å FK –∏ –∏–Ω–¥–µ–∫—Å–∞–º–∏.")
    except Exception:
        log.exception("kb_chunks_fix failed")
        await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—á–∏–Ω–∏—Ç—å kb_chunks. –°–º–æ—Ç—Ä–∏ –ª–æ–≥–∏.")

# –°–æ–∑–¥–∞—Ç—å kb_chunks –Ω–∞–¥—ë–∂–Ω–æ: —Å vector, –∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ ‚Äî fallback –±–µ–∑ vector
async def kb_chunks_create(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        if not _is_admin(update.effective_user.id):
            return await m.reply_text("–¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞.")

        from sqlalchemy import text as sa_text
        created_note = ""
        with SessionLocal() as db:
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è
            search_path = db.execute(sa_text("SHOW search_path")).scalar()
            has_tbl = db.execute(sa_text("SELECT to_regclass('public.kb_chunks') IS NOT NULL")).scalar()
            has_vector_ext = db.execute(sa_text(
                "SELECT EXISTS(SELECT 1 FROM pg_extension WHERE extname='vector')"
            )).scalar()
            has_vector_type = db.execute(sa_text(
                "SELECT EXISTS(SELECT 1 FROM pg_type WHERE typname='vector')"
            )).scalar()

            if has_tbl:
                return await m.reply_text("‚úÖ kb_chunks —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.")

            # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π ‚Äî —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
            if not has_vector_ext:
                try:
                    db.execute(sa_text("CREATE EXTENSION IF NOT EXISTS vector;"))
                    db.commit()
                    has_vector_ext = True
                except Exception as e:
                    db.rollback()
                    # –Ω–µ –ø–∞–¥–∞–µ–º ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º fallback
                    created_note += f"[warn] CREATE EXTENSION failed: {e}\n"

            # –û–±–Ω–æ–≤–∏–º –Ω–∞–ª–∏—á–∏–µ —Ç–∏–ø–∞
            if not has_vector_type:
                has_vector_type = db.execute(sa_text(
                    "SELECT EXISTS(SELECT 1 FROM pg_type WHERE typname='vector')"
                )).scalar()

            try:
                if has_vector_type:
                    # –û—Å–Ω–æ–≤–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç: —Å vector(3072)
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS kb_chunks (
                            id           BIGSERIAL PRIMARY KEY,
                            document_id  BIGINT NOT NULL,
                            chunk_index  INTEGER NOT NULL,
                            content      TEXT NOT NULL,
                            meta         JSON,
                            embedding    vector(3072)
                        );
                    """))
                    # –ò–Ω–¥–µ–∫—Å—ã –∏ FK (best-effort)
                    try:
                        db.execute(sa_text(
                            "CREATE INDEX IF NOT EXISTS ix_kb_chunks_document_id ON kb_chunks(document_id);"))
                        db.execute(sa_text("""
                            CREATE INDEX IF NOT EXISTS kb_chunks_embedding_idx
                            ON kb_chunks USING ivfflat (embedding vector_cosine_ops);
                        """))
                    except Exception as e:
                        created_note += f"[warn] index create failed: {e}\n"
                    try:
                        db.execute(sa_text("""
                            DO $$
                            BEGIN
                                IF NOT EXISTS (
                                   SELECT 1 FROM pg_constraint WHERE conname = 'fk_kb_chunks_docs'
                                ) THEN
                                   ALTER TABLE kb_chunks
                                   ADD CONSTRAINT fk_kb_chunks_docs
                                   FOREIGN KEY (document_id)
                                   REFERENCES kb_documents(id) ON DELETE CASCADE;
                                END IF;
                            END $$;
                        """))
                    except Exception as e:
                        created_note += f"[warn] FK create failed: {e}\n"

                    db.commit()
                    return await m.reply_text(
                        "‚úÖ kb_chunks —Å–æ–∑–¥–∞–Ω–∞ (vector). "
                        f"\nsearch_path={search_path}\n{created_note or ''}".strip()
                    )

                # Fallback: –±–µ–∑ vector ‚Äî embedding –∫–∞–∫ BYTEA, –±–µ–∑ ivfflat
                db.execute(sa_text("""
                    CREATE TABLE IF NOT EXISTS kb_chunks (
                        id           BIGSERIAL PRIMARY KEY,
                        document_id  BIGINT NOT NULL,
                        chunk_index  INTEGER NOT NULL,
                        content      TEXT NOT NULL,
                        meta         JSON,
                        embedding    BYTEA
                    );
                """))
                try:
                    db.execute(sa_text(
                        "CREATE INDEX IF NOT EXISTS ix_kb_chunks_document_id ON kb_chunks(document_id);"))
                except Exception as e:
                    created_note += f"[warn] fallback index failed: {e}\n"
                try:
                    db.execute(sa_text("""
                        DO $$
                        BEGIN
                            IF NOT EXISTS (
                               SELECT 1 FROM pg_constraint WHERE conname = 'fk_kb_chunks_docs'
                            ) THEN
                               ALTER TABLE kb_chunks
                               ADD CONSTRAINT fk_kb_chunks_docs
                               FOREIGN KEY (document_id)
                               REFERENCES kb_documents(id) ON DELETE CASCADE;
                            END IF;
                        END $$;
                    """))
                except Exception as e:
                    created_note += f"[warn] fallback FK failed: {e}\n"

                db.commit()
                return await m.reply_text(
                    "‚úÖ kb_chunks —Å–æ–∑–¥–∞–Ω–∞ (fallback –±–µ–∑ vector). "
                    f"\nsearch_path={search_path}\n{created_note or ''}".strip()
                )

            except Exception as e:
                db.rollback()
                raise e

    except Exception as e:
        log.exception("kb_chunks_create failed")
        await m.reply_text(f"‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å kb_chunks: {e}")

# —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥ –≤—Ä—É—á–Ω—É—é
async def dialog_new(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        m = update.effective_message or update.message
        tg_id = update.effective_user.id
        with SessionLocal() as db:
            uid = _ensure_user(db, tg_id)
            did = _exec_scalar(
                db,
                """
                INSERT INTO dialogs (user_id, title, style, model, is_deleted)
                VALUES (:u, :t, 'expert', :m, FALSE)
                RETURNING id
                """,
                u=uid, t=datetime.now().strftime("%Y-%m-%d | –¥–∏–∞–ª–æ–≥"), m=settings.openai_model
            )
        db.commit()
        await m.reply_text(f"‚úÖ –°–æ–∑–¥–∞–Ω –¥–∏–∞–ª–æ–≥ #{did}")
    except Exception:
        log.exception("dialog_new failed")
        await (update.effective_message or update.message).reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –¥–∏–∞–ª–æ–≥.")

async def pgvector_check(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        with SessionLocal() as db:
            avail = db.execute(sa_text(
                "SELECT EXISTS(SELECT 1 FROM pg_available_extensions WHERE name='vector')"
            )).scalar()
            installed = db.execute(sa_text(
                "SELECT EXISTS(SELECT 1 FROM pg_extension WHERE extname='vector')"
            )).scalar()
        await (update.effective_message or update.message).reply_text(
            f"pgvector –¥–æ—Å—Ç—É–ø–Ω–æ: {'‚úÖ' if avail else '‚ùå'}\n"
            f"pgvector —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ: {'‚úÖ' if installed else '‚ùå'}"
        )
    except Exception:
        log.exception("pgvector_check failed")
        await (update.effective_message or update.message).reply_text("‚ö† –û—à–∏–±–∫–∞ pgvector_check. –°–º–æ—Ç—Ä–∏ –ª–æ–≥–∏.")

async def repair_schema(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    –ß–∏–Ω–∏—Ç —Å—Ö–µ–º—É –ø–æ —à–∞–≥–∞–º –∏ —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ—Å–ª–µ –ö–ê–ñ–î–û–ô —Ç–∞–±–ª–∏—Ü—ã.
    –î–∞–∂–µ –µ—Å–ª–∏ –Ω–∞ kb_* —É–ø–∞–¥—ë—Ç, –±–∞–∑–æ–≤—ã–µ —Ç–∞–±–ª–∏—Ü—ã users/dialogs/messages –æ—Å—Ç–∞–Ω—É—Ç—Å—è.
    """
    m = update.effective_message or update.message
    try:
        if not _is_admin(update.effective_user.id):
            return await m.reply_text("–¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞.")

        await m.reply_text("üß∞ –†–µ–º–æ–Ω—Ç —Å—Ö–µ–º—ã –Ω–∞—á–∞—Ç. –ü–∏—à—É –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ –ª–æ–≥–∏...")

        from sqlalchemy import text as sa_text
        created = []
        with SessionLocal() as db:

            def has(table: str) -> bool:
                return bool(db.execute(sa_text("SELECT to_regclass(:t)"), {"t": f"public.{table}"}).scalar())

            # 0) vector extension ‚Äî –æ—Ç–¥–µ–ª—å–Ω–æ –∏ –±–µ–∑ –ø–∞–Ω–∏–∫–∏
            try:
                db.execute(sa_text("CREATE EXTENSION IF NOT EXISTS vector;"))
                db.commit()
                log.info("repair: extension vector OK (–∏–ª–∏ —É–∂–µ –±—ã–ª–æ)")
            except Exception:
                db.rollback()
                log.exception("repair: CREATE EXTENSION vector failed ‚Äî –ø—Ä–æ–¥–æ–ª–∂—É –±–µ–∑ –Ω–µ–≥–æ")

            # 1) USERS ‚Äî –°–ù–ê–ß–ê–õ–ê –ë–ê–ó–ê
            if not has("users"):
                db.execute(sa_text("""
                    CREATE TABLE IF NOT EXISTS users (
                        id           BIGSERIAL PRIMARY KEY,
                        tg_user_id   BIGINT UNIQUE NOT NULL,
                        is_admin     BOOLEAN NOT NULL DEFAULT FALSE,
                        is_allowed   BOOLEAN NOT NULL DEFAULT TRUE,
                        lang         TEXT,
                        created_at   TIMESTAMPTZ NOT NULL DEFAULT now()
                    );
                """))
                db.commit(); created.append("users"); log.info("repair: created users")

            # 2) DIALOGS
            if not has("dialogs"):
                db.execute(sa_text("""
                    CREATE TABLE IF NOT EXISTS dialogs (
                        id              BIGSERIAL PRIMARY KEY,
                        user_id         BIGINT NOT NULL,
                        title           TEXT,
                        style           VARCHAR(20) NOT NULL DEFAULT 'expert',
                        model           TEXT,
                        is_deleted      BOOLEAN NOT NULL DEFAULT FALSE,
                        created_at      TIMESTAMPTZ NOT NULL DEFAULT now(),
                        last_message_at TIMESTAMPTZ
                    );
                """))
                try:
                    db.execute(sa_text("""
                        DO $$
                        BEGIN
                            IF NOT EXISTS (
                               SELECT 1 FROM pg_constraint WHERE conname = 'fk_dialogs_users'
                            ) THEN
                               ALTER TABLE dialogs
                               ADD CONSTRAINT fk_dialogs_users
                               FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE;
                            END IF;
                        END $$;
                    """))
                except Exception:
                    log.exception("repair: FK dialogs->users skipped")
                db.commit(); created.append("dialogs"); log.info("repair: created dialogs")

            # 3) MESSAGES
            if not has("messages"):
                db.execute(sa_text("""
                    CREATE TABLE IF NOT EXISTS messages (
                        id         BIGSERIAL PRIMARY KEY,
                        dialog_id  BIGINT NOT NULL,
                        role       VARCHAR(20) NOT NULL,
                        content    TEXT NOT NULL,
                        tokens     INTEGER,
                        created_at TIMESTAMPTZ NOT NULL DEFAULT now()
                    );
                """))
                try:
                    db.execute(sa_text("""
                        DO $$
                        BEGIN
                            IF NOT EXISTS (
                               SELECT 1 FROM pg_constraint WHERE conname = 'fk_messages_dialogs'
                            ) THEN
                               ALTER TABLE messages
                               ADD CONSTRAINT fk_messages_dialogs
                               FOREIGN KEY (dialog_id) REFERENCES dialogs(id) ON DELETE CASCADE;
                            END IF;
                        END $$;
                    """))
                except Exception:
                    log.exception("repair: FK messages->dialogs skipped")
                db.commit(); created.append("messages"); log.info("repair: created messages")

            # --- –ë–ª–æ–∫ –ë–ó: –¥–µ–ª–∞–µ–º best-effort, –∫–∞–∂–¥—ã–π —à–∞–≥ –≤ —Å–≤–æ–µ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ ---

            # 4) KB_DOCUMENTS
            try:
                if not has("kb_documents"):
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS kb_documents (
                            id         BIGSERIAL PRIMARY KEY,
                            path       TEXT UNIQUE NOT NULL,
                            etag       TEXT,
                            mime       TEXT,
                            pages      INTEGER,
                            bytes      BIGINT,
                            updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
                            is_active  BOOLEAN NOT NULL DEFAULT TRUE
                        );
                    """))
                    db.commit(); created.append("kb_documents"); log.info("repair: created kb_documents")
            except Exception:
                db.rollback(); log.exception("repair: create kb_documents failed (–ø—Ä–æ–ø—É—Å–∫–∞—é)")

            # 5) KB_CHUNKS
            try:
                if not has("kb_chunks"):
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS kb_chunks (
                            id           BIGSERIAL PRIMARY KEY,
                            document_id  BIGINT NOT NULL,
                            chunk_index  INTEGER NOT NULL,
                            content      TEXT NOT NULL,
                            meta         JSON,
                            embedding    vector(3072)
                        );
                    """))
                    try:
                        db.execute(sa_text("CREATE INDEX IF NOT EXISTS ix_kb_chunks_document_id ON kb_chunks(document_id);"))
                        db.execute(sa_text("""
                            CREATE INDEX IF NOT EXISTS kb_chunks_embedding_idx
                            ON kb_chunks USING ivfflat (embedding vector_cosine_ops);
                        """))
                    except Exception:
                        log.exception("repair: kb_chunks indexes skipped")
                    try:
                        db.execute(sa_text("""
                            DO $$
                            BEGIN
                                IF NOT EXISTS (
                                   SELECT 1 FROM pg_constraint WHERE conname = 'fk_kb_chunks_docs'
                                ) THEN
                                   ALTER TABLE kb_chunks
                                   ADD CONSTRAINT fk_kb_chunks_docs
                                   FOREIGN KEY (document_id) REFERENCES kb_documents(id) ON DELETE CASCADE;
                                END IF;
                            END $$;
                        """))
                    except Exception:
                        log.exception("repair: FK kb_chunks->kb_documents skipped")
                    db.commit(); created.append("kb_chunks"); log.info("repair: created kb_chunks")
            except Exception:
                db.rollback(); log.exception("repair: create kb_chunks failed (–≤–æ–∑–º–æ–∂–Ω–æ, –Ω–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è vector)")

            # 6) DIALOG_KB_LINKS
            try:
                if not has("dialog_kb_links"):
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS dialog_kb_links (
                            id          BIGSERIAL PRIMARY KEY,
                            dialog_id   BIGINT NOT NULL,
                            document_id BIGINT NOT NULL,
                            created_at  TIMESTAMPTZ NOT NULL DEFAULT now()
                        );
                    """))
                    db.commit(); created.append("dialog_kb_links"); log.info("repair: created dialog_kb_links")
            except Exception:
                db.rollback(); log.exception("repair: create dialog_kb_links failed")

            # 7) PDF_PASSWORDS
            try:
                if not has("pdf_passwords"):
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS pdf_passwords (
                            id          BIGSERIAL PRIMARY KEY,
                            dialog_id   BIGINT NOT NULL,
                            document_id BIGINT NOT NULL,
                            pwd_hash    TEXT,
                            created_at  TIMESTAMPTZ NOT NULL DEFAULT now()
                        );
                    """))
                    db.commit(); created.append("pdf_passwords"); log.info("repair: created pdf_passwords")
            except Exception:
                db.rollback(); log.exception("repair: create pdf_passwords failed")

            # 8) AUDIT_LOG
            try:
                if not has("audit_log"):
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS audit_log (
                            id         BIGSERIAL PRIMARY KEY,
                            user_id    BIGINT,
                            action     TEXT,
                            meta       JSON,
                            created_at TIMESTAMPTZ NOT NULL DEFAULT now()
                        );
                    """))
                    db.commit(); created.append("audit_log"); log.info("repair: created audit_log")
            except Exception:
                db.rollback(); log.exception("repair: create audit_log failed")

        await m.reply_text("‚úÖ –ì–æ—Ç–æ–≤–æ. –°–æ–∑–¥–∞–Ω–æ: " + (", ".join(created) if created else "–Ω–∏—á–µ–≥–æ (–≤—Å—ë —É–∂–µ –±—ã–ª–æ)"))
    except Exception:
        log.exception("repair_schema failed (outer)")
        await m.reply_text("‚ö† –û—à–∏–±–∫–∞ repair_schema. –°–º–æ—Ç—Ä–∏ –ª–æ–≥–∏.")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ç–∞–±–ª–∏—Ü –≤ –ë–î
async def dbcheck(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        with SessionLocal() as db:
            rows = db.execute(sa_text("""
                select 'users' as t, to_regclass('public.users') is not null as ok
                union all select 'dialogs',          to_regclass('public.dialogs') is not null
                union all select 'messages',         to_regclass('public.messages') is not null
                union all select 'kb_documents',     to_regclass('public.kb_documents') is not null
                union all select 'kb_chunks',        to_regclass('public.kb_chunks') is not null
                union all select 'dialog_kb_links',  to_regclass('public.dialog_kb_links') is not null
                union all select 'pdf_passwords',    to_regclass('public.pdf_passwords') is not null
                union all select 'audit_log',        to_regclass('public.audit_log') is not null
            """)).all()
        lines = ["–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∞–±–ª–∏—Ü:"]
        for t, ok in rows:
            lines.append(f"{'‚úÖ' if ok else '‚ùå'} {t}")
        await (update.effective_message or update.message).reply_text("\n".join(lines))
    except Exception:
        log.exception("dbcheck failed")
        await (update.effective_message or update.message).reply_text("‚ö† –û—à–∏–±–∫–∞ dbcheck. –°–º–æ—Ç—Ä–∏ –ª–æ–≥–∏.")

# –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–≥–æ–Ω –º–∏–≥—Ä–∞—Ü–∏–π Alembic (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞)
async def migrate(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        if not _is_admin(update.effective_user.id):
            return await (update.effective_message or update.message).reply_text("–¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞.")
        await (update.effective_message or update.message).reply_text("üîß –ó–∞–ø—É—Å–∫–∞—é –º–∏–≥—Ä–∞—Ü–∏–∏...")
        # –ü—Ä–æ–≥—Ä–∞–º–º–Ω—ã–π –≤—ã–∑–æ–≤ Alembic
        import os
        from alembic.config import Config
        from alembic import command
        os.environ["DATABASE_URL"] = settings.database_url
        cfg = Config("alembic.ini")
        command.upgrade(cfg, "head")
        await (update.effective_message or update.message).reply_text("‚úÖ –ú–∏–≥—Ä–∞—Ü–∏–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã.")
    except Exception:
        log.exception("migrate failed")
        await (update.effective_message or update.message).reply_text("‚ö† –û—à–∏–±–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏. –°–º–æ—Ç—Ä–∏ –ª–æ–≥–∏.")

async def health(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        with SessionLocal() as db:
            db.execute(sa_text("SELECT 1"))
        await update.message.reply_text("‚úÖ OK: DB connection")
    except Exception:
        log.exception("health failed")
        await update.message.reply_text("‚ùå FAIL: DB connection")

async def stats(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        with SessionLocal() as db:
            dialogs = _exec_scalar(db, "SELECT COUNT(*) FROM dialogs") or 0
            messages = _exec_scalar(db, "SELECT COUNT(*) FROM messages") or 0
            docs = _exec_scalar(db, "SELECT COUNT(*) FROM kb_documents WHERE is_active") or 0
        await update.message.reply_text(
            f"–î–∏–∞–ª–æ–≥–æ–≤: {dialogs}\n–°–æ–æ–±—â–µ–Ω–∏–π: {messages}\n–î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –ë–ó: {docs}"
        )
    except Exception:
        log.exception("stats failed")
        await update.message.reply_text("‚ö† –ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")

# ---------- dialogs ----------
async def dialogs(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        tg_id = update.effective_user.id
        with SessionLocal() as db:
            uid = _ensure_user(db, tg_id)
            ds = _exec_all(
                db,
                """
                SELECT id, title
                FROM dialogs
                WHERE user_id=:u AND is_deleted=FALSE
                ORDER BY created_at DESC
                """, u=uid,
            )
        if not ds:
            await update.message.reply_text("–î–∏–∞–ª–æ–≥–æ–≤ –Ω–µ—Ç.")
            return
        rows = []
        for d_id, d_title in ds:
            rows.append([
                InlineKeyboardButton(f"üìÑ {d_title or d_id}", callback_data=f"dlg:open:{d_id}"),
                InlineKeyboardButton("‚úèÔ∏è", callback_data=f"dlg:rename:{d_id}"),
                InlineKeyboardButton("üì§", callback_data=f"dlg:export:{d_id}"),
                InlineKeyboardButton("üóë", callback_data=f"dlg:delete:{d_id}"),
            ])
        await update.message.reply_text("–ú–æ–∏ –¥–∏–∞–ª–æ–≥–∏:", reply_markup=InlineKeyboardMarkup(rows))
    except Exception:
        log.exception("dialogs failed")
        await update.message.reply_text("‚ö† –ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")

async def dialog_cb(update: Update, context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    await q.answer()
    try:
        data = q.data or ""
        if data.startswith("dlg:open:"):
            dlg_id = int(data.split(":")[-1])
            await q.edit_message_text(f"–û—Ç–∫—Ä—ã—Ç –¥–∏–∞–ª–æ–≥ #{dlg_id}")
            return

        if data.startswith("dlg:rename:"):
            dlg_id = int(data.split(":")[-1])
            context.user_data["rename_dialog_id"] = dlg_id
            await q.edit_message_text("–í–≤–µ–¥–∏—Ç–µ –Ω–æ–≤–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞:")
            return

        if data.startswith("dlg:export:"):
            dlg_id = int(data.split(":")[-1])
            with SessionLocal() as db:
                msgs = _exec_all(
                    db,
                    """
                    SELECT role, content, created_at
                    FROM messages
                    WHERE dialog_id=:d
                    ORDER BY created_at
                    """, d=dlg_id,
                )
            lines = ["# –≠–∫—Å–ø–æ—Ä—Ç –¥–∏–∞–ª–æ–≥–∞", ""]
            for role, content, _ in msgs:
                who = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if role == "user" else "–ë–æ—Ç"
                lines.append(f"**{who}:**\n{content}\n")
            data_bytes = "\n".join(lines).encode("utf-8")
            if HAS_BUFFERED:
                file = BufferedInputFile(data_bytes, filename=f"dialog_{dlg_id}.md")  # type: ignore
            else:
                file = InputFile(data_bytes, filename=f"dialog_{dlg_id}.md")  # type: ignore
            await q.message.reply_document(document=file, caption="–≠–∫—Å–ø–æ—Ä—Ç –≥–æ—Ç–æ–≤")
            return

        if data.startswith("dlg:delete:"):
            dlg_id = int(data.split(":")[-1])
            with SessionLocal() as db:
                db.execute(sa_text("UPDATE dialogs SET is_deleted=TRUE WHERE id=:d"), {"d": dlg_id})
                db.commit()
            await q.edit_message_text(f"–î–∏–∞–ª–æ–≥ #{dlg_id} —É–¥–∞–ª—ë–Ω")
            return
    except Exception:
        log.exception("dialog_cb failed")
        try:
            await q.message.reply_text("‚ö† –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ /dialogs. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
        except Exception:
            pass

async def text_router(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if "rename_dialog_id" in context.user_data:
        dlg_id = context.user_data.pop("rename_dialog_id")
        new_title = (update.message.text or "").strip()[:100]
        if not new_title:
            await update.message.reply_text("–ù–∞–∑–≤–∞–Ω–∏–µ –ø—É—Å—Ç–æ–µ. –û—Ç–º–µ–Ω–µ–Ω–æ.")
            return
        try:
            with SessionLocal() as db:
                db.execute(sa_text("UPDATE dialogs SET title=:t WHERE id=:d"), {"t": new_title, "d": dlg_id})
                db.commit()
            await update.message.reply_text("–ù–∞–∑–≤–∞–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ.")
        except Exception:
            log.exception("rename dialog title failed")
            await update.message.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ.")
        return
    await update.message.reply_text("–ü—Ä–∏–Ω—è—Ç–æ. (–¢–µ–∫—Å—Ç–æ–≤—ã–π —Ä–æ—É—Ç–µ—Ä –±—É–¥–µ—Ç –ø–æ–¥–∫–ª—é—á—ë–Ω –∫ RAG –ø–æ—Å–ª–µ —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ UI.)")

# ---------- KB ----------
PAGE_SIZE = 8

def _exec_page_count(total: int) -> int:
    return max(1, (total + PAGE_SIZE - 1) // PAGE_SIZE)

def _kb_keyboard(rows, page, pages, filter_name, admin: bool):
    nav = []
    if page > 1:
        nav.append(InlineKeyboardButton("¬´ –ù–∞–∑–∞–¥", callback_data=f"kb:list:{page-1}:{filter_name}"))
    nav.append(InlineKeyboardButton(f"{page}/{pages}", callback_data="kb:nop"))
    if page < pages:
        nav.append(InlineKeyboardButton("–í–ø–µ—Ä—ë–¥ ¬ª", callback_data=f"kb:list:{page+1}:{filter_name}"))

    filter_row = [
        InlineKeyboardButton(("üîµ " if filter_name == "all" else "") + "–í—Å–µ", callback_data="kb:list:1:all"),
        InlineKeyboardButton(("üîµ " if filter_name == "connected" else "") + "–ü–æ–¥–∫–ª—é—á—ë–Ω–Ω—ã–µ", callback_data="kb:list:1:connected"),
        InlineKeyboardButton(("üîµ " if filter_name == "available" else "") + "–î–æ—Å—Ç—É–ø–Ω—ã–µ", callback_data="kb:list:1:available"),
    ]

    keyboard = []
    keyboard.extend(rows)
    if nav:
        keyboard.append(nav)
    keyboard.append(filter_row)
    if admin:
        keyboard.append([InlineKeyboardButton("üîÑ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è", callback_data="kb:sync")])
    keyboard.append([InlineKeyboardButton("üìÅ –°—Ç–∞—Ç—É—Å –ë–ó", callback_data="kb:status")])
    return InlineKeyboardMarkup(keyboard)

def _kb_fetch(db, user_id: int, page: int, filter_name: str):
    dlg_id = _exec_scalar(
        db,
        """
        SELECT d.id
        FROM dialogs d
        WHERE d.user_id=:u AND d.is_deleted=FALSE
        ORDER BY d.created_at DESC
        LIMIT 1
        """, u=user_id,
    )
    if not dlg_id:
        dlg_id = _ensure_dialog(db, user_id)

    conn_ids = {row[0] for row in _exec_all(db,
        "SELECT document_id FROM dialog_kb_links WHERE dialog_id=:d", d=dlg_id)}

    where = "WHERE is_active"
    params = {}
    if filter_name == "connected":
        if conn_ids:
            where += " AND id = ANY(:ids)"
            params["ids"] = list(conn_ids)
        else:
            return dlg_id, [], 1, 1, conn_ids
    elif filter_name == "available" and conn_ids:
        where += " AND NOT (id = ANY(:ids))"
        params["ids"] = list(conn_ids)

    total = _exec_scalar(db, f"SELECT COUNT(*) FROM kb_documents {where}", **params) or 0
    pages = _exec_page_count(total)
    page = max(1, min(page, pages))

    rows = _exec_all(
        db,
        f"""
        SELECT id, path
        FROM kb_documents
        {where}
        ORDER BY path
        OFFSET :off LIMIT :lim
        """,
        off=(page - 1) * PAGE_SIZE, lim=PAGE_SIZE, **params
    )
    return dlg_id, rows, page, pages, conn_ids

async def kb(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        tg_id = update.effective_user.id
        with SessionLocal() as db:
            uid = _ensure_user(db, tg_id)
            _ensure_dialog(db, uid)
            dlg_id, rows, page, pages, conn_ids = _kb_fetch(db, uid, 1, "all")
        buttons = []
        for d_id, path in rows:
            checked = "‚òë" if d_id in conn_ids else "‚òê"
            fname = path.split("/")[-1]
            buttons.append([InlineKeyboardButton(f"{checked} {fname}", callback_data=f"kb:toggle:{d_id}:{page}:all")])
        kb_markup = _kb_keyboard(buttons, page, pages, "all", admin=_is_admin(tg_id))
        await update.message.reply_text("–ú–µ–Ω—é –ë–ó: –≤—ã–±–µ—Ä–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –∞–∫—Ç–∏–≤–Ω–æ–º—É –¥–∏–∞–ª–æ–≥—É.", reply_markup=kb_markup)
    except Exception:
        log.exception("kb failed")
        await update.message.reply_text("‚ö† –ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")

async def kb_cb(update: Update, context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    await q.answer()
    try:
        data = q.data or ""
        tg_id = update.effective_user.id
        with SessionLocal() as db:
            uid = _ensure_user(db, tg_id)

            if data.startswith("kb:list:"):
                _, _, page, flt = data.split(":", 3)
                dlg_id, rows, page, pages, conn_ids = _kb_fetch(db, uid, int(page), flt)
                buttons = []
                for d_id, path in rows:
                    checked = "‚òë" if d_id in conn_ids else "‚òê"
                    fname = path.split("/")[-1]
                    buttons.append([InlineKeyboardButton(f"{checked} {fname}", callback_data=f"kb:toggle:{d_id}:{page}:{flt}")])
                kb_markup = _kb_keyboard(buttons, page, pages, flt, admin=_is_admin(tg_id))
                await q.edit_message_text("–ú–µ–Ω—é –ë–ó: –≤—ã–±–µ—Ä–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –∞–∫—Ç–∏–≤–Ω–æ–º—É –¥–∏–∞–ª–æ–≥—É.", reply_markup=kb_markup)
                return

            if data.startswith("kb:toggle:"):
                _, _, doc_id, page, flt = data.split(":", 4)
                doc_id = int(doc_id)
                dlg_id = _exec_scalar(db,
                    """
                    SELECT id FROM dialogs WHERE user_id=:u AND is_deleted=FALSE
                    ORDER BY created_at DESC LIMIT 1
                    """, u=uid)
                if not dlg_id:
                    dlg_id = _ensure_dialog(db, uid)

                exist = _exec_scalar(db,
                    "SELECT id FROM dialog_kb_links WHERE dialog_id=:d AND document_id=:doc",
                    d=dlg_id, doc=doc_id)
                if exist:
                    db.execute(sa_text("DELETE FROM dialog_kb_links WHERE id=:i"), {"i": exist})
                else:
                    db.execute(sa_text(
                        "INSERT INTO dialog_kb_links (dialog_id, document_id, created_at) VALUES (:d, :doc, now())"
                    ), {"d": dlg_id, "doc": doc_id})
                db.commit()

                dlg_id, rows, page, pages, conn_ids = _kb_fetch(db, uid, int(page), flt)
                buttons = []
                for d_id, path in rows:
                    checked = "‚òë" if d_id in conn_ids else "‚òê"
                    fname = path.split("/")[-1]
                    buttons.append([InlineKeyboardButton(f"{checked} {fname}", callback_data=f"kb:toggle:{d_id}:{page}:{flt}")])
                kb_markup = _kb_keyboard(buttons, page, pages, flt, admin=_is_admin(tg_id))
                await q.edit_message_text("–ú–µ–Ω—é –ë–ó: –≤—ã–±–µ—Ä–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –∞–∫—Ç–∏–≤–Ω–æ–º—É –¥–∏–∞–ª–æ–≥—É.", reply_markup=kb_markup)
                return

            if data == "kb:status":
                docs = _exec_scalar(db, "SELECT COUNT(*) FROM kb_documents WHERE is_active") or 0
                chunks = _exec_scalar(db, "SELECT COUNT(*) FROM kb_chunks") or 0
                await q.edit_message_text(f"–î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {docs}\n–ß–∞–Ω–∫–æ–≤: {chunks}")
                return

            if data == "kb:sync":
                if not _is_admin(tg_id):
                    await q.edit_message_text("–î–æ—Å—Ç—É–ø –æ–≥—Ä–∞–Ω–∏—á—ë–Ω.")
                else:
                    await q.edit_message_text("–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∞ (–∑–∞–≥–ª—É—à–∫–∞).")
                return

            if data == "kb:nop":
                return
    except Exception:
        log.exception("kb_cb failed")
        try:
            await q.message.reply_text("‚ö† –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ /kb. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
        except Exception:
            pass

# ---------- service ----------
async def reset(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data.clear()
    await update.message.reply_text("–ö–æ–Ω—Ç–µ–∫—Å—Ç —Ç–µ–∫—É—â–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω.")

async def error_handler(update: object, context: ContextTypes.DEFAULT_TYPE):
    log.exception("Unhandled error", exc_info=context.error)
    try:
        if hasattr(update, "message") and update.message:
            await update.message.reply_text("‚ö† –ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
        elif hasattr(update, "callback_query") and update.callback_query:
            await update.callback_query.message.reply_text("‚ö† –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
    except Exception:
        pass

# ---------- build ----------
def build_app() -> Application:
    apply_migrations_if_needed()
    app = ApplicationBuilder().token(settings.telegram_bot_token).build()
    app.add_error_handler(error_handler)
    app.add_handler(CommandHandler("whoami", whoami))
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("dialog", dialog))
    app.add_handler(CommandHandler("mode", mode))
    app.add_handler(CommandHandler("model", model))
    app.add_handler(CommandHandler("revoke", revoke))
    app.add_handler(CommandHandler("grant", grant))
    app.add_handler(CommandHandler("help", help_cmd))
    app.add_handler(CommandHandler("health", health))
    app.add_handler(CommandHandler("stats", stats))
    app.add_handler(CommandHandler("reset", reset))
    app.add_handler(CommandHandler("dialogs", dialogs))
    app.add_handler(CallbackQueryHandler(dialog_cb, pattern=r"^dlg:"))
    app.add_handler(CommandHandler("repair_schema", repair_schema))
    app.add_handler(CommandHandler("dbcheck", dbcheck))
    app.add_handler(CommandHandler("migrate", migrate))
    app.add_handler(CommandHandler("kb", kb))
    app.add_handler(CallbackQueryHandler(kb_cb, pattern=r"^kb:"))
    app.add_handler(CommandHandler("dialog_new", dialog_new))
    app.add_handler(CommandHandler("pgvector_check", pgvector_check))
    app.add_handler(CommandHandler("kb_chunks_create", kb_chunks_create))
    app.add_handler(CommandHandler("kb_chunks_fix", kb_chunks_fix))
    app.add_handler(CommandHandler("kb_chunks_force", kb_chunks_force))
    app.add_handler(CommandHandler("kb_sync", kb_sync))
    app.add_handler(CommandHandler("kb_sync_pdf", kb_sync_pdf))
    app.add_handler(CommandHandler("rag_diag", rag_diag))
    app.add_handler(CommandHandler("rag_selftest", rag_selftest))
    app.add_handler(CommandHandler("kb_pdf_diag", kb_pdf_diag))

    app.add_handler(MessageHandler(filters.VOICE, on_voice))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_text))

    return app
