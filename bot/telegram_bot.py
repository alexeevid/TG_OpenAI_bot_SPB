# bot/telegram_bot.py
from __future__ import annotations

# == –ë–ê–ó–û–í–´–ï –ò–ú–ü–û–†–¢–´ ==
import asyncio
import hashlib
import json
import logging
import os
import re
import sys
import tempfile
from datetime import datetime
from io import BytesIO
from typing import List, Tuple
from urllib.parse import urlparse

import tiktoken
from openai import OpenAI
from sqlalchemy import text as sa_text

# PTB 20.x
try:
    from telegram import (
        Update,
        InlineKeyboardButton,
        InlineKeyboardMarkup,
        BufferedInputFile,
        InputFile,
    )
    HAS_BUFFERED = True
except Exception:  # —Å—Ç–∞—Ä—ã–µ —Å–±–æ—Ä–∫–∏ PTB
    from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, InputFile  # type: ignore
    HAS_BUFFERED = False

from telegram.ext import (
    Application,
    ApplicationBuilder,
    CallbackQueryHandler,
    CommandHandler,
    ContextTypes,
    MessageHandler,
    filters,
)

# == –ù–ê–°–¢–†–û–ô–ö–ò / –ë–î ==
from bot.settings import load_settings
from bot.db.session import SessionLocal  # engine –ø–æ–¥—Ç—è–≥–∏–≤–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ Alembic –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏

log = logging.getLogger(__name__)
settings = load_settings()

# OpenAI –∫–ª–∏–µ–Ω—Ç
_OA = OpenAI(api_key=(getattr(settings, "openai_api_key", None) or getattr(settings, "OPENAI_API_KEY", None)))

# ---------- SINGLETON LOCK (–∏—Å–∫–ª—é—á–∞–µ–º –¥–≤–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö poller-–∞) ----------
import psycopg2

_singleton_conn = None  # –¥–µ—Ä–∂–∏–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∂–∏–≤—ã–º (–¥–µ—Ä–∂–∏—Ç advisory_lock)

def _ensure_single_instance() -> None:
    """–ë–µ—Ä—ë–º pg_advisory_lock –Ω–∞ –ø—Ä–æ—Ü–µ—Å—Å. –ï—Å–ª–∏ –∑–∞–Ω—è—Ç ‚Äî –≤—ã—Ö–æ–¥–∏–º, —á—Ç–æ–±—ã –Ω–µ –ª–æ–≤–∏—Ç—å Conflict –æ—Ç Telegram."""
    global _singleton_conn
    if _singleton_conn is not None:
        return
    dsn = getattr(settings, "database_url", None) or getattr(settings, "DATABASE_URL", None)
    if not dsn:
        log.warning("DATABASE_URL –Ω–µ –∑–∞–¥–∞–Ω ‚Äî singleton-lock –ø—Ä–æ–ø—É—â–µ–Ω (—Ä–∏—Å–∫ Conflict).")
        return
    try:
        key_src = f"{dsn}|{getattr(settings,'telegram_bot_token',None) or getattr(settings,'TELEGRAM_BOT_TOKEN',None)}"
        lock_key = int(hashlib.sha1(key_src.encode("utf-8")).hexdigest()[:15], 16) % (2**31)
        _singleton_conn = psycopg2.connect(dsn)
        _singleton_conn.autocommit = True
        with _singleton_conn.cursor() as cur:
            cur.execute("SELECT pg_try_advisory_lock(%s)", (lock_key,))
            ok = cur.fetchone()[0]
        if not ok:
            log.error("‚ÄºÔ∏è –£–∂–µ –∑–∞–ø—É—â–µ–Ω –¥—Ä—É–≥–æ–π —ç–∫–∑–µ–º–ø–ª—è—Ä –±–æ—Ç–∞ (advisory-lock –∑–∞–Ω—è—Ç). –ó–∞–≤–µ—Ä—à–∞—é—Å—å.")
            sys.exit(0)
        log.info("‚úÖ –ü–æ–ª—É—á–µ–Ω singleton pg_advisory_lock.")
    except Exception:
        log.exception("–ù–µ —É–¥–∞–ª–æ—Å—å –≤–∑—è—Ç—å singleton-lock ‚Äî –ø—Ä–æ–¥–æ–ª–∂–∞—é –±–µ–∑ –Ω–µ–≥–æ (—Ä–∏—Å–∫ Conflict).")

# ---------- post_init: –æ—á–∏—â–∞–µ–º webhook –ø–µ—Ä–µ–¥ polling ----------
async def _post_init(app: "Application"):
    try:
        await app.bot.delete_webhook(drop_pending_updates=True)
        log.info("‚úÖ Webhook —É–¥–∞–ª—ë–Ω –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –æ—á–∏—â–µ–Ω—ã.")
    except Exception:
        log.exception("–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å webhook")

# ---------- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–û–ï ----------
TELEGRAM_CHUNK = 3500

def _split_for_tg(text: str, limit: int = TELEGRAM_CHUNK) -> List[str]:
    out, s = [], (text or "").strip()
    while len(s) > limit:
        cut = s.rfind("\n\n", 0, limit)
        if cut == -1: cut = s.rfind("\n", 0, limit)
        if cut == -1: cut = s.rfind(" ", 0, limit)
        if cut == -1: cut = limit
        out.append(s[:cut].rstrip())
        s = s[cut:].lstrip()
    if s:
        out.append(s)
    return out

async def _send_long(m, text: str):
    for part in _split_for_tg(text):
        await m.reply_text(part)

def _is_admin(tg_id: int) -> bool:
    try:
        raw = getattr(settings, "admin_user_ids", None) or getattr(settings, "ADMIN_USER_IDS", "")
        ids = [int(x.strip()) for x in str(raw).split(",") if x.strip()]
        return tg_id in ids
    except Exception:
        return False

def _ensure_user(db, tg_id: int) -> int:
    uid = db.execute(sa_text("SELECT id FROM users WHERE tg_user_id=:tg"), {"tg": tg_id}).scalar()
    if uid:
        return int(uid)
    uid = db.execute(
        sa_text("INSERT INTO users (tg_user_id, is_admin, is_allowed, lang) VALUES (:tg,FALSE,TRUE,'ru') RETURNING id"),
        {"tg": tg_id},
    ).scalar()
    db.commit()
    return int(uid)

def _create_new_dialog_for_tg(db, tg_id: int) -> int:
    uid = _ensure_user(db, tg_id)
    today = datetime.now().date().isoformat()
    cnt = db.execute(sa_text(
        "SELECT count(*) FROM dialogs WHERE user_id=:u AND is_deleted=FALSE"
    ), {"u": uid}).scalar() or 0
    title = f"{today} | –¥–∏–∞–ª–æ–≥ {cnt+1}"
    did = db.execute(sa_text("""
        INSERT INTO dialogs (user_id, title, style, model, is_deleted, created_at)
        VALUES (:u, :t, 'pro', :m, FALSE, now()) RETURNING id
    """), {"u": uid, "t": title, "m": (getattr(settings,"openai_model",None) or getattr(settings,"OPENAI_MODEL","gpt-4o-mini"))}).scalar()
    db.commit()
    return int(did)

def _get_active_dialog_id(db, tg_id: int) -> int | None:
    row = db.execute(sa_text("""
        SELECT d.id
        FROM dialogs d
        JOIN users u ON u.id = d.user_id
        WHERE u.tg_user_id=:tg AND d.is_deleted=FALSE
        ORDER BY COALESCE(d.last_message_at, to_timestamp(0)) DESC,
                 d.created_at DESC, d.id DESC
        LIMIT 1
    """), {"tg": tg_id}).first()
    return int(row[0]) if row else None

def _save_message(db, dialog_id: int, role: str, content: str):
    enc = tiktoken.get_encoding("cl100k_base")
    toks = len(enc.encode(content or ""))
    db.execute(sa_text("""
        INSERT INTO messages (dialog_id, role, content, tokens)
        VALUES (:d,:r,:c,:t)
    """), {"d": dialog_id, "r": role, "c": content, "t": toks})
    # –û–±–Ω–æ–≤–∏–º last_message_at
    db.execute(sa_text("UPDATE dialogs SET last_message_at=now() WHERE id=:d"), {"d": dialog_id})
    db.commit()

# ---------- OpenAI / RAG ----------
def _get_embedding_model() -> str:
    return getattr(settings, "embedding_model", None) or getattr(settings, "OPENAI_EMBEDDING_MODEL", None) or "text-embedding-3-large"

def _embed_query(text: str) -> List[float]:
    resp = _OA.embeddings.create(model=_get_embedding_model(), input=[text])
    return resp.data[0].embedding

def _kb_embedding_column_kind(db) -> str:
    try:
        t = db.execute(sa_text("SELECT pg_typeof(embedding)::text FROM kb_chunks LIMIT 1")).scalar()
        if t:
            t = str(t).lower()
            if "vector" in t: return "vector"
            if "bytea"  in t: return "bytea"
        t = db.execute(sa_text("""
            SELECT COALESCE(udt_name, data_type)
            FROM information_schema.columns
            WHERE table_name='kb_chunks' AND column_name='embedding'
            LIMIT 1
        """)).scalar()
        t = (t or "").lower()
        if "vector" in t: return "vector"
        if "bytea"  in t: return "bytea"
    except Exception:
        pass
    return "none"

def _vec_literal(vec: List[float]) -> tuple[dict, str]:
    arr = "[" + ","join(f"{x:.6f}" for x in (vec or [])) + "]"  # noqa
    # –û–®–ò–ë–ö–ê ‚Üë: –∏—Å–ø—Ä–∞–≤–∏–º –Ω–∏–∂–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π
    return {"q": arr}, "CAST(:q AS vector)"

# –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è (–æ—Å—Ç–∞–≤–ª—è–µ–º –æ–±–µ, –Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—É—é)
def _vec_literal_fixed(vec: List[float]) -> tuple[dict, str]:
    arr = "[" + ",".join(f"{x:.6f}" for x in (vec or [])) + "]"
    return {"q": arr}, "CAST(:q AS vector)"

def _retrieve_chunks(db, dialog_id: int, question: str, k: int = 6) -> List[dict]:
    if _kb_embedding_column_kind(db) != "vector":
        return []
    q = _embed_query(question)
    params, qexpr = _vec_literal_fixed(q)
    rows = db.execute(sa_text(f"""
        SELECT c.content, c.meta, d.path
        FROM kb_chunks c
        JOIN kb_documents d    ON d.id=c.document_id AND d.is_active
        JOIN dialog_kb_links l ON l.document_id=d.id
        WHERE l.dialog_id=:did
        ORDER BY c.embedding <=> {qexpr}
        LIMIT :k
    """), dict(params, did=dialog_id, k=k)).mappings().all()
    return [dict(r) for r in rows]

_STYLE_EXAMPLES = {
    "pro":    "–ö—Ä–∞—Ç–∫–æ, –ø–æ —à–∞–≥–∞–º, —á–µ–∫-–ª–∏—Å—Ç. –ë–µ–∑ –≤–æ–¥—ã.",
    "expert": "–ì–ª—É–±–æ–∫–æ –∏ –æ–±—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ: –ø—Ä–∏—á–∏–Ω—ã/—Å–ª–µ–¥—Å—Ç–≤–∏—è, –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã, —Å—Å—ã–ª–∫–∏.",
    "user":   "–ü—Ä–æ—Å—Ç–æ, —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∏–∑ –∂–∏–∑–Ω–∏, –±–µ–∑ –∂–∞—Ä–≥–æ–Ω–∞.",
    "ceo":    "–§–æ–∫—É—Å –Ω–∞ —Ü–µ–Ω–Ω–æ—Å—Ç–∏, —Ä–∏—Å–∫–∞—Ö, —Å—Ä–æ–∫–∞—Ö, ROI –∏ —Ä–µ—à–µ–Ω–∏—è—Ö.",
}

def _build_prompt_with_style(ctx_blocks: List[str], user_q: str, dialog_style: str) -> str:
    style_map = {
        "pro":   "–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —ë–º–∫–æ –∏ –ø–æ –¥–µ–ª—É, —à–∞–≥–∏ –∏ —á–µ–∫-–ª–∏—Å—Ç.",
        "expert":"–≠–∫—Å–ø–µ—Ä—Ç: –ø–æ–¥—Ä–æ–±–Ω–æ, –ø—Ä–∏—á–∏–Ω—ã/—Å–ª–µ–¥—Å—Ç–≤–∏—è, –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã, –≤—ã–≤–æ–¥—ã. –¶–∏—Ç–∞—Ç—ã ‚Äî –≤ –∫–æ–Ω—Ü–µ.",
        "user":  "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏, –ø—Ä–∏–º–µ—Ä—ã –∏ –∞–Ω–∞–ª–æ–≥–∏–∏.",
        "ceo":   "CEO: –±–∏–∑–Ω–µ—Å-—Ü–µ–Ω–Ω–æ—Å—Ç—å, ROI, —Ä–∏—Å–∫–∏, —Å—Ä–æ–∫–∏, –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏ trade-offs.",
    }
    style_line = style_map.get((dialog_style or "pro").lower(), style_map["pro"])
    header = (
        "–¢—ã ‚Äî –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –ë–ó, –Ω–æ –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–π—Å—è —Ü–∏—Ç–∞—Ç–∞–º–∏: "
        "—Å–∏–Ω—Ç–µ–∑–∏—Ä—É–π —Ü–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —Å—Ç–∏–ª–µ. –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–µ—Ç ‚Äî —É—Ç–æ—á–Ω–∏."
    )
    ctx = "\n\n".join([f"[–§—Ä–∞–≥–º–µ–Ω—Ç #{i+1}]\n{t}" for i, t in enumerate(ctx_blocks)])
    return f"{header}\n–°—Ç–∏–ª—å: {style_line}\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{ctx}\n\n–í–æ–ø—Ä–æ—Å: {user_q}"

def _format_citations(chunks: List[dict]) -> str:
    def short(p: str) -> str:
        return (p or "").split("/")[-1].split("?")[0]
    uniq = []
    for r in chunks:
        name = short(r.get("path") or (r.get("meta") or {}).get("path", ""))
        if name and name not in uniq:
            uniq.append(name)
    return ("\n\n–ò—Å—Ç–æ—á–Ω–∏–∫–∏: " + "; ".join(f"[{i+1}] {n}" for i, n in enumerate(uniq[:5]))) if uniq else ""

async def _chat_full(model: str, messages: list, temperature: float = 0.3, max_turns: int = 6) -> str:
    hist = list(messages)
    full = ""
    turns = 0
    while turns < max_turns:
        turns += 1
        resp = _OA.chat.completions.create(
            model=model,
            messages=hist,
            temperature=temperature,
            max_tokens=1024,
        )
        choice = resp.choices[0]
        piece = choice.message.content or ""
        full += piece
        if choice.finish_reason != "length":
            break
        hist.append({"role": "assistant", "content": piece})
        hist.append({"role": "user", "content": "–ü—Ä–æ–¥–æ–ª–∂–∞–π —Å —Ç–æ–≥–æ –º–µ—Å—Ç–∞. –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π—Å—è."})
    return full

# ---------- –ö–û–ú–ê–ù–î–´ ----------
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    await m.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! –Ø –ø–æ–º–æ–≥—É –∏—Å–∫–∞—Ç—å –æ—Ç–≤–µ—Ç—ã –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –∏–∑ –ë–ó –∏ –≤–µ—Å—Ç–∏ –¥–∏–∞–ª–æ–≥–∏ –≤ —Ä–∞–∑–Ω—ã—Ö —Å—Ç–∏–ª—è—Ö.\n"
        "–ü–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥ ‚Äî /help"
    )

async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    await m.reply_text(
        "/start ‚Äî –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ\n"
        "/help ‚Äî —Å–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥\n"
        "/dialogs ‚Äî —Å–ø–∏—Å–æ–∫ –¥–∏–∞–ª–æ–≥–æ–≤ (–æ—Ç–∫—Ä—ã—Ç—å/–ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å/—ç–∫—Å–ø–æ—Ä—Ç/—É–¥–∞–ª–∏—Ç—å)\n"
        "/dialog <id> ‚Äî —Å–¥–µ–ª–∞—Ç—å –¥–∏–∞–ª–æ–≥ –∞–∫—Ç–∏–≤–Ω—ã–º\n"
        "/dialog_new ‚Äî —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥\n"
        "/kb ‚Äî –º–µ–Ω—é –ë–ó (–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ/–æ—Ç–∫–ª—é—á–µ–Ω–∏–µ –¥–æ–∫–æ–≤)\n"
        "/kb_sync ‚Äî —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ë–ó (–∞–¥–º–∏–Ω)\n"
        "/kb_diag ‚Äî –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ë–ó\n"
        "/stats ‚Äî –∫–∞—Ä—Ç–æ—á–∫–∞ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞\n"
        "/web <–∑–∞–ø—Ä–æ—Å> ‚Äî –≤–µ–±-–ø–æ–∏—Å–∫ (–µ—Å–ª–∏ –≤–∫–ª—é—á—ë–Ω)\n"
        "/repair_schema ‚Äî –ø–æ—á–∏–Ω–∫–∞ —Å—Ö–µ–º—ã –ë–î (–∞–¥–º–∏–Ω)\n"
        "/dbcheck ‚Äî –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ç–∞–±–ª–∏—Ü\n"
        "/migrate ‚Äî –ø—Ä–∏–º–µ–Ω–∏—Ç—å Alembic –º–∏–≥—Ä–∞—Ü–∏–∏ (–∞–¥–º–∏–Ω)\n"
        "/pgvector_check ‚Äî –Ω–∞–ª–∏—á–∏–µ/—É—Å—Ç–∞–Ω–æ–≤–∫–∞ pgvector\n"
        "/whoami ‚Äî –º–æ–∏ –ø—Ä–∞–≤–∞\n"
    )

async def whoami(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        tg = update.effective_user.id
        with SessionLocal() as db:
            row = db.execute(sa_text("SELECT is_admin, is_allowed, lang FROM users WHERE tg_user_id=:tg"), {"tg": tg}).first()
        is_admin = bool(row[0]) if row else False
        is_allowed = bool(row[1]) if row else True
        lang = (row[2] or "ru") if row else "ru"
        await (update.message or update.effective_message).reply_text(
            f"whoami: tg={tg}, role={'admin' if is_admin else ('allowed' if is_allowed else 'guest')}, lang={lang}"
        )
    except Exception:
        log.exception("whoami failed")
        await (update.message or update.effective_message).reply_text("‚ö† –û—à–∏–±–∫–∞ whoami")

# ---- –î–∏–∞–ª–æ–≥–∏: —Å–ø–∏—Å–æ–∫/–Ω–æ–≤—ã–π/–ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ/—ç–∫—Å–ø–æ—Ä—Ç/–ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ ----
KB_PAGE_SIZE = 10

async def dialogs(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    page = int((context.user_data.get("dlg_page") or 1))
    try:
        with SessionLocal() as db:
            uid = _ensure_user(db, update.effective_user.id)
            total = db.execute(sa_text("SELECT count(*) FROM dialogs WHERE user_id=:u AND is_deleted=FALSE"), {"u": uid}).scalar() or 0
            if total == 0:
                kb = InlineKeyboardMarkup([[InlineKeyboardButton("‚ûï –ù–æ–≤—ã–π –¥–∏–∞–ª–æ–≥", callback_data="dlg:new")]])
                return await m.reply_text("–î–∏–∞–ª–æ–≥–æ–≤ –Ω–µ—Ç.", reply_markup=kb)

            pages = max(1, (total + KB_PAGE_SIZE - 1) // KB_PAGE_SIZE)
            page = max(1, min(page, pages))
            offset = (page - 1) * KB_PAGE_SIZE

            rows = db.execute(sa_text("""
                SELECT id, title, model, style, created_at, last_message_at
                FROM dialogs
                WHERE user_id=:u AND is_deleted=FALSE
                ORDER BY COALESCE(last_message_at, created_at) DESC
                LIMIT :lim OFFSET :off
            """), {"u": uid, "lim": KB_PAGE_SIZE, "off": offset}).all()

        buttons = []
        for (did, title, model, style, created_at, last_msg) in rows:
            label = f"{did} | {title or '(–±–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è)'}"
            buttons.append([
                InlineKeyboardButton(label, callback_data=f"dlg:open:{did}"),
                InlineKeyboardButton("‚úèÔ∏è", callback_data=f"dlg:rename:{did}"),
                InlineKeyboardButton("üì§", callback_data=f"dlg:export:{did}"),
                InlineKeyboardButton("üóëÔ∏è", callback_data=f"dlg:delete:{did}"),
            ])

        nav = []
        if pages > 1:
            if page > 1:
                nav.append(InlineKeyboardButton("¬´ –ù–∞–∑–∞–¥", callback_data=f"dlg:page:{page-1}"))
            nav.append(InlineKeyboardButton(f"{page}/{pages}", callback_data="dlg:nop"))
            if page < pages:
                nav.append(InlineKeyboardButton("–í–ø–µ—Ä—ë–¥ ¬ª", callback_data=f"dlg:page:{page+1}"))

        foot = [InlineKeyboardButton("‚ûï –ù–æ–≤—ã–π –¥–∏–∞–ª–æ–≥", callback_data="dlg:new")]
        kb = InlineKeyboardMarkup(buttons + ([nav] if nav else []) + [[b] for b in [foot]])

        await m.reply_text("–ú–æ–∏ –¥–∏–∞–ª–æ–≥–∏:", reply_markup=kb)
    except Exception:
        log.exception("dialogs failed")
        await m.reply_text("‚ö† –û—à–∏–±–∫–∞ /dialogs")

async def dialog_cb(update: Update, context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    await q.answer()
    try:
        data = q.data or ""
        if data == "dlg:nop":
            return
        if data.startswith("dlg:page:"):
            page = int(data.split(":")[-1])
            context.user_data["dlg_page"] = page
            await q.message.delete()
            return await dialogs(update, context)
        if data == "dlg:new":
            with SessionLocal() as db:
                did = _create_new_dialog_for_tg(db, update.effective_user.id)
            return await q.edit_message_text(f"‚úÖ –°–æ–∑–¥–∞–Ω –¥–∏–∞–ª–æ–≥ #{did}")
        if data.startswith("dlg:open:"):
            did = int(data.split(":")[-1])
            # –∞–∫—Ç–∏–≤–∏—Ä—É–µ–º –¥–∏–∞–ª–æ–≥ –≤ user_data
            context.user_data["active_dialog_id"] = did
            return await q.edit_message_text(f"–û—Ç–∫—Ä—ã—Ç –¥–∏–∞–ª–æ–≥ #{did}")
        if data.startswith("dlg:rename:"):
            did = int(data.split(":")[-1])
            context.user_data["rename_dialog_id"] = did
            return await q.edit_message_text("–í–≤–µ–¥–∏—Ç–µ –Ω–æ–≤–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞:")
        if data.startswith("dlg:export:"):
            did = int(data.split(":")[-1])
            with SessionLocal() as db:
                msgs = db.execute(sa_text("""
                    SELECT role, content, created_at
                    FROM messages
                    WHERE dialog_id=:d ORDER BY created_at
                """), {"d": did}).all()
            lines = ["# –≠–∫—Å–ø–æ—Ä—Ç –¥–∏–∞–ª–æ–≥–∞", ""]
            for role, content, _ in msgs:
                who = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if role == "user" else "–ë–æ—Ç"
                lines.append(f"**{who}:**\n{content}\n")
            data_bytes = "\n".join(lines).encode("utf-8")
            file = BufferedInputFile(data_bytes, filename=f"dialog_{did}.md") if HAS_BUFFERED else InputFile(data_bytes, filename=f"dialog_{did}.md")  # type: ignore
            await q.message.reply_document(document=file, caption="–≠–∫—Å–ø–æ—Ä—Ç –≥–æ—Ç–æ–≤")
            return
        if data.startswith("dlg:delete:"):
            did = int(data.split(":")[-1])
            with SessionLocal() as db:
                db.execute(sa_text("UPDATE dialogs SET is_deleted=TRUE WHERE id=:d"), {"d": did})
                db.commit()
            return await q.edit_message_text(f"–î–∏–∞–ª–æ–≥ #{did} —É–¥–∞–ª—ë–Ω")
    except Exception:
        log.exception("dialog_cb failed")
        try:
            await q.message.reply_text("‚ö† –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ /dialogs.")
        except Exception:
            pass

async def dialog_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    args = context.args or []
    if not args:
        return await dialogs(update, context)
    try:
        did = int(args[0])
    except Exception:
        return await m.reply_text("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /dialog <id>")
    # –ø—Ä–æ—Å—Ç–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ user_data
    context.user_data["active_dialog_id"] = did
    await m.reply_text(f"‚úÖ –ê–∫—Ç–∏–≤–Ω—ã–π –¥–∏–∞–ª–æ–≥: {did}")
    return await stats(update, context)

async def dialog_new(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        with SessionLocal() as db:
            did = _create_new_dialog_for_tg(db, update.effective_user.id)
        await m.reply_text(f"‚úÖ –°–æ–∑–¥–∞–Ω –¥–∏–∞–ª–æ–≥ #{did}")
    except Exception:
        log.exception("dialog_new failed")
        await m.reply_text("‚ö† –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞")

# ---- KB / SYNC / DIAG ----
def ya_download(path: str) -> bytes:
    import requests
    YA_API = "https://cloud-api.yandex.net/v1/disk"
    headers = {"Authorization": f"OAuth {getattr(settings,'yandex_disk_token',None) or getattr(settings,'YANDEX_DISK_TOKEN','')}"}
    r = requests.get(f"{YA_API}/resources/download", headers=headers, params={"path": path}, timeout=60)
    r.raise_for_status()
    href = (r.json() or {}).get("href")
    if not href:
        raise RuntimeError("download href not returned by Yandex Disk")
    f = requests.get(href, timeout=300)
    f.raise_for_status()
    return f.content

def _ya_list_files(root_path: str):
    import requests
    YA_API = "https://cloud-api.yandex.net/v1/disk"
    headers = {"Authorization": f"OAuth {getattr(settings,'yandex_disk_token',None) or getattr(settings,'YANDEX_DISK_TOKEN','')}"}
    out = []
    limit, offset = 200, 0
    while True:
        r = requests.get(
            f"{YA_API}/resources",
            headers=headers,
            params={
                "path": root_path,
                "limit": limit,
                "offset": offset,
                "fields": "_embedded.items.name,_embedded.items.path,_embedded.items.type,_embedded.items.mime_type,_embedded.items.size,_embedded.items.md5",
            },
            timeout=30,
        )
        r.raise_for_status()
        items = (r.json().get("_embedded") or {}).get("items") or []
        for it in items:
            if it.get("type") == "file":
                out.append(it)
        if len(items) < limit:
            break
        offset += limit
    return out

def _pdf_extract_text(pdf_bytes: bytes) -> tuple[str, int, bool]:
    import fitz  # PyMuPDF
    with fitz.open(stream=pdf_bytes, filetype="pdf") as doc:
        is_prot = bool(doc.is_encrypted)
        if is_prot:
            try:
                if doc.authenticate(""):
                    is_prot = False
            except Exception:
                pass
        if is_prot:
            return ("", 0, True)
        pages = doc.page_count
        out = []
        for i in range(pages):
            try:
                out.append(doc.load_page(i).get_text("text") or "")
            except Exception:
                out.append("")
        txt = "\n".join(out)
    # fallback pdfminer –µ—Å–ª–∏ –ø—É—Å—Ç–æ
    if not txt.strip():
        try:
            from pdfminer.high_level import extract_text
            txt = extract_text(BytesIO(pdf_bytes)) or ""
        except Exception:
            pass
    return (txt, pages, False)

def _chunk_text(text: str, max_tokens: int = 2000, overlap: int = 0) -> List[str]:
    enc = tiktoken.get_encoding("cl100k_base")
    toks = enc.encode(text or "")
    out = []
    i = 0
    while i < len(toks):
        part = enc.decode(toks[i:i+max_tokens]).strip()
        if part:
            out.append(part)
        i = i + max_tokens if overlap <= 0 else i + max_tokens - overlap
    return out

async def kb_sync(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    if not _is_admin(update.effective_user.id):
        return await m.reply_text("‚õî –î–æ—Å—Ç—É–ø —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∞–º.")
    await m.reply_text("üîÑ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–ø—É—â–µ–Ω–∞...")
    try:
        # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ entrypoint –≤ bot/knowledge_base/indexer.py
        import inspect
        from bot.knowledge_base import indexer
        entry = getattr(settings, "kb_sync_entrypoint", None) or os.getenv("KB_SYNC_ENTRYPOINT", None)
        fn = getattr(indexer, entry, None) if entry else None
        if not fn:
            for cand in ("sync_kb","sync_all","sync_from_yandex","sync","run_sync","full_sync","reindex","index_all","ingest_all","ingest","main"):
                if hasattr(indexer, cand) and callable(getattr(indexer, cand)):
                    fn = getattr(indexer, cand); break
        if not fn:
            raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω entrypoint –≤ indexer.py. –£–∫–∞–∂–∏—Ç–µ KB_SYNC_ENTRYPOINT –∏–ª–∏ —Ä–µ–∞–ª–∏–∑—É–π—Ç–µ sync_kb(session).")

        sig = inspect.signature(fn)
        kwargs, to_close = {}, None
        for p in sig.parameters.values():
            nm = p.name.lower()
            if nm in ("session","db","dbsession","conn","connection"):
                sess = SessionLocal(); kwargs[p.name] = sess; to_close = sess
            elif nm in ("sessionlocal","session_factory","factory","engine"):
                kwargs[p.name] = SessionLocal
            elif nm in ("settings","cfg","config","conf"):
                kwargs[p.name] = settings

        def _call():
            try: return fn(**kwargs)
            finally:
                if to_close is not None:
                    try: to_close.close()
                    except Exception: pass

        res = await asyncio.to_thread(_call)
        return await m.reply_text("‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞." if res is None else f"‚úÖ –ì–æ—Ç–æ–≤–æ: {res}")
    except Exception as e:
        log.exception("kb_sync failed")
        return await m.reply_text(f"‚ö† –û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}")

async def kb_diag(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        with SessionLocal() as db:
            docs = db.execute(sa_text("SELECT count(*) FROM kb_documents WHERE is_active")).scalar() or 0
            chunks = db.execute(sa_text("SELECT count(*) FROM kb_chunks")).scalar() or 0
            links = db.execute(sa_text("SELECT count(*) FROM dialog_kb_links")).scalar() or 0
        await m.reply_text(f"–ë–ó: –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∞–∫—Ç–∏–≤–Ω—ã—Ö ‚Äî {docs}, —á–∞–Ω–∫–æ–≤ ‚Äî {chunks}, –ø—Ä–∏–≤—è–∑–æ–∫ –∫ –¥–∏–∞–ª–æ–≥–∞–º ‚Äî {links}")
    except Exception:
        log.exception("kb_diag failed")
        await m.reply_text("‚ö† –û—à–∏–±–∫–∞ kb_diag")

async def kb_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü—Ä–æ—Å—Ç–µ–π—à–µ–µ –º–µ–Ω—é –ë–ó. (–ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ UI –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –º–æ–¥—É–ª–µ.)"""
    m = update.effective_message or update.message
    kb = InlineKeyboardMarkup([
        [InlineKeyboardButton("üîÑ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è", callback_data="kb:sync")],
        [InlineKeyboardButton("üìä –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞", callback_data="kb:diag")],
    ])
    await m.reply_text("–ú–µ–Ω—é –ë–ó:", reply_markup=kb)

async def kb_cb(update: Update, context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    await q.answer()
    data = q.data or ""
    if data == "kb:sync":
        await q.edit_message_text("üîÑ –°—Ç–∞—Ä—Ç—É—é —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é –ë–ó‚Ä¶")
        return await kb_sync(update, context)
    if data == "kb:diag":
        await kb_diag(update, context)
        try:
            await q.delete_message()
        except Exception:
            pass
        return

# ---- WEB ----
async def web_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    parts = (m.text or "").split(maxsplit=1)
    if len(parts) < 2:
        return await m.reply_text("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /web <–∑–∞–ø—Ä–æ—Å>")
    query = parts[1].strip()
    await m.reply_text(
        "üîé –í–µ–±-–ø–æ–∏—Å–∫ –ø–æ–∫–∞ –æ—Ç–∫–ª—é—á—ë–Ω –≤ —ç—Ç–æ–π —Å–±–æ—Ä–∫–µ (–∫–ª—é—á–∏ –≤–Ω–µ—à–Ω–µ–≥–æ –ø–æ–∏—Å–∫–∞ –Ω–µ –∑–∞–¥–∞–Ω—ã).\n"
        "–Ø –º–æ–≥—É –æ—Ç–≤–µ—Ç–∏—Ç—å —Å–≤–æ–∏–º–∏ –∑–Ω–∞–Ω–∏—è–º–∏ –∏–ª–∏ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –Ω–∞–π—Ç–∏ –≤ –ë–ó —á–µ—Ä–µ–∑ /kb."
    )

# ---- –°–¢–ê–¢–ò–°–¢–ò–ö–ê ----
async def stats(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        with SessionLocal() as db:
            did = context.user_data.get("active_dialog_id") or _get_active_dialog_id(db, update.effective_user.id)
            if not did:
                return await m.reply_text("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞. –°–æ–∑–¥–∞–π—Ç–µ —á–µ—Ä–µ–∑ /dialog_new –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ /dialogs.")
            row = db.execute(sa_text(
                "SELECT id, title, model, style, created_at, last_message_at FROM dialogs WHERE id=:d"
            ), {"d": did}).first()
            msgs = db.execute(sa_text("SELECT count(*) FROM messages WHERE dialog_id=:d"), {"d": did}).scalar() or 0
            docs = db.execute(sa_text("""
                SELECT d.path
                FROM kb_documents d
                JOIN dialog_kb_links l ON l.document_id=d.id
                WHERE l.dialog_id=:d ORDER BY d.path
            """), {"d": did}).fetchall()
            total_dialogs = db.execute(sa_text("""
                SELECT count(*) FROM dialogs WHERE user_id=(
                    SELECT id FROM users WHERE tg_user_id=:tg LIMIT 1
                ) AND is_deleted=FALSE
            """), {"tg": update.effective_user.id}).scalar() or 0

        title = row[1] if row else "-"
        model = row[2] if row else (getattr(settings,"openai_model",None) or "gpt-4o-mini")
        style = row[3] if row else "pro"
        created = row[4] if row else "-"
        changed = row[5] if row else "-"

        doc_list = "\n".join(f"‚Ä¢ {r[0]}" for r in docs) or "‚Äî"

        text = (
            f"–î–∏–∞–ª–æ–≥: {did} ‚Äî {title}\n"
            f"–ú–æ–¥–µ–ª—å: {model} | –°—Ç–∏–ª—å: {style}\n"
            f"–°–æ–∑–¥–∞–Ω: {created or '-'} | –ò–∑–º–µ–Ω—ë–Ω: {changed or '-'}\n"
            f"–ü–æ–¥–∫–ª—é—á—ë–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã ({len(docs)}):\n{doc_list}\n\n"
            f"–í—Å–µ–≥–æ —Ç–≤–æ–∏—Ö –¥–∏–∞–ª–æ–≥–æ–≤: {int(total_dialogs)} | –°–æ–æ–±—â–µ–Ω–∏–π –≤ —ç—Ç–æ–º –¥–∏–∞–ª–æ–≥–µ: {int(msgs)}"
        )
        return await m.reply_text(text)
    except Exception:
        log.exception("/stats failed")
        return await m.reply_text("‚ö† –û—à–∏–±–∫–∞ /stats")

# ---- –¢–ï–ö–°–¢ / –ì–û–õ–û–° ----
async def on_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    text = (m.text or "").strip()
    if not text:
        return
    try:
        with SessionLocal() as db:
            tg = update.effective_user.id
            uid = _ensure_user(db, tg)
            did = context.user_data.get("active_dialog_id") or _get_active_dialog_id(db, tg) or _create_new_dialog_for_tg(db, tg)

            # —É–∑–Ω–∞—ë–º –º–æ–¥–µ–ª—å/—Å—Ç–∏–ª—å –∏–∑ –¥–∏–∞–ª–æ–≥–∞
            row = db.execute(sa_text("SELECT model, style FROM dialogs WHERE id=:d"), {"d": did}).first()
            model = (row[0] if row and row[0] else (getattr(settings,"openai_model",None) or "gpt-4o-mini"))
            style = (row[1] if row and row[1] else "pro")

            # —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            _save_message(db, did, "user", text)

            # RAG: –¥–æ—Å—Ç–∞—ë–º —á–∞–Ω–∫–∏
            top_k = int(getattr(settings,"kb_top_k",None) or getattr(settings,"KB_TOP_K",5))
            rows = _retrieve_chunks(db, did, text, k=top_k)

        ctx_blocks = [r["content"] for r in rows]
        prompt = _build_prompt_with_style(ctx_blocks, text, style)
        messages = [{"role":"system","content":"RAG assistant"}, {"role":"user","content":prompt}]

        answer = await _chat_full(model, messages, temperature=0.3, max_turns=6)
        cites = _format_citations(rows)
        final = answer + (cites if cites else "")

        await _send_long(m, final)

        # —Å–æ—Ö—Ä–∞–Ω–∏–º –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        with SessionLocal() as db:
            _save_message(db, did, "assistant", final)

    except Exception:
        log.exception("on_text failed")
        await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")

async def on_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ì–æ–ª–æ—Å ‚Üí Whisper ‚Üí –∫–∞–∫ on_text –≤ –∞–∫—Ç–∏–≤–Ω–æ–º –¥–∏–∞–ª–æ–≥–µ."""
    m = update.effective_message or update.message
    voice = m.voice or m.audio
    if not voice:
        return await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
    try:
        file = await context.bot.get_file(voice.file_id)
        tmpdir = tempfile.mkdtemp(prefix="tg_voice_")
        ogg_path = os.path.join(tmpdir, "voice.ogg")  # –≤–∞–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        await file.download_to_drive(ogg_path)

        transcribe_model = getattr(settings, "openai_transcribe_model", None) or getattr(settings, "OPENAI_TRANSCRIBE_MODEL", "whisper-1")
        with open(ogg_path, "rb") as f:
            tr = _OA.audio.transcriptions.create(model=transcribe_model, file=f)
        recognized = (getattr(tr, "text", None) or (tr.get("text") if isinstance(tr, dict) else None) or "").strip()
        if not recognized:
            return await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –°–∫–∞–∂–∏—Ç–µ –µ—â—ë —Ä–∞–∑, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞.")

        # –ø—Ä–æ–∫–∏–Ω–µ–º –≤ on_text
        update.effective_message.text = recognized
        return await on_text(update, context)

    except Exception:
        log.exception("on_voice failed")
        return await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")

# ---- –°–ï–†–í–ò–°–ù–´–ï ----
async def dbcheck(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        with SessionLocal() as db:
            rows = db.execute(sa_text("""
                select 'users' as t, to_regclass('public.users') is not null
                union all select 'dialogs',          to_regclass('public.dialogs') is not null
                union all select 'messages',         to_regclass('public.messages') is not null
                union all select 'kb_documents',     to_regclass('public.kb_documents') is not null
                union all select 'kb_chunks',        to_regclass('public.kb_chunks') is not null
                union all select 'dialog_kb_links',  to_regclass('public.dialog_kb_links') is not null
                union all select 'pdf_passwords',    to_regclass('public.pdf_passwords') is not null
                union all select 'audit_log',        to_regclass('public.audit_log') is not null
            """)).all()
        lines = ["–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∞–±–ª–∏—Ü:"]
        for t, ok in rows:
            lines.append(f"{'‚úÖ' if ok else '‚ùå'} {t}")
        await (update.effective_message or update.message).reply_text("\n".join(lines))
    except Exception:
        log.exception("dbcheck failed")
        await (update.effective_message or update.message).reply_text("‚ö† –û—à–∏–±–∫–∞ dbcheck")

async def migrate(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        if not _is_admin(update.effective_user.id):
            return await (update.effective_message or update.message).reply_text("–¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞.")
        await (update.effective_message or update.message).reply_text("üîß –ó–∞–ø—É—Å–∫–∞—é –º–∏–≥—Ä–∞—Ü–∏–∏...")
        from alembic.config import Config
        from alembic import command
        os.environ["DATABASE_URL"] = getattr(settings,"database_url",None) or getattr(settings,"DATABASE_URL","")
        cfg = Config("alembic.ini")
        command.upgrade(cfg, "head")
        await (update.effective_message or update.message).reply_text("‚úÖ –ú–∏–≥—Ä–∞—Ü–∏–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã.")
    except Exception:
        log.exception("migrate failed")
        await (update.effective_message or update.message).reply_text("‚ö† –û—à–∏–±–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏.")

async def repair_schema(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        if not _is_admin(update.effective_user.id):
            return await m.reply_text("–¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞.")
        await m.reply_text("üß∞ –†–µ–º–æ–Ω—Ç —Å—Ö–µ–º—ã –Ω–∞—á–∞—Ç...")
        created = []
        with SessionLocal() as db:
            def has(table: str) -> bool:
                return bool(db.execute(sa_text("SELECT to_regclass(:t)"), {"t": f"public.{table}"}).scalar())

            # –ë–∞–∑–æ–≤—ã–µ
            if not has("users"):
                db.execute(sa_text("""
                    CREATE TABLE IF NOT EXISTS users (
                        id           BIGSERIAL PRIMARY KEY,
                        tg_user_id   BIGINT UNIQUE NOT NULL,
                        is_admin     BOOLEAN NOT NULL DEFAULT FALSE,
                        is_allowed   BOOLEAN NOT NULL DEFAULT TRUE,
                        lang         TEXT,
                        created_at   TIMESTAMPTZ NOT NULL DEFAULT now()
                    );
                """))
                db.commit(); created.append("users")
            if not has("dialogs"):
                db.execute(sa_text("""
                    CREATE TABLE IF NOT EXISTS dialogs (
                        id              BIGSERIAL PRIMARY KEY,
                        user_id         BIGINT NOT NULL,
                        title           TEXT,
                        style           VARCHAR(20) NOT NULL DEFAULT 'pro',
                        model           TEXT,
                        is_deleted      BOOLEAN NOT NULL DEFAULT FALSE,
                        created_at      TIMESTAMPTZ NOT NULL DEFAULT now(),
                        last_message_at TIMESTAMPTZ
                    );
                """))
                db.commit(); created.append("dialogs")
            if not has("messages"):
                db.execute(sa_text("""
                    CREATE TABLE IF NOT EXISTS messages (
                        id         BIGSERIAL PRIMARY KEY,
                        dialog_id  BIGINT NOT NULL,
                        role       VARCHAR(20) NOT NULL,
                        content    TEXT NOT NULL,
                        tokens     INTEGER,
                        created_at TIMESTAMPTZ NOT NULL DEFAULT now()
                    );
                """))
                db.commit(); created.append("messages")

            # –ë–ó
            if not has("kb_documents"):
                db.execute(sa_text("""
                    CREATE TABLE IF NOT EXISTS kb_documents (
                        id         BIGSERIAL PRIMARY KEY,
                        path       TEXT UNIQUE NOT NULL,
                        etag       TEXT,
                        mime       TEXT,
                        pages      INTEGER,
                        bytes      BIGINT,
                        updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
                        is_active  BOOLEAN NOT NULL DEFAULT TRUE
                    );
                """))
                db.commit(); created.append("kb_documents")
            if not has("kb_chunks"):
                # –µ—Å–ª–∏ –Ω–µ—Ç vector ‚Äî –≤—Å—ë —Ä–∞–≤–Ω–æ —Å–æ–∑–¥–∞–¥–∏–º –±–µ–∑ ivfflat (–º–∏–Ω–∏–º—É–º)
                try:
                    db.execute(sa_text("CREATE EXTENSION IF NOT EXISTS vector;"))
                    db.commit()
                    has_vector = True
                except Exception:
                    db.rollback(); has_vector = False
                if has_vector:
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS kb_chunks (
                            id           BIGSERIAL PRIMARY KEY,
                            document_id  BIGINT NOT NULL,
                            chunk_index  INTEGER NOT NULL,
                            content      TEXT NOT NULL,
                            meta         JSON,
                            embedding    vector(3072)
                        );
                    """))
                    db.execute(sa_text("CREATE INDEX IF NOT EXISTS ix_kb_chunks_document_id ON kb_chunks(document_id);"))
                    try:
                        db.execute(sa_text("CREATE INDEX IF NOT EXISTS kb_chunks_embedding_idx ON kb_chunks USING ivfflat (embedding vector_cosine_ops);"))
                    except Exception:
                        pass
                else:
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS kb_chunks (
                            id           BIGSERIAL PRIMARY KEY,
                            document_id  BIGINT NOT NULL,
                            chunk_index  INTEGER NOT NULL,
                            content      TEXT NOT NULL,
                            meta         JSON,
                            embedding    BYTEA
                        );
                    """))
                    db.execute(sa_text("CREATE INDEX IF NOT EXISTS ix_kb_chunks_document_id ON kb_chunks(document_id);"))
                db.commit(); created.append("kb_chunks")
            if not has("dialog_kb_links"):
                db.execute(sa_text("""
                    CREATE TABLE IF NOT EXISTS dialog_kb_links (
                        id          BIGSERIAL PRIMARY KEY,
                        dialog_id   BIGINT NOT NULL,
                        document_id BIGINT NOT NULL,
                        created_at  TIMESTAMPTZ NOT NULL DEFAULT now()
                    );
                """))
                db.commit(); created.append("dialog_kb_links")
            if not has("pdf_passwords"):
                db.execute(sa_text("""
                    CREATE TABLE IF NOT EXISTS pdf_passwords (
                        id          BIGSERIAL PRIMARY KEY,
                        dialog_id   BIGINT NOT NULL,
                        document_id BIGINT NOT NULL,
                        pwd_hash    TEXT,
                        created_at  TIMESTAMPTZ NOT NULL DEFAULT now()
                    );
                """))
                db.commit(); created.append("pdf_passwords")
            if not has("audit_log"):
                db.execute(sa_text("""
                    CREATE TABLE IF NOT EXISTS audit_log (
                        id         BIGSERIAL PRIMARY KEY,
                        user_id    BIGINT,
                        action     TEXT,
                        meta       JSON,
                        created_at TIMESTAMPTZ NOT NULL DEFAULT now()
                    );
                """))
                db.commit(); created.append("audit_log")

        await m.reply_text("‚úÖ –†–µ–º–æ–Ω—Ç –∑–∞–≤–µ—Ä—à—ë–Ω. –°–æ–∑–¥–∞–Ω–æ: " + (", ".join(created) if created else "–Ω–∏—á–µ–≥–æ ‚Äî –≤—Å—ë —É–∂–µ –±—ã–ª–æ."))
    except Exception:
        log.exception("repair_schema failed")
        await (update.effective_message or update.message).reply_text("‚ö† –û—à–∏–±–∫–∞ repair_schema")

async def pgvector_check(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        with SessionLocal() as db:
            avail = db.execute(sa_text("SELECT EXISTS(SELECT 1 FROM pg_available_extensions WHERE name='vector')")).scalar()
            installed = db.execute(sa_text("SELECT EXISTS(SELECT 1 FROM pg_extension WHERE extname='vector')")).scalar()
        await (update.effective_message or update.message).reply_text(
            f"pgvector –¥–æ—Å—Ç—É–ø–Ω–æ: {'‚úÖ' if avail else '‚ùå'}\n"
            f"pgvector —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ: {'‚úÖ' if installed else '‚ùå'}"
        )
    except Exception:
        log.exception("pgvector_check failed")
        await (update.effective_message or update.message).reply_text("‚ö† –û—à–∏–±–∫–∞ pgvector_check")

# ---------- –°–ë–û–†–ö–ê –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø ----------
def build_app() -> Application:
    _ensure_single_instance()
    token = getattr(settings, "telegram_bot_token", None) or getattr(settings, "TELEGRAM_BOT_TOKEN", None)
    app = ApplicationBuilder().token(token).post_init(_post_init).build()

    # –ö–æ–º–∞–Ω–¥—ã
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_cmd))
    app.add_handler(CommandHandler("whoami", whoami))

    app.add_handler(CommandHandler("dialogs", dialogs))
    app.add_handler(CallbackQueryHandler(dialog_cb, pattern=r"^dlg:"))

    app.add_handler(CommandHandler("dialog", dialog_cmd))
    app.add_handler(CommandHandler("dialog_new", dialog_new))

    app.add_handler(CommandHandler("kb", kb_cmd))
    app.add_handler(CallbackQueryHandler(kb_cb, pattern=r"^kb:"))
    app.add_handler(CommandHandler("kb_sync", kb_sync))
    app.add_handler(CommandHandler("kb_diag", kb_diag))

    app.add_handler(CommandHandler("stats", stats))
    app.add_handler(CommandHandler("web", web_cmd))

    app.add_handler(CommandHandler("repair_schema", repair_schema))
    app.add_handler(CommandHandler("dbcheck", dbcheck))
    app.add_handler(CommandHandler("migrate", migrate))
    app.add_handler(CommandHandler("pgvector_check", pgvector_check))

    # –°–æ–æ–±—â–µ–Ω–∏—è
    app.add_handler(MessageHandler(filters.VOICE | filters.AUDIO, on_voice))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_text))

    return app
