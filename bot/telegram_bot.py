from __future__ import annotations
import tiktoken
import asyncio
from openai import OpenAI
from io import BytesIO
import os, re, inspect
from datetime import datetime
from urllib.parse import urlparse
import tempfile

# --- singleton lock for polling (prevents "Conflict: ... other getUpdates") ---
import os, sys, hashlib, psycopg2

_singleton_conn = None  # –¥–µ—Ä–∂–∏–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –æ—Ç–∫—Ä—ã—Ç—ã–º, –ø–æ–∫–∞ –∂–∏–≤—ë—Ç –ø—Ä–æ—Ü–µ—Å—Å

def _ensure_single_instance() -> None:
    """
    –ë–µ—Ä—ë–º advisory-lock –≤ PostgreSQL. –ï—Å–ª–∏ –∑–∞–Ω—è—Ç–æ ‚Äî –≤—ã—Ö–æ–¥–∏–º (–≤—Ç–æ—Ä–∞—è –∫–æ–ø–∏—è).
    –õ–æ–∫ –¥–µ—Ä–∂–∏—Ç—Å—è, –ø–æ–∫–∞ –æ—Ç–∫—Ä—ã—Ç _singleton_conn (–¥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞).
    """
    global _singleton_conn
    if _singleton_conn is not None:
        return  # —É–∂–µ –≤–∑—è–ª–∏

    dsn = getattr(settings, "database_url", None) or getattr(settings, "DATABASE_URL", None)
    if not dsn:
        # –±–µ–∑ –ë–î –ª–æ–∫ –Ω–µ –≤–æ–∑—å–º—ë–º ‚Äî –ø—Ä–æ—Å—Ç–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–µ–º
        log.warning("DATABASE_URL –Ω–µ –∑–∞–¥–∞–Ω ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞—é singleton-lock (—Ä–∏—Å–∫ Conflict).")
        return

    # –°—Ç–∞–±–∏–ª—å–Ω—ã–π –∫–ª—é—á –¥–ª—è advisory-lock
    lock_key = int(hashlib.sha1(f"{dsn}|{settings.telegram_bot_token}".encode("utf-8")).hexdigest()[:15], 16) % (2**31)
    try:
        _singleton_conn = psycopg2.connect(dsn)
        _singleton_conn.autocommit = True
        with _singleton_conn.cursor() as cur:
            cur.execute("SELECT pg_try_advisory_lock(%s)", (lock_key,))
            ok = cur.fetchone()[0]
        if not ok:
            log.error("‚ÄºÔ∏è –ù–∞–π–¥–µ–Ω–∞ –¥—Ä—É–≥–∞—è –∫–æ–ø–∏—è –±–æ—Ç–∞ (advisory-lock —É–∂–µ –∑–∞–Ω—è—Ç). –ó–∞–≤–µ—Ä—à–∞—é—Å—å.")
            # –º—è–≥–∫–∏–π –≤—ã—Ö–æ–¥, —á—Ç–æ–±—ã Railway –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏–ª —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —ç–∫–∑–µ–º–ø–ª—è—Ä
            sys.exit(0)
        log.info("‚úÖ Singleton-lock –ø–æ–ª—É—á–µ–Ω (pg_advisory_lock).")
    except Exception:
        log.exception("–ù–µ —É–¥–∞–ª–æ—Å—å –≤–∑—è—Ç—å singleton-lock. –†–∏—Å–∫ Conflict –æ—Å—Ç–∞—ë—Ç—Å—è.")

# --- post_init –¥–ª—è Application: —É–¥–∞–ª—è–µ–º webhook –ø–µ—Ä–µ–¥ polling ---
async def _post_init(app: "Application"):
    try:
        await app.bot.delete_webhook(drop_pending_updates=True)
        log.info("‚úÖ Webhook —É–¥–∞–ª—ë–Ω, pending updates —Å–±—Ä–æ—à–µ–Ω—ã.")
    except Exception:
        log.exception("–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å webhook")


import logging
from datetime import datetime
from io import BytesIO
# ==== KB RAG helpers (safe define if missing) ====
import json

# PTB 20.4 –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç BufferedInputFile. –î–µ–ª–∞–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π –∏–º–ø–æ—Ä—Ç.
try:
    from telegram import (
        Update, InlineKeyboardButton, InlineKeyboardMarkup, BufferedInputFile, InputFile
    )
    HAS_BUFFERED = True
except Exception:  # pragma: no cover
    from telegram import (  # type: ignore
        Update, InlineKeyboardButton, InlineKeyboardMarkup, InputFile
    )
    HAS_BUFFERED = False

from telegram.ext import (
    ApplicationBuilder, Application, CommandHandler, ContextTypes,
    MessageHandler, CallbackQueryHandler, filters
)
from sqlalchemy import text as sa_text

from bot.settings import load_settings
from bot.db.session import SessionLocal  # engine –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤–Ω—É—Ç—Ä–∏ apply_migrations_if_needed

log = logging.getLogger(__name__)
settings = load_settings()
_oa_client = OpenAI(api_key=settings.openai_api_key)

# --- –ê–≤—Ç–æ-–º–∏–≥—Ä–∞—Ü–∏—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ (–µ—Å–ª–∏ –Ω–µ—Ç —Ç–∞–±–ª–∏—Ü) ---
def apply_migrations_if_needed(force: bool = False) -> None:
    """
    –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç (–∏–ª–∏ force=True), –∑–∞–ø—É—Å–∫–∞–µ–º alembic upgrade head.
    –†–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ –∫–æ–Ω—Å–æ–ª–∏ Railway.
    """
    try:
        from sqlalchemy import text as sa_text
        from bot.db.session import engine
        need = True
        if not force:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤–æ–π —Ç–∞–±–ª–∏—Ü—ã
            with engine.connect() as conn:
                exists = conn.execute(sa_text("SELECT to_regclass('public.users')")).scalar()
                need = not bool(exists)

        if need:
            log.info("Auto-migrate: applying Alembic migrations...")
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º Alembic –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ
            import os
            import time
            from alembic.config import Config
            from alembic import command

            cfg = Config("alembic.ini")  # —Ñ–∞–π–ª –ª–µ–∂–∏—Ç –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞
            os.environ["DATABASE_URL"] = settings.database_url  # —á—Ç–æ–±—ã Alembic –∑–Ω–∞–ª, –∫—É–¥–∞ –ø–æ–¥–∫–ª—é—á–∞—Ç—å—Å—è
            command.upgrade(cfg, "head")
            log.info("Auto-migrate: done")
        else:
            log.info("Auto-migrate: tables already present")
    except Exception:
        log.exception("Auto-migrate failed")

# ---------- helpers ----------
def _exec_scalar(db, sql: str, **params):
    return db.execute(sa_text(sql), params).scalar()

def _exec_all(db, sql: str, **params):
    return db.execute(sa_text(sql), params).all()

def _ensure_user(db, tg_id: int) -> int:
    uid = _exec_scalar(db, "SELECT id FROM users WHERE tg_user_id=:tg", tg=tg_id)
    if uid:
        return uid
    uid = _exec_scalar(
        db,
        """
        INSERT INTO users (tg_user_id, is_admin, is_allowed, lang)
        VALUES (:tg, FALSE, TRUE, 'ru')
        RETURNING id
        """, tg=tg_id,
    )
    db.commit()
    return uid

def _ensure_dialog(db, user_id: int) -> int:
    did = _exec_scalar(
        db,
        """
        SELECT id FROM dialogs
        WHERE user_id=:u AND is_deleted=FALSE
        ORDER BY created_at DESC
        LIMIT 1
        """, u=user_id,
    )
    if did:
        return did
    did = _exec_scalar(
        db,
        """
        INSERT INTO dialogs (user_id, title, style, model, is_deleted)
        VALUES (:u, :t, 'expert', :m, FALSE)
        RETURNING id
        """, u=user_id, t=datetime.now().strftime("%Y-%m-%d | –¥–∏–∞–ª–æ–≥"), m=settings.openai_model,
    )
    db.commit()
    return did

def _is_admin(tg_id: int) -> bool:
    try:
        ids = [int(x.strip()) for x in (settings.admin_user_ids or "").split(",") if x.strip()]
        return tg_id in ids
    except Exception:
        return False

TELEGRAM_CHUNK = 3500  # –±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Å–æ–æ–±—â–µ–Ω–∏—è

def _split_for_tg(text: str, limit: int = TELEGRAM_CHUNK):
    """–î–µ–ª–∏—Ç –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Ç–∞–∫, —á—Ç–æ–±—ã –Ω–µ —Ä–≤–∞—Ç—å —Å–ª–æ–≤–∞/–∞–±–∑–∞—Ü—ã."""
    parts, s = [], text.strip()
    while len(s) > limit:
        cut = s.rfind("\n\n", 0, limit)
        if cut == -1:
            cut = s.rfind("\n", 0, limit)
        if cut == -1:
            cut = s.rfind(" ", 0, limit)
        if cut == -1:
            cut = limit
        parts.append(s[:cut].rstrip())
        s = s[cut:].lstrip()
    if s:
        parts.append(s)
    return parts


async def web_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    text = (m.text or "").strip()
    parts = text.split(maxsplit=1)
    if len(parts) < 2 or not parts[1].strip():
        return await m.reply_text("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /web <–∑–∞–ø—Ä–æ—Å>")

    query = parts[1].strip()
    note = await m.reply_text("üîé –ò—â—É –≤ –≤–µ–±–µ, –ø–æ–¥–æ–∂–¥–∏ –ø–∞—Ä—É —Å–µ–∫—É–Ω–¥‚Ä¶")

    try:
        from bot.web_search import web_search_digest, sources_footer
        answer, sources = await web_search_digest(query, max_results=6, openai_api_key=settings.openai_api_key)

        footer = ("\n\n–ò—Å—Ç–æ—á–Ω–∏–∫–∏:\n" + sources_footer(sources)) if sources else ""
        await _send_long(m, (answer or "–ì–æ—Ç–æ–≤–æ.") + footer)

        if sources:
            buttons = [[InlineKeyboardButton(f"[{i+1}] {urlparse(s['url']).netloc}", url=s['url'])] for i, s in enumerate(sources)]
            await m.reply_text("–û—Ç–∫—Ä—ã—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏:", reply_markup=InlineKeyboardMarkup(buttons), disable_web_page_preview=True)
    except Exception as e:
        await m.reply_text(f"‚ö† –í–µ–±-–ø–æ–∏—Å–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    finally:
        try:
            await note.delete()
        except Exception:
            pass

# /dialog <id> ‚Äî —Å–¥–µ–ª–∞—Ç—å –¥–∏–∞–ª–æ–≥ –∞–∫—Ç–∏–≤–Ω—ã–º
async def dialog_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    args = context.args or []

    # –µ—Å–ª–∏ id –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω ‚Äî –ø—Ä–æ—Å—Ç–æ –ø–æ–∫–∞–∂–µ–º —Å–ø–∏—Å–æ–∫ –¥–∏–∞–ª–æ–≥–æ–≤
    if not args:
        return await dialogs(update, context)

    # –ø–∞—Ä—Å–∏–º id
    try:
        did = int(args[0])
    except Exception:
        return await m.reply_text("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /dialog <id>")

    try:
        with SessionLocal() as db:
            # –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∏–∞–ª–æ–≥ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
            row = db.execute(sa_text("""
                SELECT d.id
                FROM dialogs d
                JOIN users u ON u.id = d.user_id
                WHERE u.tg_user_id = :tg AND d.id = :did
                LIMIT 1
            """), {"tg": update.effective_user.id, "did": did}).fetchone()

            if not row:
                return await m.reply_text("‚ö† –î–∏–∞–ª–æ–≥ –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –≤–∞–º.")

            # –µ—Å–ª–∏ –≤ –ø—Ä–æ–µ–∫—Ç–µ –µ—Å—Ç—å —Ö–µ–ª–ø–µ—Ä ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
            try:
                _set_active_dialog_id  # type: ignore
                _set_active_dialog_id(db, update.effective_user.id, did)  # noqa
            except NameError:
                # –∑–∞–ø–∞—Å–Ω–æ–π –ø—É—Ç—å: –¥–µ—Ä–∂–∏–º –∞–∫—Ç–∏–≤–Ω—ã–π –¥–∏–∞–ª–æ–≥ –≤ user_data
                context.user_data["active_dialog_id"] = did

            await m.reply_text(f"‚úÖ –ê–∫—Ç–∏–≤–Ω—ã–π –¥–∏–∞–ª–æ–≥: {did}")
            # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —Å—Ä–∞–∑—É –ø–æ–∫–∞–∑–∞—Ç—å /stats
            return await stats(update, context)

    except Exception:
        log.exception("dialog_cmd failed")
        return await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –¥–∏–∞–ª–æ–≥. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")


async def _send_long(m, text: str):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –ø–∞—á–∫–∞–º–∏, –µ—Å–ª–∏ –æ–Ω –¥–ª–∏–Ω–Ω–µ–µ –ª–∏–º–∏—Ç–∞ Telegram."""
    for chunk in _split_for_tg(text):
        await m.reply_text(chunk)

async def _chat_full(model: str, messages: list, temperature: float = 0.3, max_turns: int = 6):
    """
    –í—ã–∑—ã–≤–∞–µ—Ç Chat Completions —Å—Ç–æ–ª—å–∫–æ —Ä–∞–∑, —Å–∫–æ–ª—å–∫–æ –Ω—É–∂–Ω–æ, –ø–æ–∫–∞ finish_reason != 'length'
    –∏–ª–∏ –Ω–µ –∏—Å—á–µ—Ä–ø–∞–Ω –ª–∏–º–∏—Ç max_turns. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Å–∫–ª–µ–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç.
    """
    hist = list(messages)
    full = ""
    turns = 0
    while turns < max_turns:
        turns += 1
        resp = _oa_client.chat.completions.create(
            model=model,
            messages=hist,
            temperature=temperature,
            max_tokens=1024,  # –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å, –Ω–æ –º—ã –≤—Å—ë —Ä–∞–≤–Ω–æ –∞–≤—Ç–æ–ø—Ä–æ–¥–æ–ª–∂–∏–º
        )
        choice = resp.choices[0]
        piece = choice.message.content or ""
        full += piece
        finish = choice.finish_reason
        if finish != "length":
            break
        # –ø—Ä–æ—Å–∏–º –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å
        hist.append({"role": "assistant", "content": piece})
        hist.append({"role": "user", "content": "–ü—Ä–æ–¥–æ–ª–∂–∞–π —Å —Ç–æ–≥–æ –º–µ—Å—Ç–∞. –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π—Å—è."})
    return full

def _get_active_dialog_id(db, tg_id: int) -> int | None:
    row = db.execute(sa_text("""
        SELECT d.id
        FROM dialogs d
        JOIN users u ON u.id = d.user_id
        WHERE u.tg_user_id = :tg AND d.is_deleted = FALSE
        ORDER BY COALESCE(d.last_message_at, to_timestamp(0)) DESC,
                 COALESCE(d.created_at,      to_timestamp(0)) DESC,
                 d.id DESC
        LIMIT 1
    """), {"tg": tg_id}).first()
    return row[0] if row else None

async def whoami(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        tg_id = update.effective_user.id
        with SessionLocal() as db:
            row = db.execute(sa_text("SELECT id, is_admin, is_allowed, lang FROM users WHERE tg_user_id=:tg"), {"tg": tg_id}).first()
            if not row:
                uid = _ensure_user(db, tg_id)
                row = db.execute(sa_text("SELECT id, is_admin, is_allowed, lang FROM users WHERE id=:id"), {"id": uid}).first()
        is_admin = bool(row[1]) if row else False
        is_allowed = bool(row[2]) if row else True
        lang = (row[3] or "ru") if row else "ru"
        role = "admin" if is_admin else ("allowed" if is_allowed else "guest")
        await (update.message or update.effective_message).reply_text(f"whoami: tg={tg_id}, role={role}, lang={lang}")
    except Exception:
        log.exception("whoami failed")
        await (update.message or update.effective_message).reply_text("‚ö† –û—à–∏–±–∫–∞ whoami")

async def grant(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        if not _is_admin(update.effective_user.id):
            return await (update.message or update.effective_message).reply_text("‚õî –î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â—ë–Ω (–Ω—É–∂–Ω–æ –±—ã—Ç—å –∞–¥–º–∏–Ω–æ–º).")
        args = (update.message.text or "").split()
        if len(args) < 2 or not args[1].isdigit():
            return await (update.message or update.effective_message).reply_text("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /grant <tg_id>")
        target = int(args[1])
        with SessionLocal() as db:
            uid = _exec_scalar(db, "SELECT id FROM users WHERE tg_user_id=:tg", tg=target)
            if not uid:
                uid = _exec_scalar(db, "INSERT INTO users (tg_user_id, is_admin, is_allowed, lang) VALUES (:tg,FALSE,TRUE,'ru') RETURNING id", tg=target)
            else:
                db.execute(sa_text("UPDATE users SET is_allowed=TRUE WHERE id=:id"), {"id": uid})
            db.commit()
        await (update.message or update.effective_message).reply_text(f"‚úÖ –í—ã–¥–∞–Ω –¥–æ—Å—Ç—É–ø –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {target}")
    except Exception:
        log.exception("grant failed")
        await (update.message or update.effective_message).reply_text("‚ö† –û—à–∏–±–∫–∞ grant")

async def revoke(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        if not _is_admin(update.effective_user.id):
            return await (update.message or update.effective_message).reply_text("‚õî –î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â—ë–Ω (–Ω—É–∂–Ω–æ –±—ã—Ç—å –∞–¥–º–∏–Ω–æ–º).")
        args = (update.message.text or "").split()
        if len(args) < 2 or not args[1].isdigit():
            return await (update.message or update.effective_message).reply_text("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /revoke <tg_id>")
        target = int(args[1])
        with SessionLocal() as db:
            uid = _exec_scalar(db, "SELECT id FROM users WHERE tg_user_id=:tg", tg=target)
            if uid:
                db.execute(sa_text("UPDATE users SET is_allowed=FALSE WHERE id=:id"), {"id": uid})
                db.commit()
        await (update.message or update.effective_message).reply_text(f"üö´ –î–æ—Å—Ç—É–ø –æ—Ç–æ–∑–≤–∞–Ω —É {target}")
    except Exception:
        log.exception("revoke failed")
        await (update.message or update.effective_message).reply_text("‚ö† –û—à–∏–±–∫–∞ revoke")
# ---------- commands ----------
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    await m.reply_text(
        "–ó–¥–æ—Ä–æ–≤! –Ø –ø–æ–º–æ–≥—É –∏—Å–∫–∞—Ç—å –æ—Ç–≤–µ—Ç—ã –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –∏–∑ –ë–ó –∏ –≤–µ—Å—Ç–∏ –¥–∏–∞–ª–æ–≥–∏ –≤ —Ä–∞–∑–Ω—ã—Ö —Å—Ç–∏–ª—è—Ö.\n"
        "–í—Å–µ –∫–æ–º–∞–Ω–¥—ã —Ç—É—Ç ‚Äî /help"
    )

async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    await m.reply_text(
        "/start ‚Äî –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ\n"
        "/help ‚Äî –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥\n"
        "/dialogs ‚Äî —Å–ø–∏—Å–æ–∫ –¥–∏–∞–ª–æ–≥–æ–≤ (–æ—Ç–∫—Ä—ã—Ç—å/–ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å/—ç–∫—Å–ø–æ—Ä—Ç/—É–¥–∞–ª–∏—Ç—å)\n"
        "/dialog_new ‚Äî —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥\n"
        "/kb ‚Äî –ø–æ–¥–∫–ª—é—á–∏—Ç—å/–æ—Ç–∫–ª—é—á–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –ë–ó\n"
        "/stats ‚Äî –∫–∞—Ä—Ç–æ—á–∫–∞ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞\n"
        "/model ‚Äî –≤—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å (–¢–û–ü-10 + –ü–æ–∫–∞–∑–∞—Ç—å –µ—â—ë)\n"
        "/mode ‚Äî —Å—Ç–∏–ª—å –æ—Ç–≤–µ—Ç–∞ (pro/expert/user/ceo)\n"
        "/img <–æ–ø–∏—Å–∞–Ω–∏–µ> ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–ø–æ–∫–∞–∂—É –∏—Ç–æ–≥–æ–≤—ã–π prompt)\n"
        "/web <–∑–∞–ø—Ä–æ—Å> ‚Äî (–∑–∞–≥–ª—É—à–∫–∞) –≤–µ–±-–ø–æ–∏—Å–∫\n"
        "/reset ‚Äî —Å–±—Ä–æ—Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞\n"
        "/whoami ‚Äî –º–æ–∏ –ø—Ä–∞–≤–∞\n"
    )

async def cmd_web(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    query = " ".join(context.args or [])
    if not query:
        return await m.reply_text("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /web <–∑–∞–ø—Ä–æ—Å>")
    await m.reply_text(
        "üîé –í–µ–±-–ø–æ–∏—Å–∫ –ø–æ–∫–∞ –æ—Ç–∫–ª—é—á—ë–Ω –≤ —ç—Ç–æ–π —Å–±–æ—Ä–∫–µ (–∫–ª—é—á–∏ –≤–Ω–µ—à–Ω–µ–≥–æ –ø–æ–∏—Å–∫–∞ –Ω–µ –∑–∞–¥–∞–Ω—ã).\n"
        "–Ø –º–æ–≥—É –æ—Ç–≤–µ—Ç–∏—Ç—å —Å–≤–æ–∏–º–∏ –∑–Ω–∞–Ω–∏—è–º–∏ –∏–ª–∏ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –Ω–∞–π—Ç–∏ –≤ –ë–ó —á–µ—Ä–µ–∑ /kb."
    )

async def on_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ì–æ–ª–æ—Å ‚Üí Whisper ‚Üí –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –≤ –∞–∫—Ç–∏–≤–Ω—ã–π –¥–∏–∞–ª–æ–≥."""
    m = update.effective_message or update.message
    voice = m.voice or m.audio
    if not voice:
        return await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")

    try:
        # 1) –°–∫–∞—á–∏–≤–∞–µ–º –≥–æ–ª–æ—Å –≤ .ogg (Telegram voice ‚Äî OGG/Opus)
        import tempfile, pathlib
        file = await context.bot.get_file(voice.file_id)
        tmpdir = tempfile.mkdtemp(prefix="tg_voice_")
        ogg_path = str(pathlib.Path(tmpdir) / "voice.ogg")   # –í–∞–∂–Ω–æ: –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        await file.download_to_drive(ogg_path)

        # 2) –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ OpenAI (whisper-1 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
        from openai import OpenAI
        client = OpenAI(api_key=settings.OPENAI_API_KEY)
        model_name = getattr(settings, "OPENAI_TRANSCRIBE_MODEL", "whisper-1")
        with open(ogg_path, "rb") as f:
            tr = client.audio.transcriptions.create(model=model_name, file=f)  # file name=voice.ogg ‚Üí –æ–∫
        text = (getattr(tr, "text", None) or (tr.get("text") if isinstance(tr, dict) else None) or "").strip()
        if not text:
            return await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –°–∫–∞–∂–∏—Ç–µ –µ—â—ë —Ä–∞–∑, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞.")

        # 3) –°–æ—Ö—Ä–∞–Ω—è–µ–º ¬´user¬ª –≤ –¢–ï–ö–£–©–ò–ô –∞–∫—Ç–∏–≤–Ω—ã–π –¥–∏–∞–ª–æ–≥
        with SessionLocal() as db:
            did = _get_active_dialog_id(db, update.effective_user.id) or _create_new_dialog_for_tg(db, update.effective_user.id)
            _save_message(db, did, "user", text)  # –≤ —Ç–≤–æ—ë–º –ø—Ä–æ–µ–∫—Ç–µ —É–∂–µ –µ—Å—Ç—å —Ö–µ–ª–ø–µ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è

        # 4) –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π on_text
        update.effective_message.text = text
        return await on_text(update, context)

    except Exception:
        log.exception("on_voice failed")
        return await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")

def ya_download(path: str) -> bytes:
    """
    –°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª —Å –Ø.–î–∏—Å–∫–∞ –ø–æ –∞–±—Å–æ–ª—é—Ç–Ω–æ–º—É –ø—É—Ç–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'disk:/–ë–∞–∑–∞ –ó–Ω–∞–Ω–∏–π/file.pdf').
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –±–∏–Ω–∞—Ä–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞.
    """
    import requests
    YA_API = "https://cloud-api.yandex.net/v1/disk"
    headers = {"Authorization": f"OAuth {settings.yandex_disk_token}"}

    # 1) –ø–æ–ª—É—á–∞–µ–º href –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    r = requests.get(
        f"{YA_API}/resources/download",
        headers=headers,
        params={"path": path},
        timeout=60,
    )
    r.raise_for_status()
    href = (r.json() or {}).get("href")
    if not href:
        raise RuntimeError("download href not returned by Yandex Disk")

    # 2) —Å–∫–∞—á–∏–≤–∞–µ–º —Å–∞–º —Ñ–∞–π–ª
    f = requests.get(href, timeout=300)
    f.raise_for_status()
    return f.content

async def rag_selftest(update, context):
    from sqlalchemy import text as sa_text
    m = update.effective_message or update.message
    try:
        with SessionLocal() as db:
            t = db.execute(sa_text("SELECT pg_typeof(embedding)::text FROM kb_chunks LIMIT 1")).scalar()
            d = db.execute(sa_text("SELECT (embedding <=> embedding) FROM kb_chunks LIMIT 1")).scalar()
        await m.reply_text(f"pg_typeof(embedding) = {t}\n(embedding <=> embedding) = {d}")
    except Exception as e:
        log.exception("rag_selftest failed")
        await m.reply_text(f"‚ùå rag_selftest: {e}")

# ---- RAG helpers ----
from typing import List, Tuple

def _vec_literal(vec: list[float]) -> tuple[dict, str]:
    # –ø–æ–¥–∞—ë–º —Å—Ç—Ä–æ–∫—É –≤–∏–¥–∞ "[0.1,0.2,...]" –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–µ q
    arr = "[" + ",".join(f"{x:.6f}" for x in (vec or [])) + "]"
    return {"q": arr}, "CAST(:q AS vector)"   # <- –≤–æ–∑–≤—Ä–∞—â–∞–µ–º params –∏ SQL-–≤—ã—Ä–∞–∂–µ–Ω–∏–µ

def _embed_query(text: str) -> List[float]:
    from openai import OpenAI
    client = OpenAI(api_key=settings.openai_api_key)
    return client.embeddings.create(model=settings.embedding_model, input=[text]).data[0].embedding

def _retrieve_chunks(db, dialog_id: int, question: str, k: int = 6) -> List[dict]:
    # –µ—Å–ª–∏ —Å—Ç–æ–ª–±–µ—Ü embedding –Ω–µ –≤ vector-—Ç–∏–ø–µ ‚Äî –ø—Ä–æ—Å—Ç–æ –≤–µ—Ä–Ω—ë–º –ø—É—Å—Ç–æ (RAG –æ—Ç–∫–ª—é—á–∏—Ç—Å—è)
    kind = _kb_embedding_column_kind(db)
    if kind != "vector":
        return []

    q = _embed_query(question)
    params, qexpr = _vec_literal(q)
    
    sql = f"""
        SELECT c.content, c.meta, d.path
        FROM kb_chunks c
        JOIN kb_documents d    ON d.id = c.document_id AND d.is_active = TRUE
        JOIN dialog_kb_links l ON l.document_id = c.document_id
        WHERE l.dialog_id = :did
        ORDER BY c.embedding <=> {qexpr}
        LIMIT :k
    """
    p = {"did": dialog_id, "k": k}
    p.update(params)
    rows = db.execute(sa_text(sql), p).mappings().all()
    return [dict(r) for r in rows]

_STYLE_EXAMPLES = {
    "pro":    "–ö—Ä–∞—Ç–∫–æ, –ø–æ —à–∞–≥–∞–º, —á–µ–∫-–ª–∏—Å—Ç. –ë–µ–∑ –≤–æ–¥—ã. –ü—Ä–∏–º–µ—Ä: ¬´–®–∞–≥–∏ 1‚Äì5, —Ä–∏—Å–∫–∏, KPI, –¥–µ–¥–ª–∞–π–Ω—ã¬ª.",
    "expert": "–ì–ª—É–±–æ–∫–æ –∏ –æ–±—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ: –ø—Ä–∏—á–∏–Ω—ã/—Å–ª–µ–¥—Å—Ç–≤–∏—è, –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã, —Å—Å—ã–ª–∫–∏. –ü—Ä–∏–º–µ—Ä: ¬´–ù–∞—á–Ω—ë–º —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π‚Ä¶¬ª.",
    "user":   "–ü—Ä–æ—Å—Ç–æ, –ø–æ–Ω—è—Ç–Ω—ã–º —è–∑—ã–∫–æ–º, —Å –º–µ—Ç–∞—Ñ–æ—Ä–∞–º–∏ –∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∏–∑ –∂–∏–∑–Ω–∏.",
    "ceo":    "–° —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –±–∏–∑–Ω–µ—Å–∞: —Ü–µ–Ω–Ω–æ—Å—Ç—å/—Å—Ç–æ–∏–º–æ—Å—Ç—å, —Ä–∏—Å–∫–∏, —Å—Ä–æ–∫–∏, —Ä–µ—à–µ–Ω–∏—è, –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏ trade-offs.",
}

def _build_prompt_with_style(ctx_blocks: List[str], user_q: str, dialog_style: str) -> str:
    style_map = {
        "pro":   "–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —ë–º–∫–æ –∏ –ø–æ –¥–µ–ª—É, —à–∞–≥–∏ –∏ —á–µ–∫-–ª–∏—Å—Ç.",
        "expert":"–≠–∫—Å–ø–µ—Ä—Ç: –ø–æ–¥—Ä–æ–±–Ω–æ, –ø—Ä–∏—á–∏–Ω—ã/—Å–ª–µ–¥—Å—Ç–≤–∏—è, –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã, –≤—ã–≤–æ–¥—ã. –¶–∏—Ç–∞—Ç—ã –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Ç–æ–ª—å–∫–æ –≤ –∫–æ–Ω—Ü–µ.",
        "user":  "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏, –ø—Ä–∏–º–µ—Ä—ã –∏ –∞–Ω–∞–ª–æ–≥–∏–∏.",
        "ceo":   "CEO: –±–∏–∑–Ω–µ—Å-—Ü–µ–Ω–Ω–æ—Å—Ç—å, ROI, —Ä–∏—Å–∫–∏, —Ä–µ—à–µ–Ω–∏—è –∏ –∫–æ–º–ø—Ä–æ–º–∏—Å—Å—ã.",
    }
    style_line = style_map.get(dialog_style or "pro", style_map["pro"])
    header = (
        "–¢—ã ‚Äî –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –ë–ó, –Ω–æ –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–π—Å—è —Ü–∏—Ç–∞—Ç–∞–º–∏: "
        "—Å–∏–Ω—Ç–µ–∑–∏—Ä—É–π —Ü–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —Å—Ç–∏–ª–µ. –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–µ—Ç ‚Äî —É—Ç–æ—á–Ω–∏."
    )
    ctx = "\n\n".join([f"[–§—Ä–∞–≥–º–µ–Ω—Ç #{i+1}]\n{t}" for i, t in enumerate(ctx_blocks)])
    return f"{header}\n–°—Ç–∏–ª—å: {style_line}\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{ctx}\n\n–í–æ–ø—Ä–æ—Å: {user_q}"

def _format_citations(chunks: List[dict]) -> str:
    # –ë–µ—Ä—ë–º –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
    def short(p: str) -> str:
        return (p or "").split("/")[-1].split("?")[0]
    uniq = []
    for r in chunks:
        name = short(r.get("path") or (r.get("meta") or {}).get("path", ""))
        if name and name not in uniq:
            uniq.append(name)
    if not uniq: 
        return ""
    return "\n\n–ò—Å—Ç–æ—á–Ω–∏–∫–∏: " + "; ".join(f"[{i+1}] {n}" for i, n in enumerate(uniq[:5]))



async def kb_pdf_diag(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        if not _is_admin(update.effective_user.id):
            return await m.reply_text("–¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞.")

        root = settings.yandex_root_path
        files = [f for f in _ya_list_files(root) if (f.get("name") or "").lower().endswith(".pdf")]

        lines = []
        for it in files:
            path = it.get("path") or it.get("name")
            try:
                blob = ya_download(path)
                txt, pages, is_prot = _pdf_extract_text(blob)
                sample = (txt or "").strip().replace("\n", " ")
                sample = (sample[:120] + "‚Ä¶") if len(sample) > 120 else sample
                lines.append(f"‚Ä¢ {path.split('/')[-1]} | pages={pages} | prot={'yes' if is_prot else 'no'} | text_len={len(txt or '')} | sample='{sample}'")
            except Exception as e:
                lines.append(f"‚Ä¢ {path.split('/')[-1]} | ERROR: {e}")
        if not lines:
            lines = ["(PDF –Ω–µ –Ω–∞–π–¥–µ–Ω—ã)"]
        await m.reply_text("PDF DIAG:\n" + "\n".join(lines[:30]))
    except Exception:
        log.exception("kb_pdf_diag failed")
        await m.reply_text("‚ö† kb_pdf_diag: –æ—à–∏–±–∫–∞. –°–º–æ—Ç—Ä–∏ –ª–æ–≥–∏.")

async def rag_diag(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    q = " ".join(context.args) if context.args else ""
    if not q:
        return await m.reply_text("–ù–∞–ø–∏—à–∏—Ç–µ –∑–∞–ø—Ä–æ—Å: /rag_diag –≤–∞—à –≤–æ–ø—Ä–æ—Å")
    try:
        with SessionLocal() as db:
            uid = _ensure_user(db, update.effective_user.id)
            did = _ensure_dialog(db, uid)
            rows = _retrieve_chunks(db, did, q, k=5)
            if not rows:
                return await m.reply_text("–ù–∏—á–µ–≥–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –Ω–µ –Ω–∞—à–ª–∏ —Å—Ä–µ–¥–∏ –ø–æ–¥–∫–ª—é—á—ë–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.")
            out = []
            for i, r in enumerate(rows, 1):
                path = (r.get("path") or (r.get("meta") or {}).get("path", "")).split("/")[-1]
                sample = (r["content"] or "")[:140].replace("\n", " ")
                out.append(f"[{i}] {path} ‚Äî ‚Äú{sample}‚Ä¶‚Äù")
            await m.reply_text("\n".join(out))
    except Exception:
        log.exception("rag_diag failed")
        await m.reply_text("‚ö† rag_diag: –æ—à–∏–±–∫–∞. –°–º–æ—Ç—Ä–∏ –ª–æ–≥–∏.")

# ---- PDF helpers ----
def _pdf_extract_text(pdf_bytes: bytes) -> tuple[str, int, bool]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (—Ç–µ–∫—Å—Ç, pages, is_protected).
    1) PyMuPDF
    2) Fallback –Ω–∞ pdfminer.six, –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –ø—É—Å—Ç–æ–π –∏ –Ω–µ –∑–∞—â–∏—â—ë–Ω
    """
    import fitz  # PyMuPDF
    with fitz.open(stream=pdf_bytes, filetype="pdf") as doc:
        is_prot = bool(doc.is_encrypted)
        if is_prot:
            try:
                if doc.authenticate(""):
                    is_prot = False
            except Exception:
                pass
        if is_prot:
            return ("", 0, True)

        pages = doc.page_count
        out = []
        for i in range(pages):
            try:
                text = doc.load_page(i).get_text("text") or ""
            except Exception:
                text = ""
            out.append(text)
        txt = "\n".join(out)

    # Fallback: –µ—Å–ª–∏ –ø—É—Å—Ç–æ, –ø–æ–ø—Ä–æ–±—É–µ–º pdfminer
    if not txt.strip():
        try:
            from io import BytesIO
            from pdfminer.high_level import extract_text
            txt = extract_text(BytesIO(pdf_bytes)) or ""
        except Exception:
            pass

    return (txt, pages, False)


# 0) –∫–∞–∫–æ–≥–æ —Ç–∏–ø–∞ –∫–æ–ª–æ–Ω–∫–∞ embedding –≤ kb_chunks: 'vector' | 'bytea' | 'none'
try:
    _kb_embedding_column_kind
except NameError:
    def _kb_embedding_column_kind(db) -> str:
        try:
            t = db.execute(sa_text("SELECT pg_typeof(embedding)::text FROM kb_chunks LIMIT 1")).scalar()
            if t:
                t = str(t).lower()
                if "vector" in t:
                    return "vector"
                if "bytea" in t:
                    return "bytea"
            # fallback —á–µ—Ä–µ–∑ information_schema
            t = db.execute(sa_text("""
                SELECT COALESCE(udt_name, data_type)
                FROM information_schema.columns
                WHERE table_name='kb_chunks' AND column_name='embedding'
                LIMIT 1
            """)).scalar()
            t = (t or "").lower()
            if "vector" in t:
                return "vector"
            if "bytea" in t:
                return "bytea"
        except Exception:
            pass
        return "none"

# 1) upsert –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ kb_documents (–≤–æ–∑–≤—Ä–∞—â–∞–µ–º id)
try:
    _kb_upsert_document
except NameError:
    def _kb_upsert_document(db, path: str, mime: str, size: int, etag: str) -> int:
        sql = sa_text("""
            INSERT INTO kb_documents (path, mime, bytes, etag, updated_at, is_active)
            VALUES (:p, :m, :b, :e, now(), TRUE)
            ON CONFLICT (path) DO UPDATE
              SET mime = EXCLUDED.mime,
                  bytes = EXCLUDED.bytes,
                  etag  = EXCLUDED.etag,
                  updated_at = now(),
                  is_active = TRUE
            RETURNING id
        """)
        doc_id = db.execute(sql, {"p": path, "m": mime, "b": size, "e": etag}).scalar()
        db.commit()
        return int(doc_id)

# 2) –æ—á–∏—Å—Ç–∫–∞ —á–∞–Ω–∫–æ–≤ –ø–æ document_id
try:
    _kb_clear_chunks
except NameError:
    def _kb_clear_chunks(db, document_id: int):
        db.execute(sa_text("DELETE FROM kb_chunks WHERE document_id=:d"), {"d": document_id})
        db.commit()

# 3) –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —Å –Ø.–î–∏—Å–∫–∞ –ø–æ –ø—É—Ç–∏
try:
    _ya_download
except NameError:
    def _chunk_text(text: str, max_tokens: int = 2000, overlap: int = 0):
        """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –∫—É—Å–∫–∏ –ø–æ max_tokens –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º overlap"""
        enc = tiktoken.get_encoding("cl100k_base")
        tokens = enc.encode(text)
    
        chunks = []
        i = 0
        while i < len(tokens):
            chunk_tokens = tokens[i:i+max_tokens]
            chunk_text = enc.decode(chunk_tokens)
            chunks.append(chunk_text.strip())
            if overlap > 0:
                i += max_tokens - overlap
            else:
                i += max_tokens
    
        return chunks

# 4) –ø—Ä–æ—Å—Ç–∞—è —Ä–µ–∑–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞–Ω–∫–∏
try:
    _chunk_text
except NameError:
    def _chunk_text(text: str, max_tokens: int = 2000):
        """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –∫—É—Å–∫–∏ –ø–æ max_tokens –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        enc = tiktoken.get_encoding("cl100k_base")
        tokens = enc.encode(text)
    
        chunks = []
        for i in range(0, len(tokens), max_tokens):
            chunk_tokens = tokens[i:i+max_tokens]
            chunk_text = enc.decode(chunk_tokens)
            chunks.append(chunk_text.strip())
    
        return chunks

# 5) —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –ø–∞—á–∫–æ–π (OpenAI)
try:
    _get_embeddings
except NameError:
    def _get_embeddings(chunks: list[str]) -> list[list[float]]:
        """
        –°—á–∏—Ç–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ, –±–∞—Ç—á–∞–º–∏:
        - –ª–∏–º–∏—Ç –ø–æ —Å—É–º–º–∞—Ä–Ω—ã–º —Ç–æ–∫–µ–Ω–∞–º ~250k –Ω–∞ –∑–∞–ø—Ä–æ—Å (–∑–∞–ø–∞—Å –æ—Ç 300k);
        - –¥–æ–ø. –ª–∏–º–∏—Ç –Ω–∞ —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —ç–ª–µ–º–µ–Ω—Ç–æ–≤, —á—Ç–æ–±—ã –Ω–µ —Ä–∞–∑–¥—É–≤–∞—Ç—å payload.
        """
        if not chunks:
            return []
    
        enc = tiktoken.get_encoding("cl100k_base")
        from openai import OpenAI
        client = OpenAI(api_key=settings.openai_api_key)
    
        MAX_TOKENS_PER_REQ = 250_000   # –∑–∞–ø–∞—Å –æ—Ç –ª–∏–º–∏—Ç–∞ 300k
        MAX_ITEMS_PER_REQ  = 128       # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –æ–≥—Ä–∞–Ω–∏—á–∏–º –∏ –ø–æ —á–∏—Å–ª—É —Å—Ç—Ä–æ–∫
    
        out: list[list[float]] = []
        batch: list[str] = []
        batch_tok_sum = 0
    
        def flush_batch():
            nonlocal out, batch, batch_tok_sum
            if not batch:
                return
            resp = client.embeddings.create(model=settings.embedding_model, input=batch)
            data = getattr(resp, "data", None) or resp.get("data", [])
            # order –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω, –ø—Ä–æ—Å—Ç–æ –¥–æ–ø–∏—Å—ã–≤–∞–µ–º
            out.extend([item.embedding for item in data])
            batch = []
            batch_tok_sum = 0
    
        for ch in chunks:
            t = len(enc.encode(ch or ""))
            # –µ—Å–ª–∏ –æ–¥–∏–Ω–æ—á–Ω—ã–π —á–∞–Ω–∫ –≤–¥—Ä—É–≥ –±–æ–ª—å—à–µ –ª–∏–º–∏—Ç–∞ ‚Äî —É–∂–µ –ø–æ—Ä–µ–∑–∞–Ω —Ä–∞–Ω–µ–µ; –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π:
            if t > MAX_TOKENS_PER_REQ:
                # –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞—â–∏—Ç–∞: –¥–æ—Ä–µ–∑–∞—Ç—å –Ω–∞ –ø–æ–¥—á–∞–Ω–∫–∏ –ø–æ 2000 —Ç–æ–∫–µ–Ω–æ–≤
                subchunks = []
                toks = enc.encode(ch or "")
                for i in range(0, len(toks), 2000):
                    subchunks.append(enc.decode(toks[i:i+2000]))
                # —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø—Ä–æ–≥–æ–Ω—è–µ–º –ø–æ–¥—á–∞–Ω–∫–∏ —Ç–µ–º –∂–µ –º–µ—Ö–∞–Ω–∏–∑–º–æ–º
                out.extend(_get_embeddings(subchunks))
                continue
    
            # –µ—Å–ª–∏ —Ç–µ–∫—É—â–∏–π –Ω–µ –≤–ª–µ–∑–∞–µ—Ç –≤ –±–∞—Ç—á ‚Äî —à–ª—ë–º —Ç–æ, —á—Ç–æ –Ω–∞–∫–æ–ø–ª–µ–Ω–æ
            if batch and (batch_tok_sum + t > MAX_TOKENS_PER_REQ or len(batch) >= MAX_ITEMS_PER_REQ):
                flush_batch()
    
            batch.append(ch)
            batch_tok_sum += t
    
        flush_batch()
        return out

# 6) SQL-—Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
try:
    _format_vector_sql
except NameError:
    def _format_vector_sql(vec: list[float]) -> tuple[str, dict]:
        arr = "[" + ",".join(f"{x:.6f}" for x in (vec or [])) + "]"
        return " CAST(:emb AS vector) ", {"emb": arr}

try:
    _format_bytea_sql
except NameError:
    def _format_bytea_sql(vec: list[float]) -> tuple[str, dict]:
        try:
            import struct
            from psycopg2 import Binary
            b = struct.pack(f"{len(vec)}f", *vec) if vec else b""
            return " :emb ", {"emb": Binary(b)}
        except Exception:
            return " NULL ", {}
# ==== /KB RAG helpers ====

# --- Fallback –ª–∏—Å—Ç–∏–Ω–≥ –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–∞ (–µ—Å–ª–∏ –Ω–µ—Ç —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ö–µ–ª–ø–µ—Ä–∞) ---
def _ya_list_files(root_path: str):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ –Ø.–î–∏—Å–∫–∞ —á–µ—Ä–µ–∑ REST API.
    –≠–ª–µ–º–µ–Ω—Ç—ã: name, path, type, mime_type, size, md5.
    """
    import requests
    YA_API = "https://cloud-api.yandex.net/v1/disk"
    out = []
    limit, offset = 200, 0
    headers = {"Authorization": f"OAuth {settings.yandex_disk_token}"}
    while True:
        params = {
            "path": root_path,
            "limit": limit,
            "offset": offset,
            "fields": "_embedded.items.name,_embedded.items.path,_embedded.items.type,_embedded.items.mime_type,_embedded.items.size,_embedded.items.md5",
        }
        r = requests.get(f"{YA_API}/resources", headers=headers, params=params, timeout=30)
        r.raise_for_status()
        data = r.json()
        items = (data.get("_embedded") or {}).get("items") or []
        for it in items:
            if it.get("type") == "file":
                out.append(it)
        if len(items) < limit:
            break
        offset += limit
    return out


def _kb_update_pages(db, document_id: int, pages: int | None):
    if pages is None:
        return
    db.execute(sa_text("UPDATE kb_documents SET pages=:p, updated_at=now() WHERE id=:id"), {"p": pages, "id": document_id})
    db.commit()

# –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ PDF (–±–µ–∑ –ø–∞—Ä–æ–ª—è). –ó–∞—â–∏—â—ë–Ω–Ω—ã–µ PDF —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º, –Ω–æ –Ω–µ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º.

async def kb_sync_pdf(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        if not _is_admin(update.effective_user.id):
            return await m.reply_text("–¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞.")
        await m.reply_text("üìÑ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è PDF –Ω–∞—á–∞–ª–∞—Å—å‚Ä¶")

        root = settings.yandex_root_path
        files = [f for f in _ya_list_files(root) if (f.get("name") or "").lower().endswith(".pdf")]

        touched_docs = len(files)
        indexed_docs = 0
        indexed_chunks = 0

        with SessionLocal() as db:
            emb_kind = _kb_embedding_column_kind(db)  # 'vector' | 'bytea' | 'none'

            # –î–µ–∞–∫—Ç–∏–≤–∏—Ä—É–µ–º PDF, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –Ω–∞ –¥–∏—Å–∫–µ
            present = { (f.get("path") or f.get("name")) for f in files if (f.get("path") or f.get("name")) }
            rows = db.execute(sa_text("SELECT id, path, is_active FROM kb_documents WHERE mime LIKE 'application/pdf%'")).mappings().all()
            for r in rows:
                if r["path"] not in present and r["is_active"]:
                    db.execute(sa_text("UPDATE kb_documents SET is_active=FALSE, updated_at=now() WHERE id=:id"), {"id": r["id"]})
            db.commit()

            for it in files:
                path  = it.get("path") or it.get("name")
                mime  = it.get("mime_type") or "application/pdf"
                size  = int(it.get("size") or 0)
                etag  = it.get("md5") or ""
                if not path:
                    continue

                doc_id = _kb_upsert_document(db, path=path, mime=mime, size=size, etag=etag)

                # –°–∫–∞—á–∏–≤–∞–µ–º
                try:
                    blob = ya_download(path)
                except Exception as e:
                    log.exception("pdf download failed: %s (%s)", path, e)
                    continue

                # –ü–∞—Ä—Å–∏–º
                try:
                    txt, pages, is_prot = _pdf_extract_text(blob)
                except Exception as e:
                    log.exception("pdf parse failed: %s (%s)", path, e)
                    continue

                _kb_update_pages(db, doc_id, pages if pages else None)

                # –ó–∞—â–∏—â—ë–Ω–Ω—ã–π –∏–ª–∏ –ø—É—Å—Ç–æ–π PDF ‚Äî –Ω–µ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º
                if is_prot or not txt.strip():
                    log.info("pdf skipped (protected or empty): %s", path)
                    continue

                # –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Ü–µ–ª–∏–∫–æ–º –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
                _kb_clear_chunks(db, doc_id)

                chunks = _chunk_text(txt, settings.chunk_size, settings.chunk_overlap)
                embs = _get_embeddings(chunks) if emb_kind in ("vector","bytea") else [[] for _ in chunks]

                doc_failed = False
                inserted = 0
                for idx, (ch, ve) in enumerate(zip(chunks, embs)):
                    meta = {"path": path, "mime": mime}
                    if emb_kind == "vector":
                        place, params = _format_vector_sql(ve)
                    elif emb_kind == "bytea":
                        place, params = _format_bytea_sql(ve)
                    else:
                        place, params = " NULL ", {}

                    sql = f"""
                        INSERT INTO kb_chunks (document_id, chunk_index, content, meta, embedding)
                        VALUES (:d, :i, :c, :meta, {place})
                    """
                    p = {"d": doc_id, "i": idx, "c": ch, "meta": json.dumps(meta)}
                    p.update(params)
                    try:
                        db.execute(sa_text(sql), p)
                        inserted += 1
                        if inserted % 200 == 0:
                            db.commit()
                    except Exception as e:
                        log.exception("insert pdf chunk failed (doc_id=%s, idx=%s): %s", doc_id, idx, e)
                        doc_failed = True
                        continue

                db.commit()

                if not doc_failed and inserted > 0:
                    indexed_docs += 1
                    indexed_chunks += inserted

        await m.reply_text(
            "‚úÖ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è PDF –∑–∞–≤–µ—Ä—à–µ–Ω–∞.\n"
            f"–î–æ–∫—É–º–µ–Ω—Ç–æ–≤ —É—á—Ç–µ–Ω–æ: {touched_docs}\n"
            f"–ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ: {indexed_docs} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, {indexed_chunks} —á–∞–Ω–∫–æ–≤"
        )
    except Exception as e:
        log.exception("kb_sync_pdf failed")
        await (update.effective_message or update.message).reply_text(f"‚ö† kb_sync_pdf: {e}")

# --- KB sync (—É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–∑–æ–≤ indexer) ---
import os, re, inspect, asyncio

async def kb_sync(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    if not _is_admin(update.effective_user.id):
        return await m.reply_text("‚õî –î–æ—Å—Ç—É–ø —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∞–º.")
    await m.reply_text("üîÑ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–ø—É—â–µ–Ω–∞...")

    try:
        from bot.knowledge_base import indexer

        explicit = getattr(settings, "kb_sync_entrypoint", None) or os.getenv("KB_SYNC_ENTRYPOINT")
        fn = getattr(indexer, explicit, None) if explicit else None
        if not fn:
            for name in ("sync_kb","sync_all","sync_from_yandex","sync","run_sync","full_sync",
                         "reindex","index_all","ingest_all","ingest","main"):
                if hasattr(indexer, name) and callable(getattr(indexer, name)):
                    fn = getattr(indexer, name); break
        if not fn:
            for name in dir(indexer):
                if name.startswith("_"): continue
                if re.search(r"(sync|index|ingest)", name, re.I) and callable(getattr(indexer, name)):
                    fn = getattr(indexer, name); break
        if not fn:
            raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω entrypoint –≤ indexer.py. –£–∫–∞–∂–∏—Ç–µ KB_SYNC_ENTRYPOINT –∏–ª–∏ —Ä–µ–∞–ª–∏–∑—É–π—Ç–µ sync_kb(session).")

        sig = inspect.signature(fn)
        kwargs, session_to_close = {}, None
        for p in sig.parameters.values():
            nm = p.name.lower()
            if nm in ("session","db","dbsession","conn","connection"):
                sess = SessionLocal(); kwargs[p.name] = sess; session_to_close = sess
            elif nm in ("sessionlocal","session_factory","factory","engine"):
                kwargs[p.name] = SessionLocal
            elif nm in ("settings","cfg","config","conf"):
                kwargs[p.name] = settings
            elif p.default is inspect._empty:
                kwargs[p.name] = None  # –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä
        def _call():
            try: return fn(**kwargs)
            finally:
                if session_to_close is not None:
                    try: session_to_close.close()
                    except Exception: pass
        result = await asyncio.to_thread(_call)

        if isinstance(result, dict):
            upd = result.get("updated"); skp = result.get("skipped"); tot = result.get("total")
            msg = "‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞."
            if upd is not None or skp is not None or tot is not None:
                msg += f" –û–±–Ω–æ–≤–ª–µ–Ω–æ: {upd or 0}, –ø—Ä–æ–ø—É—â–µ–Ω–æ: {skp or 0}, –≤—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –Ω–∞ –¥–∏—Å–∫–µ: {tot or 0}."
            return await m.reply_text(msg)
        elif isinstance(result, (tuple, list)) and len(result) >= 2:
            return await m.reply_text(f"‚úÖ –ì–æ—Ç–æ–≤–æ: –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ {result[0]}, —á–∞–Ω–∫–æ–≤ {result[1]}")
        else:
            return await m.reply_text("‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
    except Exception as e:
        log.exception("kb_sync failed")
        return await m.reply_text(f"‚ö† –û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}")


KB_PAGE_SIZE = 10



async def kb_chunks_force(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        if not _is_admin(update.effective_user.id):
            return await m.reply_text("–¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞.")

        from sqlalchemy import text as sa_text
        notes = []

        with SessionLocal() as db:
            # 0) vector –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π (–±–µ–∑ –ø–∞–Ω–∏–∫–∏ –ø—Ä–∏ –æ—à–∏–±–∫–µ)
            try:
                db.execute(sa_text("CREATE EXTENSION IF NOT EXISTS vector;"))
                db.commit()
            except Exception:
                db.rollback()
                notes.append("[warn] CREATE EXTENSION vector failed")

            # 1) –°–æ–∑–¥–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É (–µ—Å–ª–∏ vector –µ—Å—Ç—å ‚Äî —Å vector(3072), –∏–Ω–∞—á–µ fallback BYTEA)
            has_vector_type = False
            try:
                has_vector_type = db.execute(sa_text(
                    "SELECT EXISTS(SELECT 1 FROM pg_type WHERE typname='vector')"
                )).scalar()
            except Exception:
                pass

            try:
                if has_vector_type:
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS kb_chunks (
                            id           BIGSERIAL PRIMARY KEY,
                            document_id  BIGINT NOT NULL,
                            chunk_index  INTEGER NOT NULL,
                            content      TEXT NOT NULL,
                            meta         JSON,
                            embedding    vector(3072)
                        );
                    """))
                else:
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS kb_chunks (
                            id           BIGSERIAL PRIMARY KEY,
                            document_id  BIGINT NOT NULL,
                            chunk_index  INTEGER NOT NULL,
                            content      TEXT NOT NULL,
                            meta         JSON,
                            embedding    BYTEA
                        );
                    """))
                    notes.append("[info] fallback: embedding BYTEA (–Ω–µ—Ç —Ç–∏–ø–∞ vector)")
                db.commit()
            except Exception as e:
                db.rollback()
                raise RuntimeError(f"CREATE TABLE failed: {e}")

            # 2) –ü—Ä–æ—Å—Ç–µ–π—à–∏–µ –∏–Ω–¥–µ–∫—Å—ã (–±–µ–∑ ivfflat) ‚Äî –æ—Ç–¥–µ–ª—å–Ω–∞—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è
            try:
                db.execute(sa_text("CREATE INDEX IF NOT EXISTS ix_kb_chunks_document_id ON kb_chunks(document_id);"))
                db.execute(sa_text("CREATE INDEX IF NOT EXISTS ix_kb_chunks_doc_chunk ON kb_chunks(document_id, chunk_index);"))
                db.commit()
            except Exception as e:
                db.rollback()
                notes.append(f"[warn] create simple indexes failed: {e}")

            # 3) –í–Ω–µ—à–Ω–∏–π –∫–ª—é—á –Ω–∞ kb_documents ‚Äî –æ—Ç–¥–µ–ª—å–Ω–∞—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è
            try:
                db.execute(sa_text("""
                    DO $$
                    BEGIN
                        IF NOT EXISTS (
                           SELECT 1 FROM pg_constraint WHERE conname='fk_kb_chunks_docs'
                        ) THEN
                           ALTER TABLE kb_chunks
                           ADD CONSTRAINT fk_kb_chunks_docs
                           FOREIGN KEY (document_id) REFERENCES kb_documents(id) ON DELETE CASCADE;
                        END IF;
                    END $$;
                """))
                db.commit()
            except Exception as e:
                db.rollback()
                notes.append(f"[warn] add FK failed: {e}")

        await m.reply_text("‚úÖ kb_chunks —Å–æ–∑–¥–∞–Ω–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–∞ (–±–µ–∑ ivfflat).\n" + ("\n".join(notes) if notes else ""))
    except Exception as e:
        import traceback
        tb = traceback.format_exc(limit=3)
        log.exception("kb_chunks_force failed")
        await m.reply_text(f"‚ö† kb_chunks_force: {e}\n{tb}")

# –î–æ–≤–µ–¥—ë–º kb_chunks: —É–±–µ—Ä—ë–º ivfflat, –¥–æ–±–∞–≤–∏–º FK –∏ —Ç–µ—Ö.–∏–Ω–¥–µ–∫—Å—ã
async def kb_chunks_fix(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        if not _is_admin(update.effective_user.id):
            return await m.reply_text("–¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞.")
        from sqlalchemy import text as sa_text
        with SessionLocal() as db:
            # —É–¥–∞–ª–∏—Ç—å ivfflat-–∏–Ω–¥–µ–∫—Å –µ—Å–ª–∏ –æ–Ω —É—Å–ø–µ–ª —Å–æ–∑–¥–∞—Ç—å—Å—è —á–∞—Å—Ç–∏—á–Ω–æ (–Ω–∞ –≤—Å—è–∫–∏–π)
            try:
                db.execute(sa_text("DROP INDEX IF EXISTS kb_chunks_embedding_idx;"))
                db.commit()
            except Exception:
                db.rollback()
            # –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º
            db.execute(sa_text("CREATE INDEX IF NOT EXISTS ix_kb_chunks_document_id ON kb_chunks(document_id);"))
            db.execute(sa_text("CREATE INDEX IF NOT EXISTS ix_kb_chunks_doc_chunk ON kb_chunks(document_id, chunk_index);"))
            # –¥–æ–±–∞–≤–∏—Ç—å FK –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
            try:
                db.execute(sa_text("""
                    DO $$
                    BEGIN
                        IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='fk_kb_chunks_docs') THEN
                            ALTER TABLE kb_chunks
                            ADD CONSTRAINT fk_kb_chunks_docs
                            FOREIGN KEY (document_id) REFERENCES kb_documents(id) ON DELETE CASCADE;
                        END IF;
                    END $$;
                """))
            except Exception:
                pass
            db.commit()
        await m.reply_text("‚úÖ kb_chunks –ø–æ—á–∏–Ω–µ–Ω–∞: –±–µ–∑ ivfflat, —Å FK –∏ –∏–Ω–¥–µ–∫—Å–∞–º–∏.")
    except Exception:
        log.exception("kb_chunks_fix failed")
        await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—á–∏–Ω–∏—Ç—å kb_chunks. –°–º–æ—Ç—Ä–∏ –ª–æ–≥–∏.")

# –°–æ–∑–¥–∞—Ç—å kb_chunks –Ω–∞–¥—ë–∂–Ω–æ: —Å vector, –∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ ‚Äî fallback –±–µ–∑ vector
async def kb_chunks_create(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        if not _is_admin(update.effective_user.id):
            return await m.reply_text("–¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞.")

        from sqlalchemy import text as sa_text
        created_note = ""
        with SessionLocal() as db:
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è
            search_path = db.execute(sa_text("SHOW search_path")).scalar()
            has_tbl = db.execute(sa_text("SELECT to_regclass('public.kb_chunks') IS NOT NULL")).scalar()
            has_vector_ext = db.execute(sa_text(
                "SELECT EXISTS(SELECT 1 FROM pg_extension WHERE extname='vector')"
            )).scalar()
            has_vector_type = db.execute(sa_text(
                "SELECT EXISTS(SELECT 1 FROM pg_type WHERE typname='vector')"
            )).scalar()

            if has_tbl:
                return await m.reply_text("‚úÖ kb_chunks —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.")

            # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π ‚Äî —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
            if not has_vector_ext:
                try:
                    db.execute(sa_text("CREATE EXTENSION IF NOT EXISTS vector;"))
                    db.commit()
                    has_vector_ext = True
                except Exception as e:
                    db.rollback()
                    # –Ω–µ –ø–∞–¥–∞–µ–º ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º fallback
                    created_note += f"[warn] CREATE EXTENSION failed: {e}\n"

            # –û–±–Ω–æ–≤–∏–º –Ω–∞–ª–∏—á–∏–µ —Ç–∏–ø–∞
            if not has_vector_type:
                has_vector_type = db.execute(sa_text(
                    "SELECT EXISTS(SELECT 1 FROM pg_type WHERE typname='vector')"
                )).scalar()

            try:
                if has_vector_type:
                    # –û—Å–Ω–æ–≤–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç: —Å vector(3072)
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS kb_chunks (
                            id           BIGSERIAL PRIMARY KEY,
                            document_id  BIGINT NOT NULL,
                            chunk_index  INTEGER NOT NULL,
                            content      TEXT NOT NULL,
                            meta         JSON,
                            embedding    vector(3072)
                        );
                    """))
                    # –ò–Ω–¥–µ–∫—Å—ã –∏ FK (best-effort)
                    try:
                        db.execute(sa_text(
                            "CREATE INDEX IF NOT EXISTS ix_kb_chunks_document_id ON kb_chunks(document_id);"))
                        db.execute(sa_text("""
                            CREATE INDEX IF NOT EXISTS kb_chunks_embedding_idx
                            ON kb_chunks USING ivfflat (embedding vector_cosine_ops);
                        """))
                    except Exception as e:
                        created_note += f"[warn] index create failed: {e}\n"
                    try:
                        db.execute(sa_text("""
                            DO $$
                            BEGIN
                                IF NOT EXISTS (
                                   SELECT 1 FROM pg_constraint WHERE conname = 'fk_kb_chunks_docs'
                                ) THEN
                                   ALTER TABLE kb_chunks
                                   ADD CONSTRAINT fk_kb_chunks_docs
                                   FOREIGN KEY (document_id)
                                   REFERENCES kb_documents(id) ON DELETE CASCADE;
                                END IF;
                            END $$;
                        """))
                    except Exception as e:
                        created_note += f"[warn] FK create failed: {e}\n"

                    db.commit()
                    return await m.reply_text(
                        "‚úÖ kb_chunks —Å–æ–∑–¥–∞–Ω–∞ (vector). "
                        f"\nsearch_path={search_path}\n{created_note or ''}".strip()
                    )

                # Fallback: –±–µ–∑ vector ‚Äî embedding –∫–∞–∫ BYTEA, –±–µ–∑ ivfflat
                db.execute(sa_text("""
                    CREATE TABLE IF NOT EXISTS kb_chunks (
                        id           BIGSERIAL PRIMARY KEY,
                        document_id  BIGINT NOT NULL,
                        chunk_index  INTEGER NOT NULL,
                        content      TEXT NOT NULL,
                        meta         JSON,
                        embedding    BYTEA
                    );
                """))
                try:
                    db.execute(sa_text(
                        "CREATE INDEX IF NOT EXISTS ix_kb_chunks_document_id ON kb_chunks(document_id);"))
                except Exception as e:
                    created_note += f"[warn] fallback index failed: {e}\n"
                try:
                    db.execute(sa_text("""
                        DO $$
                        BEGIN
                            IF NOT EXISTS (
                               SELECT 1 FROM pg_constraint WHERE conname = 'fk_kb_chunks_docs'
                            ) THEN
                               ALTER TABLE kb_chunks
                               ADD CONSTRAINT fk_kb_chunks_docs
                               FOREIGN KEY (document_id)
                               REFERENCES kb_documents(id) ON DELETE CASCADE;
                            END IF;
                        END $$;
                    """))
                except Exception as e:
                    created_note += f"[warn] fallback FK failed: {e}\n"

                db.commit()
                return await m.reply_text(
                    "‚úÖ kb_chunks —Å–æ–∑–¥–∞–Ω–∞ (fallback –±–µ–∑ vector). "
                    f"\nsearch_path={search_path}\n{created_note or ''}".strip()
                )

            except Exception as e:
                db.rollback()
                raise e

    except Exception as e:
        log.exception("kb_chunks_create failed")
        await m.reply_text(f"‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å kb_chunks: {e}")

# —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥ –≤—Ä—É—á–Ω—É—é
async def dialog_new(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        tg = update.effective_user.id
        with SessionLocal() as db:
            did = _create_new_dialog_for_tg(db, tg)
        await m.reply_text(f"‚úÖ –°–æ–∑–¥–∞–Ω –¥–∏–∞–ª–æ–≥ #{did}")
    except Exception:
        log.exception("dialog_new failed")
        await m.reply_text("‚ö† –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞")

def _create_new_dialog_for_tg(db, tg_id: int) -> int:
    uid = _exec_scalar(db, "SELECT id FROM users WHERE tg_user_id=:tg ORDER BY id LIMIT 1", tg=tg_id)
    if not uid:
        uid = _ensure_user(db, tg_id)

    today = datetime.now().date().isoformat()
    cnt = _exec_scalar(db, """
        SELECT count(*) FROM dialogs d
        JOIN users u ON u.id = d.user_id
        WHERE u.tg_user_id = :tg AND d.is_deleted = FALSE
    """, tg=tg_id) or 0
    title = f"{today} | –¥–∏–∞–ª–æ–≥ {cnt+1}"

    did = _exec_scalar(db, """
        INSERT INTO dialogs (user_id, title, style, model, is_deleted, created_at, last_message_at)
        VALUES (:u, :t, :s, :m, FALSE, now(), NULL) RETURNING id
    """, u=uid, t=title, s="pro", m=settings.openai_model)
    db.commit()
    return did

async def pgvector_check(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        with SessionLocal() as db:
            avail = db.execute(sa_text(
                "SELECT EXISTS(SELECT 1 FROM pg_available_extensions WHERE name='vector')"
            )).scalar()
            installed = db.execute(sa_text(
                "SELECT EXISTS(SELECT 1 FROM pg_extension WHERE extname='vector')"
            )).scalar()
        await (update.effective_message or update.message).reply_text(
            f"pgvector –¥–æ—Å—Ç—É–ø–Ω–æ: {'‚úÖ' if avail else '‚ùå'}\n"
            f"pgvector —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ: {'‚úÖ' if installed else '‚ùå'}"
        )
    except Exception:
        log.exception("pgvector_check failed")
        await (update.effective_message or update.message).reply_text("‚ö† –û—à–∏–±–∫–∞ pgvector_check. –°–º–æ—Ç—Ä–∏ –ª–æ–≥–∏.")

async def repair_schema(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    –ß–∏–Ω–∏—Ç —Å—Ö–µ–º—É –ø–æ —à–∞–≥–∞–º –∏ —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ—Å–ª–µ –ö–ê–ñ–î–û–ô —Ç–∞–±–ª–∏—Ü—ã.
    –î–∞–∂–µ –µ—Å–ª–∏ –Ω–∞ kb_* —É–ø–∞–¥—ë—Ç, –±–∞–∑–æ–≤—ã–µ —Ç–∞–±–ª–∏—Ü—ã users/dialogs/messages –æ—Å—Ç–∞–Ω—É—Ç—Å—è.
    """
    m = update.effective_message or update.message
    try:
        if not _is_admin(update.effective_user.id):
            return await m.reply_text("–¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞.")

        await m.reply_text("üß∞ –†–µ–º–æ–Ω—Ç —Å—Ö–µ–º—ã –Ω–∞—á–∞—Ç. –ü–∏—à—É –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ –ª–æ–≥–∏...")

        from sqlalchemy import text as sa_text
        created = []
        with SessionLocal() as db:

            def has(table: str) -> bool:
                return bool(db.execute(sa_text("SELECT to_regclass(:t)"), {"t": f"public.{table}"}).scalar())

            # 0) vector extension ‚Äî –æ—Ç–¥–µ–ª—å–Ω–æ –∏ –±–µ–∑ –ø–∞–Ω–∏–∫–∏
            try:
                db.execute(sa_text("CREATE EXTENSION IF NOT EXISTS vector;"))
                db.commit()
                log.info("repair: extension vector OK (–∏–ª–∏ —É–∂–µ –±—ã–ª–æ)")
            except Exception:
                db.rollback()
                log.exception("repair: CREATE EXTENSION vector failed ‚Äî –ø—Ä–æ–¥–æ–ª–∂—É –±–µ–∑ –Ω–µ–≥–æ")

            # 1) USERS ‚Äî –°–ù–ê–ß–ê–õ–ê –ë–ê–ó–ê
            if not has("users"):
                db.execute(sa_text("""
                    CREATE TABLE IF NOT EXISTS users (
                        id           BIGSERIAL PRIMARY KEY,
                        tg_user_id   BIGINT UNIQUE NOT NULL,
                        is_admin     BOOLEAN NOT NULL DEFAULT FALSE,
                        is_allowed   BOOLEAN NOT NULL DEFAULT TRUE,
                        lang         TEXT,
                        created_at   TIMESTAMPTZ NOT NULL DEFAULT now()
                    );
                """))
                db.commit(); created.append("users"); log.info("repair: created users")

            # 2) DIALOGS
            if not has("dialogs"):
                db.execute(sa_text("""
                    CREATE TABLE IF NOT EXISTS dialogs (
                        id              BIGSERIAL PRIMARY KEY,
                        user_id         BIGINT NOT NULL,
                        title           TEXT,
                        style           VARCHAR(20) NOT NULL DEFAULT 'expert',
                        model           TEXT,
                        is_deleted      BOOLEAN NOT NULL DEFAULT FALSE,
                        created_at      TIMESTAMPTZ NOT NULL DEFAULT now(),
                        last_message_at TIMESTAMPTZ
                    );
                """))
                try:
                    db.execute(sa_text("""
                        DO $$
                        BEGIN
                            IF NOT EXISTS (
                               SELECT 1 FROM pg_constraint WHERE conname = 'fk_dialogs_users'
                            ) THEN
                               ALTER TABLE dialogs
                               ADD CONSTRAINT fk_dialogs_users
                               FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE;
                            END IF;
                        END $$;
                    """))
                except Exception:
                    log.exception("repair: FK dialogs->users skipped")
                db.commit(); created.append("dialogs"); log.info("repair: created dialogs")

            # 3) MESSAGES
            if not has("messages"):
                db.execute(sa_text("""
                    CREATE TABLE IF NOT EXISTS messages (
                        id         BIGSERIAL PRIMARY KEY,
                        dialog_id  BIGINT NOT NULL,
                        role       VARCHAR(20) NOT NULL,
                        content    TEXT NOT NULL,
                        tokens     INTEGER,
                        created_at TIMESTAMPTZ NOT NULL DEFAULT now()
                    );
                """))
                try:
                    db.execute(sa_text("""
                        DO $$
                        BEGIN
                            IF NOT EXISTS (
                               SELECT 1 FROM pg_constraint WHERE conname = 'fk_messages_dialogs'
                            ) THEN
                               ALTER TABLE messages
                               ADD CONSTRAINT fk_messages_dialogs
                               FOREIGN KEY (dialog_id) REFERENCES dialogs(id) ON DELETE CASCADE;
                            END IF;
                        END $$;
                    """))
                except Exception:
                    log.exception("repair: FK messages->dialogs skipped")
                db.commit(); created.append("messages"); log.info("repair: created messages")

            # --- –ë–ª–æ–∫ –ë–ó: –¥–µ–ª–∞–µ–º best-effort, –∫–∞–∂–¥—ã–π —à–∞–≥ –≤ —Å–≤–æ–µ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ ---

            # 4) KB_DOCUMENTS
            try:
                if not has("kb_documents"):
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS kb_documents (
                            id         BIGSERIAL PRIMARY KEY,
                            path       TEXT UNIQUE NOT NULL,
                            etag       TEXT,
                            mime       TEXT,
                            pages      INTEGER,
                            bytes      BIGINT,
                            updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
                            is_active  BOOLEAN NOT NULL DEFAULT TRUE
                        );
                    """))
                    db.commit(); created.append("kb_documents"); log.info("repair: created kb_documents")
            except Exception:
                db.rollback(); log.exception("repair: create kb_documents failed (–ø—Ä–æ–ø—É—Å–∫–∞—é)")

            # 5) KB_CHUNKS
            try:
                if not has("kb_chunks"):
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS kb_chunks (
                            id           BIGSERIAL PRIMARY KEY,
                            document_id  BIGINT NOT NULL,
                            chunk_index  INTEGER NOT NULL,
                            content      TEXT NOT NULL,
                            meta         JSON,
                            embedding    vector(3072)
                        );
                    """))
                    try:
                        db.execute(sa_text("CREATE INDEX IF NOT EXISTS ix_kb_chunks_document_id ON kb_chunks(document_id);"))
                        db.execute(sa_text("""
                            CREATE INDEX IF NOT EXISTS kb_chunks_embedding_idx
                            ON kb_chunks USING ivfflat (embedding vector_cosine_ops);
                        """))
                    except Exception:
                        log.exception("repair: kb_chunks indexes skipped")
                    try:
                        db.execute(sa_text("""
                            DO $$
                            BEGIN
                                IF NOT EXISTS (
                                   SELECT 1 FROM pg_constraint WHERE conname = 'fk_kb_chunks_docs'
                                ) THEN
                                   ALTER TABLE kb_chunks
                                   ADD CONSTRAINT fk_kb_chunks_docs
                                   FOREIGN KEY (document_id) REFERENCES kb_documents(id) ON DELETE CASCADE;
                                END IF;
                            END $$;
                        """))
                    except Exception:
                        log.exception("repair: FK kb_chunks->kb_documents skipped")
                    db.commit(); created.append("kb_chunks"); log.info("repair: created kb_chunks")
            except Exception:
                db.rollback(); log.exception("repair: create kb_chunks failed (–≤–æ–∑–º–æ–∂–Ω–æ, –Ω–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è vector)")

            # 6) DIALOG_KB_LINKS
            try:
                if not has("dialog_kb_links"):
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS dialog_kb_links (
                            id          BIGSERIAL PRIMARY KEY,
                            dialog_id   BIGINT NOT NULL,
                            document_id BIGINT NOT NULL,
                            created_at  TIMESTAMPTZ NOT NULL DEFAULT now()
                        );
                    """))
                    db.commit(); created.append("dialog_kb_links"); log.info("repair: created dialog_kb_links")
            except Exception:
                db.rollback(); log.exception("repair: create dialog_kb_links failed")

            # 7) PDF_PASSWORDS
            try:
                if not has("pdf_passwords"):
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS pdf_passwords (
                            id          BIGSERIAL PRIMARY KEY,
                            dialog_id   BIGINT NOT NULL,
                            document_id BIGINT NOT NULL,
                            pwd_hash    TEXT,
                            created_at  TIMESTAMPTZ NOT NULL DEFAULT now()
                        );
                    """))
                    db.commit(); created.append("pdf_passwords"); log.info("repair: created pdf_passwords")
            except Exception:
                db.rollback(); log.exception("repair: create pdf_passwords failed")

            # 8) AUDIT_LOG
            try:
                if not has("audit_log"):
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS audit_log (
                            id         BIGSERIAL PRIMARY KEY,
                            user_id    BIGINT,
                            action     TEXT,
                            meta       JSON,
                            created_at TIMESTAMPTZ NOT NULL DEFAULT now()
                        );
                    """))
                    db.commit(); created.append("audit_log"); log.info("repair: created audit_log")
            except Exception:
                db.rollback(); log.exception("repair: create audit_log failed")

        await m.reply_text("‚úÖ –ì–æ—Ç–æ–≤–æ. –°–æ–∑–¥–∞–Ω–æ: " + (", ".join(created) if created else "–Ω–∏—á–µ–≥–æ (–≤—Å—ë —É–∂–µ –±—ã–ª–æ)"))
    except Exception:
        log.exception("repair_schema failed (outer)")
        await m.reply_text("‚ö† –û—à–∏–±–∫–∞ repair_schema. –°–º–æ—Ç—Ä–∏ –ª–æ–≥–∏.")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ç–∞–±–ª–∏—Ü –≤ –ë–î
async def dbcheck(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        with SessionLocal() as db:
            rows = db.execute(sa_text("""
                select 'users' as t, to_regclass('public.users') is not null as ok
                union all select 'dialogs',          to_regclass('public.dialogs') is not null
                union all select 'messages',         to_regclass('public.messages') is not null
                union all select 'kb_documents',     to_regclass('public.kb_documents') is not null
                union all select 'kb_chunks',        to_regclass('public.kb_chunks') is not null
                union all select 'dialog_kb_links',  to_regclass('public.dialog_kb_links') is not null
                union all select 'pdf_passwords',    to_regclass('public.pdf_passwords') is not null
                union all select 'audit_log',        to_regclass('public.audit_log') is not null
            """)).all()
        lines = ["–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∞–±–ª–∏—Ü:"]
        for t, ok in rows:
            lines.append(f"{'‚úÖ' if ok else '‚ùå'} {t}")
        await (update.effective_message or update.message).reply_text("\n".join(lines))
    except Exception:
        log.exception("dbcheck failed")
        await (update.effective_message or update.message).reply_text("‚ö† –û—à–∏–±–∫–∞ dbcheck. –°–º–æ—Ç—Ä–∏ –ª–æ–≥–∏.")

# –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–≥–æ–Ω –º–∏–≥—Ä–∞—Ü–∏–π Alembic (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞)
async def migrate(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        if not _is_admin(update.effective_user.id):
            return await (update.effective_message or update.message).reply_text("–¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞.")
        await (update.effective_message or update.message).reply_text("üîß –ó–∞–ø—É—Å–∫–∞—é –º–∏–≥—Ä–∞—Ü–∏–∏...")
        # –ü—Ä–æ–≥—Ä–∞–º–º–Ω—ã–π –≤—ã–∑–æ–≤ Alembic
        import os
        from alembic.config import Config
        from alembic import command
        os.environ["DATABASE_URL"] = settings.database_url
        cfg = Config("alembic.ini")
        command.upgrade(cfg, "head")
        await (update.effective_message or update.message).reply_text("‚úÖ –ú–∏–≥—Ä–∞—Ü–∏–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã.")
    except Exception:
        log.exception("migrate failed")
        await (update.effective_message or update.message).reply_text("‚ö† –û—à–∏–±–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏. –°–º–æ—Ç—Ä–∏ –ª–æ–≥–∏.")

async def health(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        with SessionLocal() as db:
            db.execute(sa_text("SELECT 1"))
        await update.message.reply_text("‚úÖ OK: DB connection")
    except Exception:
        log.exception("health failed")
        await update.message.reply_text("‚ùå FAIL: DB connection")

async def stats(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        with SessionLocal() as db:
            did = _get_active_dialog_id(db, update.effective_user.id)
            row = db.execute(sa_text(
                "SELECT id, title, model, style, created_at, last_message_at "
                "FROM dialogs WHERE id=:d"
            ), {"d": did}).fetchone()

            # –°–æ–æ–±—â–µ–Ω–∏—è –∏–º–µ–Ω–Ω–æ —ç—Ç–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞
            msgs = db.execute(sa_text(
                "SELECT count(*) FROM messages WHERE dialog_id=:d"
            ), {"d": did}).scalar() or 0

            # –ü–æ–¥–∫–ª—é—á—ë–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
            docs = db.execute(sa_text(
                "SELECT d.path "
                "FROM kb_documents d "
                "JOIN dialog_kb_links l ON l.document_id=d.id "
                "WHERE l.dialog_id=:d ORDER BY d.path"
            ), {"d": did}).fetchall()
            doc_list = "\n".join(f"‚Ä¢ {r[0]}" for r in docs) or "‚Äî"

            total_dialogs = db.execute(sa_text(
                "SELECT count(*) FROM dialogs WHERE user_id=("
                "  SELECT id FROM users WHERE tg_user_id=:tg LIMIT 1)"
            ), {"tg": update.effective_user.id}).scalar() or 0

        text = (
            f"whoami: tg={update.effective_user.id}, role={'admin' if _is_admin(update.effective_user.id) else 'allowed'}, lang={context.user_data.get('lang','ru')}\n\n"
            f"–î–∏–∞–ª–æ–≥: {row.id} ‚Äî {row.title}\n"
            f"–ú–æ–¥–µ–ª—å: {row.model} | –°—Ç–∏–ª—å: {row.style}\n"
            f"–°–æ–∑–¥–∞–Ω: {row.created_at or '-'} | –ò–∑–º–µ–Ω—ë–Ω: {row.last_message_at or '-'}\n"
            f"–ü–æ–¥–∫–ª—é—á—ë–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã ({len(docs)}):\n{doc_list}\n\n"
            f"–í—Å–µ–≥–æ —Ç–≤–æ–∏—Ö –¥–∏–∞–ª–æ–≥–æ–≤: {total_dialogs} | –°–æ–æ–±—â–µ–Ω–∏–π –≤ —ç—Ç–æ–º –¥–∏–∞–ª–æ–≥–µ: {msgs}"
        )
        return await m.reply_text(text)
    except Exception:
        log.exception("/stats failed")
        return await m.reply_text("‚ö† –û—à–∏–±–∫–∞ /stats")

async def dialog_cb(update: Update, context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    await q.answer()
    try:
        data = q.data or ""
        if data.startswith("dlg:open:"):
            dlg_id = int(data.split(":")[-1])
            await q.edit_message_text(f"–û—Ç–∫—Ä—ã—Ç –¥–∏–∞–ª–æ–≥ #{dlg_id}")
            return

        if data == "dlg:nop" or data.startswith("dlg:page:"):
            # –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ—Ä–∏—Å—É–µ–º —Å–ø–∏—Å–æ–∫
            return await dialogs(update, context)

        if data.startswith("dlg:rename:"):
            dlg_id = int(data.split(":")[-1])
            context.user_data["rename_dialog_id"] = dlg_id
            await q.edit_message_text("–í–≤–µ–¥–∏—Ç–µ –Ω–æ–≤–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞:")
            return

        if data.startswith("dlg:export:"):
            dlg_id = int(data.split(":")[-1])
            with SessionLocal() as db:
                msgs = _exec_all(
                    db,
                    """
                    SELECT role, content, created_at
                    FROM messages
                    WHERE dialog_id=:d
                    ORDER BY created_at
                    """, d=dlg_id,
                )
            lines = ["# –≠–∫—Å–ø–æ—Ä—Ç –¥–∏–∞–ª–æ–≥–∞", ""]
            for role, content, _ in msgs:
                who = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if role == "user" else "–ë–æ—Ç"
                lines.append(f"**{who}:**\n{content}\n")
            data_bytes = "\n".join(lines).encode("utf-8")
            if HAS_BUFFERED:
                file = BufferedInputFile(data_bytes, filename=f"dialog_{dlg_id}.md")  # type: ignore
            else:
                file = InputFile(data_bytes, filename=f"dialog_{dlg_id}.md")  # type: ignore
            await q.message.reply_document(document=file, caption="–≠–∫—Å–ø–æ—Ä—Ç –≥–æ—Ç–æ–≤")
            return

        if data.startswith("dlg:delete:"):
            dlg_id = int(data.split(":")[-1])
            with SessionLocal() as db:
                db.execute(sa_text("UPDATE dialogs SET is_deleted=TRUE WHERE id=:d"), {"d": dlg_id})
                db.commit()
            await q.edit_message_text(f"–î–∏–∞–ª–æ–≥ #{dlg_id} —É–¥–∞–ª—ë–Ω")
            return
    except Exception:
        log.exception("dialog_cb failed")
        try:
            await q.message.reply_text("‚ö† –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ /dialogs. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
        except Exception:
            pass

async def text_router(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if "rename_dialog_id" in context.user_data:
        dlg_id = context.user_data.pop("rename_dialog_id")
        new_title = (update.message.text or "").strip()[:100]
        if not new_title:
            await update.message.reply_text("–ù–∞–∑–≤–∞–Ω–∏–µ –ø—É—Å—Ç–æ–µ. –û—Ç–º–µ–Ω–µ–Ω–æ.")
            return
        try:
            with SessionLocal() as db:
                db.execute(sa_text("UPDATE dialogs SET title=:t WHERE id=:d"), {"t": new_title, "d": dlg_id})
                db.commit()
            await update.message.reply_text("–ù–∞–∑–≤–∞–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ.")
        except Exception:
            log.exception("rename dialog title failed")
            await update.message.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ.")
        return
    await update.message.reply_text("–ü—Ä–∏–Ω—è—Ç–æ. (–¢–µ–∫—Å—Ç–æ–≤—ã–π —Ä–æ—É—Ç–µ—Ä –±—É–¥–µ—Ç –ø–æ–¥–∫–ª—é—á—ë–Ω –∫ RAG –ø–æ—Å–ª–µ —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ UI.)")

# ---------- KB ----------
PAGE_SIZE = 8

def _exec_page_count(total: int) -> int:
    return max(1, (total + PAGE_SIZE - 1) // PAGE_SIZE)

def _kb_keyboard(rows, page, pages, filter_name, admin: bool):
    nav = []
    if page > 1:
        nav.append(InlineKeyboardButton("¬´ –ù–∞–∑–∞–¥", callback_data=f"kb:list:{page-1}:{filter_name}"))
    nav.append(InlineKeyboardButton(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}/{pages}", callback_data="kb:nop"))
    if page < pages:
        nav.append(InlineKeyboardButton("–í–ø–µ—Ä—ë–¥ ¬ª", callback_data=f"kb:list:{page+1}:{filter_name}"))

    filter_row = [
        InlineKeyboardButton(("üîµ " if filter_name == "all" else "") + "–í—Å–µ", callback_data="kb:list:1:all"),
        InlineKeyboardButton(("üîµ " if filter_name == "connected" else "") + "–ü–æ–¥–∫–ª—é—á—ë–Ω–Ω—ã–µ", callback_data="kb:list:1:connected"),
        InlineKeyboardButton(("üîµ " if filter_name == "available" else "") + "–î–æ—Å—Ç—É–ø–Ω—ã–µ", callback_data="kb:list:1:available"),
    ]

    keyboard = []
    keyboard.extend(rows)
    if nav:
        keyboard.append(nav)
    keyboard.append(filter_row)
    if admin:
        keyboard.append([InlineKeyboardButton("üîÑ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è", callback_data="kb:sync")])
    keyboard.append([InlineKeyboardButton("üìÅ –°—Ç–∞—Ç—É—Å –ë–ó", callback_data="kb:status")])
    return InlineKeyboardMarkup(keyboard)

def _kb_fetch(db, user_id: int, page: int, filter_name: str):
    dlg_id = _exec_scalar(
        db,
        """
        SELECT d.id
        FROM dialogs d
        WHERE d.user_id=:u AND d.is_deleted=FALSE
        ORDER BY d.created_at DESC
        LIMIT 1
        """, u=user_id,
    )
    if not dlg_id:
        dlg_id = _ensure_dialog(db, user_id)

    conn_ids = {row[0] for row in _exec_all(db,
        "SELECT document_id FROM dialog_kb_links WHERE dialog_id=:d", d=dlg_id)}

    where = "WHERE is_active"
    params = {}
    if filter_name == "connected":
        if conn_ids:
            where += " AND id = ANY(:ids)"
            params["ids"] = list(conn_ids)
        else:
            return dlg_id, [], 1, 1, conn_ids
    elif filter_name == "available" and conn_ids:
        where += " AND NOT (id = ANY(:ids))"
        params["ids"] = list(conn_ids)

    total = _exec_scalar(db, f"SELECT COUNT(*) FROM kb_documents {where}", **params) or 0
    pages = _exec_page_count(total)
    page = max(1, min(page, pages))

    rows = _exec_all(
        db,
        f"""
        SELECT id, path
        FROM kb_documents
        {where}
        ORDER BY path
        OFFSET :off LIMIT :lim
        """,
        off=(page - 1) * PAGE_SIZE, lim=PAGE_SIZE, **params
    )
    return dlg_id, rows, page, pages, conn_ids

KB_PAGE_SIZE = 10



async def reset(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        with SessionLocal() as db:
            tg_id = update.effective_user.id
            uid = _ensure_user(db, tg_id)
            did = _ensure_dialog(db, uid)
            db.execute(sa_text("DELETE FROM messages WHERE dialog_id=:d"),   {"d": did})
            db.execute(sa_text("DELETE FROM dialog_kb_links WHERE dialog_id=:d"), {"d": did})
            db.execute(sa_text("DELETE FROM pdf_passwords WHERE dialog_id=:d"),   {"d": did})
            db.execute(sa_text("UPDATE dialogs SET last_message_at=NULL WHERE id=:d"), {"d": did})
            db.commit()
        context.user_data.clear()
        await m.reply_text("‚ôªÔ∏è –î–∏–∞–ª–æ–≥ –æ—á–∏—â–µ–Ω: –∏—Å—Ç–æ—Ä–∏—è, –ø—Ä–∏–≤—è–∑–∫–∏ –ë–ó –∏ –ø–∞—Ä–æ–ª–∏ PDF —Å–±—Ä–æ—à–µ–Ω—ã.")
    except Exception:
        log.exception("reset failed")
        await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å —Å–±—Ä–æ—Å–∏—Ç—å –¥–∏–∞–ª–æ–≥.")

async def error_handler(update: object, context: ContextTypes.DEFAULT_TYPE):
    log.exception("Unhandled error", exc_info=context.error)
    try:
        if hasattr(update, "message") and update.message:
            await update.message.reply_text("‚ö† –ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
        elif hasattr(update, "callback_query") and update.callback_query:
            await update.callback_query.message.reply_text("‚ö† –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
    except Exception:
        pass

# ---------- build ----------

# === /model: inline selector of available OpenAI models ===
def _model_score(mid: str) -> int:
    m = mid.lower()
    if any(x in m for x in ["dall-e", "whisper", "embedding", "text-embedding", "tts", "audio"]):
        return -100
    score = 0
    if "latest" in m: score += 10
    if "preview" in m: score += 6
    if any(x in m for x in ["o4", "4o"]): score += 100
    if "4.1" in m: score += 80
    if "4" in m: score += 60
    if "mini" in m: score += 8
    if "turbo" in m: score += 4
    if "3.5" in m: score += 1
    return score

# —Ñ–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —á–∞—Ç–æ–≤—ã–µ —Å–µ–º–µ–π—Å—Ç–≤–∞ –∏ –∏—Å–∫–ª—é—á–∞–µ–º –≤—Å—ë –ª–∏—à–Ω–µ–µ
def _keep_chat_model(mid: str) -> bool:
    m = mid.lower()
    if any(x in m for x in ["embedding", "text-embedding", "dall-e", "whisper", "tts", "audio", "moderation", "computer-use"]):
        return False
    # —Å–∫—Ä—ã–≤–∞–µ–º —è–≤–Ω—ã–π –º—É—Å–æ—Ä/–Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ
    if m.startswith("babbage") or m.startswith("davinci") or m.startswith("curie") or m.startswith("ada"):
        return False
    if m.startswith("gpt-5"):  # –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º
        return False
    # –æ—Å—Ç–∞–≤–ª—è–µ–º gpt-4/4o/4.1/o4, 3.5, chatgpt-4o-latest
    return any(x in m for x in ["gpt-4", "gpt-3.5", "chatgpt-4o", "o4"])

def _sort_models(models):
    # —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ created (desc), –µ—Å–ª–∏ –µ—Å—Ç—å; –∏–Ω–∞—á–µ –ø–æ —ç–≤—Ä–∏—Å—Ç–∏–∫–µ
    def score(item):
        mid = getattr(item, "id", "")
        created = getattr(item, "created", 0) or 0
        return (created, len(mid) * -1)
    return sorted(models, key=score, reverse=True)

async def model_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        client = OpenAI(api_key=settings.openai_api_key)
        res = client.models.list()
        models = [it for it in getattr(res, "data", []) if _keep_chat_model(getattr(it, "id", ""))]
        models = _sort_models(models)
        ids = [it.id for it in models]

        # —Å–æ—Ö—Ä–∞–Ω–∏–º –¥–ª—è "–ü–æ–∫–∞–∑–∞—Ç—å –µ—â—ë"
        context.user_data["all_models_sorted"] = ids

        top10 = ids[:10]
        buttons = [[InlineKeyboardButton(mid, callback_data=f"model:set:{mid}")] for mid in top10]
        if len(ids) > 10:
            buttons.append([InlineKeyboardButton("–ü–æ–∫–∞–∑–∞—Ç—å –µ—â—ë", callback_data="model:more:2")])
        buttons.append([InlineKeyboardButton("–ó–∞–∫—Ä—ã—Ç—å", callback_data="model:close")])
        await m.reply_text("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞:", reply_markup=InlineKeyboardMarkup(buttons))
    except Exception:
        log.exception("model_menu failed")
        await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π")

def _page_models(ids: list[str], page: int, page_size: int = 10):
    pages = max(1, (len(ids) + page_size - 1) // page_size)
    page = max(1, min(page, pages))
    beg = (page - 1) * page_size
    chunk = ids[beg:beg + page_size]
    rows = [[InlineKeyboardButton(mid, callback_data=f"model:set:{mid}")] for mid in chunk]
    nav = []
    if page > 1:
        nav.append(InlineKeyboardButton("¬´ –ù–∞–∑–∞–¥", callback_data=f"model:more:{page-1}"))
    nav.append(InlineKeyboardButton(f"{page}/{pages}", callback_data="model:nop"))
    if page < pages:
        nav.append(InlineKeyboardButton("–í–ø–µ—Ä—ë–¥ ¬ª", callback_data=f"model:more:{page+1}"))
    rows.append(nav)
    rows.append([InlineKeyboardButton("–ó–∞–∫—Ä—ã—Ç—å", callback_data="model:close")])
    return InlineKeyboardMarkup(rows)

async def model_cb(update: Update, context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    await q.answer()
    try:
        data = q.data or ""
        if data in ("model:close", "model:nop"):
            try: await q.delete_message()
            except Exception: pass
            return

        if data.startswith("model:more:"):
            page = int(data.split(":")[-1])
            ids = context.user_data.get("all_models_sorted") or []
            return await q.edit_message_reply_markup(reply_markup=_page_models(ids, page))

        if data.startswith("model:set:"):
            mid = data.split(":", 2)[-1]
            # –ø—Ä–æ–≤–µ—Ä–∏–º –±—ã—Å—Ç—Ä–æ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
            try:
                client = OpenAI(api_key=settings.openai_api_key)
                client.chat.completions.create(model=mid, messages=[{"role": "user", "content": "ping"}], max_tokens=1)
            except Exception:
                return await q.edit_message_text(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å ¬´{mid}¬ª. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é.")

            tg = update.effective_user.id
            with SessionLocal() as db:
                did = _exec_scalar(db, """
                    SELECT d.id
                    FROM dialogs d
                    JOIN users u ON u.id = d.user_id
                    WHERE u.tg_user_id = :tg AND d.is_deleted = FALSE
                    ORDER BY d.created_at DESC
                    LIMIT 1
                """, tg=tg)
                if not did:
                    return await q.edit_message_text("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞. –ù–∞–∂–º–∏ /dialog_new.")
                db.execute(sa_text("UPDATE dialogs SET model=:m WHERE id=:d"), {"m": mid, "d": did})
                db.commit()
            return await q.edit_message_text(f"‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å: {mid}")
    except Exception:
        log.exception("model_cb failed")
        try: await q.message.reply_text("‚ö† –û—à–∏–±–∫–∞ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏")
        except Exception: pass


def _send_model_page(all_ids, page: int, qmsg):
    PAGE = 10
    pages = max(1, (len(all_ids) + PAGE - 1) // PAGE)
    page = max(1, min(page, pages))
    beg = (page-1) * PAGE
    chunk = all_ids[beg:beg+PAGE]
    rows = [[InlineKeyboardButton(mid, callback_data=f"model:set:{mid}")] for mid in chunk]
    nav = []
    if page > 1:
        nav.append(InlineKeyboardButton("¬´ –ù–∞–∑–∞–¥", callback_data=f"model:more:{page-1}"))
    nav.append(InlineKeyboardButton(f"{page}/{pages}", callback_data="model:nop"))
    if page < pages:
        nav.append(InlineKeyboardButton("–í–ø–µ—Ä—ë–¥ ¬ª", callback_data=f"model:more:{page+1}"))
    rows.append(nav)
    rows.append([InlineKeyboardButton("–ó–∞–∫—Ä—ã—Ç—å", callback_data="model:close")])
    return InlineKeyboardMarkup(rows)

async def mode_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    kb = InlineKeyboardMarkup([
        [InlineKeyboardButton("–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª", callback_data="mode:set:pro")],
        [InlineKeyboardButton("–≠–∫—Å–ø–µ—Ä—Ç", callback_data="mode:set:expert")],
        [InlineKeyboardButton("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å", callback_data="mode:set:user")],
        [InlineKeyboardButton("–°–ï–û", callback_data="mode:set:ceo")],
        [InlineKeyboardButton("–ó–∞–∫—Ä—ã—Ç—å", callback_data="mode:close")],
    ])
    await m.reply_text("–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–∏–ª—å –æ—Ç–≤–µ—Ç–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞:", reply_markup=kb)

async def mode_cb(update: Update, context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    if not q: return
    await q.answer()
    data = q.data or ""
    if data == "mode:close":
        try:
            await q.message.edit_reply_markup(reply_markup=None)
        except Exception:
            pass
        return
    if data.startswith("mode:set:"):
        style = data.split(":", 2)[2]
        if style not in ("ceo","expert","pro","user"):
            return await q.message.reply_text("–ù–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–π —Å—Ç–∏–ª—å.")
        with SessionLocal() as db:
            uid = _ensure_user(db, q.from_user.id)
            did = _ensure_dialog(db, uid)
            db.execute(sa_text("UPDATE dialogs SET style=:s WHERE id=:d"), {"s": style, "d": did})
            db.commit()
        sample = _STYLE_EXAMPLES.get(style, "")
        await q.message.reply_text(f"‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Å—Ç–∏–ª—å: {style}\n–ü—Ä–∏–º–µ—Ä: {sample}")
        try:
            await q.message.edit_reply_markup(reply_markup=None)
        except Exception:
            pass

async def cmd_img(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    q = (m.text or "").split(maxsplit=1)
    if len(q) < 2:
        return await m.reply_text("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /img <–æ–ø–∏—Å–∞–Ω–∏–µ>")
    try:
        from bot.openai_helper import generate_image_bytes
        content, final_prompt = await generate_image_bytes(q[1])
        await m.reply_photo(photo=content, caption=f"üñºÔ∏è –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ DALL¬∑E 3\nPrompt ‚Üí {final_prompt}")
    except Exception:
        log.exception("img failed")
        await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.")

DIALOGS_PAGE_SIZE = 6

DIALOGS_PAGE_SIZE = 6

async def dialogs(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        tg = update.effective_user.id
        with SessionLocal() as db:
            ds = _exec_all(db, """
                SELECT d.id, COALESCE(d.title,'')
                FROM dialogs d
                JOIN users u ON u.id = d.user_id
                WHERE u.tg_user_id = :tg AND d.is_deleted = FALSE
                ORDER BY d.created_at DESC
            """, tg=tg)

        if not ds:
            kb = [[InlineKeyboardButton("‚ûï –ù–æ–≤—ã–π –¥–∏–∞–ª–æ–≥", callback_data="dlg:new")]]
            return await m.reply_text("–î–∏–∞–ª–æ–≥–æ–≤ –Ω–µ—Ç.", reply_markup=InlineKeyboardMarkup(kb))

        page = 1
        pages = max(1, (len(ds) + DIALOGS_PAGE_SIZE - 1) // DIALOGS_PAGE_SIZE)
        beg = (page - 1) * DIALOGS_PAGE_SIZE
        chunk = ds[beg:beg + DIALOGS_PAGE_SIZE]

        rows = []
        for did, title in chunk:
            name = title or f"–î–∏–∞–ª–æ–≥ #{did}"
            rows.append([
                InlineKeyboardButton(name[:30] + ("‚Ä¶" if len(name) > 30 else ""), callback_data=f"dlg:open:{did}"),
                InlineKeyboardButton("‚úèÔ∏è", callback_data=f"dlg:rename:{did}"),
                InlineKeyboardButton("üì§", callback_data=f"dlg:export:{did}"),
                InlineKeyboardButton("üóëÔ∏è", callback_data=f"dlg:delete:{did}"),
            ])

        nav = []
        if pages > 1:
            nav.append(InlineKeyboardButton("–í–ø–µ—Ä—ë–¥ ¬ª", callback_data=f"dlg:page:{page+1}"))
        rows.append(nav or [InlineKeyboardButton(" ", callback_data="dlg:nop")])
        rows.append([InlineKeyboardButton("‚ûï –ù–æ–≤—ã–π –¥–∏–∞–ª–æ–≥", callback_data="dlg:new")])

        await m.reply_text("–ú–æ–∏ –¥–∏–∞–ª–æ–≥–∏:", reply_markup=InlineKeyboardMarkup(rows))
    except Exception:
        log.exception("dialogs failed")
        await m.reply_text("‚ö† –û—à–∏–±–∫–∞ /dialogs")

async def dialog_cb(update: Update, context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    await q.answer()
    try:
        data = q.data or ""
        tg = update.effective_user.id

        if data == "dlg:nop":
            return

        if data == "dlg:new":
            with SessionLocal() as db:
                did = _create_new_dialog_for_tg(db, tg)
            return await q.edit_message_text(f"‚úÖ –°–æ–∑–¥–∞–Ω –¥–∏–∞–ª–æ–≥ #{did}")

        if data.startswith("dlg:page:"):
            page = int(data.split(":")[-1])
            with SessionLocal() as db:
                ds = _exec_all(db, """
                    SELECT d.id, COALESCE(d.title,'')
                    FROM dialogs d
                    JOIN users u ON u.id = d.user_id
                    WHERE u.tg_user_id = :tg AND d.is_deleted = FALSE
                    ORDER BY d.created_at DESC
                """, tg=tg)
            total = len(ds)
            pages = max(1, (total + DIALOGS_PAGE_SIZE - 1) // DIALOGS_PAGE_SIZE)
            page = max(1, min(page, pages))
            beg = (page - 1) * DIALOGS_PAGE_SIZE
            chunk = ds[beg:beg + DIALOGS_PAGE_SIZE]

            rows = []
            for did, title in chunk:
                name = title or f"–î–∏–∞–ª–æ–≥ #{did}"
                rows.append([
                    InlineKeyboardButton(name[:30] + ("‚Ä¶" if len(name) > 30 else ""), callback_data=f"dlg:open:{did}"),
                    InlineKeyboardButton("‚úèÔ∏è", callback_data=f"dlg:rename:{did}"),
                    InlineKeyboardButton("üì§", callback_data=f"dlg:export:{did}"),
                    InlineKeyboardButton("üóëÔ∏è", callback_data=f"dlg:delete:{did}"),
                ])
            nav = []
            if page > 1:
                nav.append(InlineKeyboardButton("¬´ –ù–∞–∑–∞–¥", callback_data=f"dlg:page:{page-1}"))
            nav.append(InlineKeyboardButton(f"{page}/{pages}", callback_data="dlg:nop"))
            if page < pages:
                nav.append(InlineKeyboardButton("–í–ø–µ—Ä—ë–¥ ¬ª", callback_data=f"dlg:page:{page+1}"))
            rows.append(nav)
            rows.append([InlineKeyboardButton("‚ûï –ù–æ–≤—ã–π –¥–∏–∞–ª–æ–≥", callback_data="dlg:new")])

            return await q.edit_message_text("–ú–æ–∏ –¥–∏–∞–ª–æ–≥–∏:", reply_markup=InlineKeyboardMarkup(rows))

        if data.startswith("dlg:open:"):
            dlg_id = int(data.split(":")[-1])
            # –∞–∫—Ç–∏–≤–∏—Ä—É–µ–º –¥–∏–∞–ª–æ–≥, –ù–ï –º–µ–Ω—è—è created_at ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º last_message_at
            with SessionLocal() as db:
                db.execute(sa_text("UPDATE dialogs SET last_message_at = now() WHERE id = :d"), {"d": dlg_id})
                db.commit()
            return await q.edit_message_text(f"–û—Ç–∫—Ä—ã—Ç –¥–∏–∞–ª–æ–≥ #{dlg_id}")

        if data.startswith("dlg:rename:"):
            dlg_id = int(data.split(":")[-1])
            context.user_data["rename_dialog_id"] = dlg_id
            return await q.edit_message_text("–í–≤–µ–¥–∏—Ç–µ –Ω–æ–≤–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞:")

        if data.startswith("dlg:export:"):
            dlg_id = int(data.split(":")[-1])
            with SessionLocal() as db:
                msgs = _exec_all(db, """
                    SELECT role, content, created_at
                    FROM messages
                    WHERE dialog_id = :d
                    ORDER BY created_at
                """, d=dlg_id)
            lines = ["# –≠–∫—Å–ø–æ—Ä—Ç –¥–∏–∞–ª–æ–≥–∞", ""]
            for role, content, _ in msgs:
                who = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if role == "user" else "–ë–æ—Ç"
                lines.append(f"**{who}:**\n{content}\n")
            data_bytes = "\n".join(lines).encode("utf-8")
            file = (BufferedInputFile if HAS_BUFFERED else InputFile)(data_bytes, filename=f"dialog_{dlg_id}.md")  # type: ignore
            return await q.message.reply_document(document=file, caption="–≠–∫—Å–ø–æ—Ä—Ç –≥–æ—Ç–æ–≤")

        if data.startswith("dlg:delete:"):
            dlg_id = int(data.split(":")[-1])
            with SessionLocal() as db:
                db.execute(sa_text("UPDATE dialogs SET is_deleted = TRUE WHERE id = :d"), {"d": dlg_id})
                db.commit()
            return await q.edit_message_text(f"–î–∏–∞–ª–æ–≥ #{dlg_id} —É–¥–∞–ª—ë–Ω")

    except Exception:
        log.exception("dialog_cb failed")
        try:
            await q.message.reply_text("‚ö† –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ /dialogs. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
        except Exception:
            pass
        
def build_app() -> Application:
    # alembic autoupgrade / –ª–µ–Ω–∏–≤—ã–µ –º–∏–≥—Ä–∞—Ü–∏–∏
    apply_migrations_if_needed()

    # –≥–∞—Ä–∞–Ω—Ç–∏—è –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Å—Ç–∞–Ω—Å–∞ (–¥–æ —Å—Ç–∞—Ä—Ç–∞ polling)
    _ensure_single_instance()

    # —Å–æ–±–∏—Ä–∞–µ–º Application —Å post_init-—Ö—É–∫–æ–º, –∫–æ—Ç–æ—Ä—ã–π —É–¥–∞–ª—è–µ—Ç webhook
    app = ApplicationBuilder() \
        .token(settings.telegram_bot_token) \
        .post_init(_post_init) \
        .build()

    app.add_error_handler(error_handler)

    # --- –≤–∞—à–∏ —Ö–µ–Ω–¥–ª–µ—Ä—ã (–æ—Å—Ç–∞–≤–ª—è—é –∫–∞–∫ —É –≤–∞—Å, –Ω–æ —Å–º. –ø—É–Ω–∫—Ç 2 –ø—Ä–æ –¥—É–±–ª–∏–∫–∞—Ç—ã) ---
    app.add_handler(CallbackQueryHandler(model_cb, pattern=r"^model:"))
    app.add_handler(CallbackQueryHandler(mode_cb, pattern=r"^mode:"))

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_cmd))
    app.add_handler(CommandHandler("stats", stats))
    app.add_handler(CommandHandler("model", model_menu))
    app.add_handler(CommandHandler("mode", mode_menu))
    app.add_handler(CommandHandler("reset", reset))
    app.add_handler(CommandHandler("dialogs", dialogs))
    app.add_handler(CommandHandler("dialog", dialog_cmd))
    app.add_handler(CommandHandler("dialog_new", dialog_new))
    app.add_handler(CommandHandler("kb", kb_cmd))
    app.add_handler(CommandHandler("kb_diag", kb_diag))
    app.add_handler(CommandHandler("img", img_cmd))
    app.add_handler(CommandHandler("grant", grant))
    app.add_handler(CommandHandler("revoke", revoke))
    app.add_handler(CommandHandler("whoami", whoami))
    app.add_handler(CommandHandler("rag_diag", rag_diag))
    app.add_handler(CommandHandler("rag_selftest", rag_selftest))
    app.add_handler(CommandHandler("kb_pdf_diag", kb_pdf_diag))
    app.add_handler(CommandHandler("web", web_cmd))
    # –∞–¥–º–∏–Ω–∫–∏ –ø–æ –ë–ó
    app.add_handler(CommandHandler("kb_chunks", kb_chunks_cmd))
    app.add_handler(CommandHandler("kb_reindex", kb_reindex))
    app.add_handler(CommandHandler("kb_sync", kb_sync_admin))
    # —Å–æ–æ–±—â–µ–Ω–∏—è
    app.add_handler(MessageHandler(filters.VOICE, on_voice))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_text))

    return app

async def kb_sync_admin(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ê–¥–º–∏–Ω-—Å–∏–Ω–∫ –ë–ó: –Ω–∞–¥—ë–∂–Ω–æ –≤—ã–∑—ã–≤–∞–µ—Ç entrypoint –∏–∑ bot.knowledge_base.indexer, 
    –¥–∞–∂–µ –µ—Å–ª–∏ –≤–Ω—É—Ç—Ä–∏ –æ–Ω –∑–∞–ø—É—Å–∫–∞–µ—Ç —Å–≤–æ–π asyncio.run()."""
    m = update.effective_message or update.message
    if not _is_admin(update.effective_user.id):
        return await m.reply_text("‚õî –î–æ—Å—Ç—É–ø —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∞–º.")
    await m.reply_text("üîÑ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–ø—É—â–µ–Ω–∞...")

    import asyncio, inspect, os, re
    try:
        from bot.knowledge_base import indexer

        explicit = getattr(settings, "kb_sync_entrypoint", None) or os.getenv("KB_SYNC_ENTRYPOINT")
        fn = getattr(indexer, explicit, None) if explicit else None
        if not fn:
            for name in ("sync_kb","sync_all","sync_from_yandex","sync","run_sync","full_sync",
                         "reindex","index_all","ingest_all","ingest","main"):
                if hasattr(indexer, name) and callable(getattr(indexer, name)):
                    fn = getattr(indexer, name); break
        if not fn:
            for name in dir(indexer):
                if name.startswith("_"): 
                    continue
                if re.search(r"(sync|index|ingest)", name, re.I) and callable(getattr(indexer, name)):
                    fn = getattr(indexer, name); break
        if not fn:
            raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω entrypoint –≤ indexer.py. –£–∫–∞–∂–∏—Ç–µ KB_SYNC_ENTRYPOINT –∏–ª–∏ —Ä–µ–∞–ª–∏–∑—É–π—Ç–µ sync_kb(session).")

        sig = inspect.signature(fn)
        kwargs, session_to_close = {}, None
        for p in sig.parameters.values():
            nm = p.name.lower()
            if nm in ("session","db","dbsession","conn","connection"):
                sess = SessionLocal(); kwargs[p.name] = sess; session_to_close = sess
            elif nm in ("sessionlocal","session_factory","factory","engine"):
                kwargs[p.name] = SessionLocal
            elif nm in ("settings","cfg","config","conf"):
                kwargs[p.name] = settings
            elif p.default is inspect._empty:
                kwargs[p.name] = None

        # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –∑–∞–ø—É—Å–∫: –∫–æ—Ä—É—Ç–∏–Ω—ã ‚Äî await, —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ (–≤ —Ç.—á. —Å asyncio.run –≤–Ω—É—Ç—Ä–∏) ‚Äî –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ç—Ä–µ–¥–µ.
        import asyncio
        import inspect as _inspect
        try:
            if _inspect.iscoroutinefunction(fn):
                result = await fn(**kwargs)
            else:
                loop = asyncio.get_running_loop()
                result = await loop.run_in_executor(None, lambda: fn(**kwargs))
        finally:
            if session_to_close is not None:
                try: session_to_close.close()
                except Exception: pass

        if isinstance(result, dict):
            upd = result.get("updated"); skp = result.get("skipped"); tot = result.get("total")
            msg = "‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞."
            if upd is not None or skp is not None or tot is not None:
                msg += f" –û–±–Ω–æ–≤–ª–µ–Ω–æ: {upd or 0}, –ø—Ä–æ–ø—É—â–µ–Ω–æ: {skp or 0}, –≤—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –Ω–∞ –¥–∏—Å–∫–µ: {tot or 0}."
            return await m.reply_text(msg)
        elif isinstance(result, (tuple, list)) and len(result) >= 2:
            return await m.reply_text(f"‚úÖ –ì–æ—Ç–æ–≤–æ: –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ {result[0]}, —á–∞–Ω–∫–æ–≤ {result[1]}")
        else:
            return await m.reply_text("‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
    except Exception as e:
        log.exception("kb_sync_admin failed")
        return await m.reply_text(f"‚ö† –û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}")

KB_PAGE_SIZE = 10

def _kb_build_ui(db, tg_id: int, mode: str, page: int):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (text, markup, total_pages, page, linked_ids_set)."""
    did = _get_active_dialog_id(db, tg_id) or _create_new_dialog_for_tg(db, tg_id)
    linked = set(x[0] for x in db.execute(sa_text(
        "SELECT document_id FROM dialog_kb_links WHERE dialog_id=:d"
    ), {"d": did}).fetchall())

    docs = db.execute(sa_text("""
        SELECT id, path, is_active
        FROM kb_documents
        ORDER BY path
    """)).fetchall()

    def is_linked(doc_id): return doc_id in linked

    if mode == "linked":
        docs = [r for r in docs if is_linked(r[0])]
    elif mode == "avail":
        docs = [r for r in docs if not is_linked(r[0])]

    total = len(docs)
    pages = max(1, (total + KB_PAGE_SIZE - 1) // KB_PAGE_SIZE)
    page = max(1, min(page, pages))
    beg = (page - 1) * KB_PAGE_SIZE
    chunk = docs[beg:beg + KB_PAGE_SIZE]

    rows = []
    for doc_id, path, is_active in chunk:
        check = "‚òë" if doc_id in linked else "‚òê"
        title = (path or f"doc #{doc_id}")[:70]
        rows.append([InlineKeyboardButton(f"{check} {title}", callback_data=f"kb:toggle:{doc_id}")])

    nav = []
    if page > 1:   nav.append(InlineKeyboardButton("¬´", callback_data=f"kb:page:{page-1}"))
    nav.append(InlineKeyboardButton(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}/{pages}", callback_data="kb:nop"))
    if page < pages: nav.append(InlineKeyboardButton("¬ª", callback_data=f"kb:page:{page+1}"))
    if nav: rows.append(nav)

    rows.append([
        InlineKeyboardButton("–í—Å–µ", callback_data="kb:mode:all"),
        InlineKeyboardButton("–ü–æ–¥–∫–ª—é—á—ë–Ω–Ω—ã–µ", callback_data="kb:mode:linked"),
        InlineKeyboardButton("–î–æ—Å—Ç—É–ø–Ω—ã–µ", callback_data="kb:mode:avail"),
    ])
    rows.append([InlineKeyboardButton("üóò –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è", callback_data="kb:sync")])
    rows.append([InlineKeyboardButton("üìä –°—Ç–∞—Ç—É—Å –ë–ó", callback_data="kb:status")])

    text = "–ú–µ–Ω—é –ë–ó: –≤—ã–±–µ—Ä–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –∞–∫—Ç–∏–≤–Ω–æ–º—É –¥–∏–∞–ª–æ–≥—É."
    return text, InlineKeyboardMarkup(rows), pages, page, linked

async def kb(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        mode = context.user_data.get("kb_mode", "all")
        page = context.user_data.get("kb_page", 1)
        with SessionLocal() as db:
            text, markup, pages, page, _ = _kb_build_ui(db, update.effective_user.id, mode, page)
        context.user_data["kb_page"] = page
        await m.reply_text(text, reply_markup=markup)
    except Exception:
        log.exception("kb failed")
        await m.reply_text("‚ö† –û—à–∏–±–∫–∞ /kb")

async def kb_cb(update: Update, context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    data = q.data or ""
    await q.answer()
    try:
        mode = context.user_data.get("kb_mode", "all")
        page = context.user_data.get("kb_page", 1)

        if data == "kb:nop":
            return

        if data.startswith("kb:page:"):
            page = int(data.split(":")[-1])
            context.user_data["kb_page"] = page
            with SessionLocal() as db:
                text, markup, _, page, _ = _kb_build_ui(db, update.effective_user.id, mode, page)
            return await q.edit_message_text(text, reply_markup=markup)

        if data.startswith("kb:mode:"):
            mode = data.split(":")[-1]
            context.user_data["kb_mode"] = mode
            context.user_data["kb_page"] = 1
            with SessionLocal() as db:
                text, markup, _, page, _ = _kb_build_ui(db, update.effective_user.id, mode, 1)
            return await q.edit_message_text(text, reply_markup=markup)

        if data.startswith("kb:toggle:"):
            doc_id = int(data.split(":")[-1])
            with SessionLocal() as db:
                did = _get_active_dialog_id(db, update.effective_user.id) or _create_new_dialog_for_tg(db, update.effective_user.id)
                exists = _exec_scalar(db,
                    "SELECT 1 FROM dialog_kb_links WHERE dialog_id=:d AND document_id=:doc LIMIT 1",
                    d=did, doc=doc_id)
                if exists:
                    db.execute(sa_text("DELETE FROM dialog_kb_links WHERE dialog_id=:d AND document_id=:doc"),
                               {"d": did, "doc": doc_id})
                else:
                    db.execute(sa_text(
                        "INSERT INTO dialog_kb_links (dialog_id, document_id, created_at) "
                        "VALUES (:d,:doc,now()) ON CONFLICT DO NOTHING"),
                        {"d": did, "doc": doc_id})
                db.commit()
                text, markup, _, page, _ = _kb_build_ui(db, update.effective_user.id, mode, page)
            return await q.edit_message_text(text, reply_markup=markup)

        if data in ("kb:sync", "kb:sync:run"):
            return await kb_sync_admin(update, context)

        if data == "kb:status":
            with SessionLocal() as db:
                d = _exec_scalar(db, "SELECT count(*) FROM kb_documents") or 0
                c = _exec_scalar(db, "SELECT count(*) FROM kb_chunks") or 0
            return await q.message.reply_text(f"–ë–ó: –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ {d}, —á–∞–Ω–∫–æ–≤ {c}")
    except Exception:
        log.exception("kb_cb failed")
        try:
            await q.message.reply_text("‚ö† –û—à–∏–±–∫–∞ –º–µ–Ω—é –ë–ó.")
        except Exception:
            pass

async def kb_chunks_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ê–¥–º–∏–Ω: /kb_chunks <size> <overlap> [<kb_top_k>] ‚Äî –º–µ–Ω—è–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ —Ä–∞–Ω—Ç–∞–π–º–µ (–¥–æ —Ä–µ—Å—Ç–∞—Ä—Ç–∞)."""
    m = update.effective_message or update.message
    if not _is_admin(update.effective_user.id):
        return await m.reply_text("‚õî –î–æ—Å—Ç—É–ø —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∞–º.")

    parts = (m.text or "").split()
    if len(parts) < 3:
        s, o, _ = _get_chunk_params()
        return await m.reply_text(
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /kb_chunks <size> <overlap> [<kb_top_k>]\n"
            f"–¢–µ–∫—É—â–∏–µ: size={s}, overlap={o}. –î–ª—è –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–π —Å–º–µ–Ω—ã –ø—Ä–∞–≤—å—Ç–µ CHUNK_SIZE/CHUNK_OVERLAP –≤ env."
        )

    try:
        size = int(parts[1]); overlap = int(parts[2])
        if size < 200 or size > 8000:
            return await m.reply_text("size –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 200..8000.")
        if overlap < 0 or overlap >= size:
            return await m.reply_text("overlap –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 0..(size-1).")

        for attr in ("chunk_size", "CHUNK_SIZE"):
            if hasattr(settings, attr):
                setattr(settings, attr, size)
        for attr in ("chunk_overlap", "CHUNK_OVERLAP"):
            if hasattr(settings, attr):
                setattr(settings, attr, overlap)

        if len(parts) >= 4:
            kb_top_k = int(parts[3])
            for attr in ("kb_top_k", "KB_TOP_K"):
                if hasattr(settings, attr):
                    setattr(settings, attr, kb_top_k)

        s, o, _ = _get_chunk_params()
        await m.reply_text(
            f"‚úÖ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±–Ω–æ–≤–ª–µ–Ω—ã: size={s}, overlap={o}. "
            f"–î–ª—è –ø–µ—Ä–µ—Å—á—ë—Ç–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤ ‚Äî /kb_reindex."
        )
    except Exception:
        log.exception("/kb_chunks failed")
        await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–º–µ–Ω–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã.")

def _get_chunk_params():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (size, overlap, embedding_model) –∏–∑ settings (snake/UPPER case)."""
    size = getattr(settings, "chunk_size", None) or getattr(settings, "CHUNK_SIZE", None) or 1200
    overlap = getattr(settings, "chunk_overlap", None) or getattr(settings, "CHUNK_OVERLAP", None) or 200
    emb = getattr(settings, "openai_embedding_model", None) or getattr(settings, "OPENAI_EMBEDDING_MODEL", None) or "text-embedding-3-large"
    return int(size), int(overlap), str(emb)
    
async def kb_reindex(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–ª–Ω—ã–π —Ä–µ–∏–Ω–¥–µ–∫—Å: —á–∏—Å—Ç–∏–º —á–∞–Ω–∫–∏, —Å–±—Ä–∞—Å—ã–≤–∞–µ–º etag/chunk_schema –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –æ–±—ã—á–Ω—ã–π —Å–∏–Ω–∫. –¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–æ–≤."""
    m = update.effective_message or update.message
    if not _is_admin(update.effective_user.id):
        return await m.reply_text("‚õî –î–æ—Å—Ç—É–ø —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∞–º.")

    size, overlap, emb = _get_chunk_params()
    await m.reply_text(f"‚ôªÔ∏è –ü–æ–ª–Ω—ã–π —Ä–µ–∏–Ω–¥–µ–∫—Å: size={size}, overlap={overlap}, embedding={emb}.\n"
                       f"–û—á–∏—â–∞—é —á–∞–Ω–∫–∏ –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞—é —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é‚Ä¶")
    try:
        with SessionLocal() as db:
            db.execute(sa_text("DELETE FROM kb_chunks"))
            db.execute(sa_text("UPDATE kb_documents SET etag=NULL, updated_at=now()"))
            try:
                db.execute(sa_text("UPDATE kb_documents SET chunk_schema=NULL"))
            except Exception:
                pass
            db.commit()
        return await kb_sync_admin(update, context)
    except Exception as e:
        log.exception("kb_reindex failed")
        return await m.reply_text(f"‚ö† –û—à–∏–±–∫–∞ —Ä–µ–∏–Ω–¥–µ–∫—Å–∞: {e}")

async def on_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–¢–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å: –∞–∫—Ç–∏–≤–Ω—ã–π –¥–∏–∞–ª–æ–≥, RAG, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏, –¥–ª–∏–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã."""
    m = update.effective_message or update.message

    if "rename_dialog_id" in context.user_data:
        dlg_id = context.user_data.pop("rename_dialog_id")
        new_title = (m.text or "").strip()[:100]
        if not new_title:
            return await m.reply_text("–ù–∞–∑–≤–∞–Ω–∏–µ –ø—É—Å—Ç–æ–µ. –û—Ç–º–µ–Ω–µ–Ω–æ.")
        try:
            with SessionLocal() as db:
                db.execute(sa_text("UPDATE dialogs SET title=:t WHERE id=:d"), {"t": new_title, "d": dlg_id})
                db.commit()
            return await m.reply_text("–ù–∞–∑–≤–∞–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ.")
        except Exception:
            log.exception("rename dialog title failed")
            return await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ.")

    q = (m.text or "").strip()
    if not q:
        return

    try:
        with SessionLocal() as db:
            tg = update.effective_user.id
            did = _get_active_dialog_id(db, tg)
            if not did:
                did = _create_new_dialog_for_tg(db, tg)

            row = db.execute(sa_text("SELECT model, style FROM dialogs WHERE id=:d"), {"d": did}).first()
            dia_model = row[0] if row and row[0] else settings.openai_model
            dia_style = row[1] if row and row[1] else "pro"

            chunks = retriever.search(did, query_embedding, top_k=max(settings.KB_TOP_K, 6))
            chunks = diversify_chunks(chunks, k=settings.KB_TOP_K)
            ctx_blocks = [c.get("content", "")[:1000] for c in chunks] if chunks else []

        prompt = _build_prompt_with_style(ctx_blocks, q, dia_style) if ctx_blocks else q

        system = {"role": "system", "content": "RAG assistant"}
        user = {"role": "user", "content": prompt}
        answer = await _chat_full(dia_model, [system, user], temperature=0.3)

        if chunks:
            answer += _format_citations(chunks)

        try:
            with SessionLocal() as db:
                db.execute(sa_text(
                    "INSERT INTO messages (dialog_id, role, content, created_at) VALUES (:d,'user',:c,now())"
                ), {"d": did, "c": q})
                db.execute(sa_text(
                    "INSERT INTO messages (dialog_id, role, content, created_at) VALUES (:d,'assistant',:c,now())"
                ), {"d": did, "c": answer})
                db.execute(sa_text("UPDATE dialogs SET last_message_at=now() WHERE id=:d"), {"d": did})
                db.commit()
        except Exception:
            log.exception("save messages failed")

        await _send_long(m, answer)

    except Exception:
        log.exception("on_text failed")
        await m.reply_text("‚ö† –ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")

def diversify_chunks(chunks, k):
    """–ë–µ—Ä—ë—Ç –±–æ–ª—å—à–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏ –∂–∞–¥–Ω–æ –Ω–∞–±–∏—Ä–∞–µ—Ç –¥–æ k, —Å—Ç–∞—Ä–∞—è—Å—å –Ω–µ –±—Ä–∞—Ç—å
    –º–Ω–æ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –∏–∑ –æ–¥–Ω–æ–≥–æ –∏ —Ç–æ–≥–æ –∂–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ–¥—Ä—è–¥."""
    if not chunks:
        return []
    # –æ–∂–∏–¥–∞–µ–º, —á—Ç–æ –≤ —á–∞–Ω–∫–µ –µ—Å—Ç—å .document_id –∏–ª–∏ meta —Å id/path
    def doc_id_of(ch):
        if hasattr(ch, "document_id"):
            return ch.document_id
        if isinstance(ch, dict):
            return ch.get("document_id") or (ch.get("meta") or {}).get("document_id")
        return None

    pool = chunks[: max(k*3, k)]  # –±–æ–ª—å—à–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    picked, seen = [], set()
    # 1 –ø—Ä–æ—Ö–æ–¥ ‚Äî –ø–æ –æ–¥–Ω–æ–º—É —Ñ—Ä–∞–≥–º–µ–Ω—Ç—É —Å –∫–∞–∂–¥–æ–≥–æ doc
    for ch in pool:
        did = doc_id_of(ch)
        if did is not None and did not in seen:
            picked.append(ch); seen.add(did)
            if len(picked) >= k:
                return picked
    # –¥–æ–±–∏—Ä–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è ‚Äî –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
    for ch in pool:
        if ch in picked:
            continue
        picked.append(ch)
        if len(picked) >= k:
            break
    return picked

