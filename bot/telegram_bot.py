from __future__ import annotations
import tiktoken
import asyncio
from openai import OpenAI
from io import BytesIO
import os, re, inspect
from datetime import datetime

import logging
from datetime import datetime
from io import BytesIO
# ==== KB RAG helpers (safe define if missing) ====
import json

# PTB 20.4 –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç BufferedInputFile. –î–µ–ª–∞–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π –∏–º–ø–æ—Ä—Ç.
try:
    from telegram import (
        Update, InlineKeyboardButton, InlineKeyboardMarkup, BufferedInputFile, InputFile
    )
    HAS_BUFFERED = True
except Exception:  # pragma: no cover
    from telegram import (  # type: ignore
        Update, InlineKeyboardButton, InlineKeyboardMarkup, InputFile
    )
    HAS_BUFFERED = False

from telegram.ext import (
    ApplicationBuilder, Application, CommandHandler, ContextTypes,
    MessageHandler, CallbackQueryHandler, filters
)
from sqlalchemy import text as sa_text

from bot.settings import load_settings
from bot.db.session import SessionLocal  # engine –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤–Ω—É—Ç—Ä–∏ apply_migrations_if_needed

log = logging.getLogger(__name__)
settings = load_settings()
_oa_client = OpenAI(api_key=settings.openai_api_key)

# --- –ê–≤—Ç–æ-–º–∏–≥—Ä–∞—Ü–∏—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ (–µ—Å–ª–∏ –Ω–µ—Ç —Ç–∞–±–ª–∏—Ü) ---
def apply_migrations_if_needed(force: bool = False) -> None:
    """
    –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç (–∏–ª–∏ force=True), –∑–∞–ø—É—Å–∫–∞–µ–º alembic upgrade head.
    –†–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ –∫–æ–Ω—Å–æ–ª–∏ Railway.
    """
    try:
        from sqlalchemy import text as sa_text
        from bot.db.session import engine
        need = True
        if not force:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤–æ–π —Ç–∞–±–ª–∏—Ü—ã
            with engine.connect() as conn:
                exists = conn.execute(sa_text("SELECT to_regclass('public.users')")).scalar()
                need = not bool(exists)

        if need:
            log.info("Auto-migrate: applying Alembic migrations...")
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º Alembic –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ
            import os
            import time
            from alembic.config import Config
            from alembic import command

            cfg = Config("alembic.ini")  # —Ñ–∞–π–ª –ª–µ–∂–∏—Ç –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞
            os.environ["DATABASE_URL"] = settings.database_url  # —á—Ç–æ–±—ã Alembic –∑–Ω–∞–ª, –∫—É–¥–∞ –ø–æ–¥–∫–ª—é—á–∞—Ç—å—Å—è
            command.upgrade(cfg, "head")
            log.info("Auto-migrate: done")
        else:
            log.info("Auto-migrate: tables already present")
    except Exception:
        log.exception("Auto-migrate failed")

# ---------- helpers ----------
def _exec_scalar(db, sql: str, **params):
    return db.execute(sa_text(sql), params).scalar()

def _exec_all(db, sql: str, **params):
    return db.execute(sa_text(sql), params).all()

def _ensure_user(db, tg_id: int) -> int:
    uid = _exec_scalar(db, "SELECT id FROM users WHERE tg_user_id=:tg", tg=tg_id)
    if uid:
        return uid
    uid = _exec_scalar(
        db,
        """
        INSERT INTO users (tg_user_id, is_admin, is_allowed, lang)
        VALUES (:tg, FALSE, TRUE, 'ru')
        RETURNING id
        """, tg=tg_id,
    )
    db.commit()
    return uid

def _ensure_dialog(db, user_id: int) -> int:
    did = _exec_scalar(
        db,
        """
        SELECT id FROM dialogs
        WHERE user_id=:u AND is_deleted=FALSE
        ORDER BY created_at DESC
        LIMIT 1
        """, u=user_id,
    )
    if did:
        return did
    did = _exec_scalar(
        db,
        """
        INSERT INTO dialogs (user_id, title, style, model, is_deleted)
        VALUES (:u, :t, 'expert', :m, FALSE)
        RETURNING id
        """, u=user_id, t=datetime.now().strftime("%Y-%m-%d | –¥–∏–∞–ª–æ–≥"), m=settings.openai_model,
    )
    db.commit()
    return did

def _is_admin(tg_id: int) -> bool:
    try:
        ids = [int(x.strip()) for x in (settings.admin_user_ids or "").split(",") if x.strip()]
        return tg_id in ids
    except Exception:
        return False

TELEGRAM_CHUNK = 3500  # –±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Å–æ–æ–±—â–µ–Ω–∏—è

def _split_for_tg(text: str, limit: int = TELEGRAM_CHUNK):
    """–î–µ–ª–∏—Ç –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Ç–∞–∫, —á—Ç–æ–±—ã –Ω–µ —Ä–≤–∞—Ç—å —Å–ª–æ–≤–∞/–∞–±–∑–∞—Ü—ã."""
    parts, s = [], text.strip()
    while len(s) > limit:
        cut = s.rfind("\n\n", 0, limit)
        if cut == -1:
            cut = s.rfind("\n", 0, limit)
        if cut == -1:
            cut = s.rfind(" ", 0, limit)
        if cut == -1:
            cut = limit
        parts.append(s[:cut].rstrip())
        s = s[cut:].lstrip()
    if s:
        parts.append(s)
    return parts

async def _send_long(m, text: str):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –ø–∞—á–∫–∞–º–∏, –µ—Å–ª–∏ –æ–Ω –¥–ª–∏–Ω–Ω–µ–µ –ª–∏–º–∏—Ç–∞ Telegram."""
    for chunk in _split_for_tg(text):
        await m.reply_text(chunk)

async def _chat_full(model: str, messages: list, temperature: float = 0.3, max_turns: int = 6):
    """
    –í—ã–∑—ã–≤–∞–µ—Ç Chat Completions —Å—Ç–æ–ª—å–∫–æ —Ä–∞–∑, —Å–∫–æ–ª—å–∫–æ –Ω—É–∂–Ω–æ, –ø–æ–∫–∞ finish_reason != 'length'
    –∏–ª–∏ –Ω–µ –∏—Å—á–µ—Ä–ø–∞–Ω –ª–∏–º–∏—Ç max_turns. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Å–∫–ª–µ–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç.
    """
    hist = list(messages)
    full = ""
    turns = 0
    while turns < max_turns:
        turns += 1
        resp = _oa_client.chat.completions.create(
            model=model,
            messages=hist,
            temperature=temperature,
            max_tokens=1024,  # –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å, –Ω–æ –º—ã –≤—Å—ë —Ä–∞–≤–Ω–æ –∞–≤—Ç–æ–ø—Ä–æ–¥–æ–ª–∂–∏–º
        )
        choice = resp.choices[0]
        piece = choice.message.content or ""
        full += piece
        finish = choice.finish_reason
        if finish != "length":
            break
        # –ø—Ä–æ—Å–∏–º –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å
        hist.append({"role": "assistant", "content": piece})
        hist.append({"role": "user", "content": "–ü—Ä–æ–¥–æ–ª–∂–∞–π —Å —Ç–æ–≥–æ –º–µ—Å—Ç–∞. –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π—Å—è."})
    return full


async def whoami(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        tg_id = update.effective_user.id
        with SessionLocal() as db:
            row = db.execute(sa_text("SELECT id, is_admin, is_allowed, lang FROM users WHERE tg_user_id=:tg"), {"tg": tg_id}).first()
            if not row:
                uid = _ensure_user(db, tg_id)
                row = db.execute(sa_text("SELECT id, is_admin, is_allowed, lang FROM users WHERE id=:id"), {"id": uid}).first()
        is_admin = bool(row[1]) if row else False
        is_allowed = bool(row[2]) if row else True
        lang = (row[3] or "ru") if row else "ru"
        role = "admin" if is_admin else ("allowed" if is_allowed else "guest")
        await (update.message or update.effective_message).reply_text(f"whoami: tg={tg_id}, role={role}, lang={lang}")
    except Exception:
        log.exception("whoami failed")
        await (update.message or update.effective_message).reply_text("‚ö† –û—à–∏–±–∫–∞ whoami")

async def grant(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        if not _is_admin(update.effective_user.id):
            return await (update.message or update.effective_message).reply_text("‚õî –î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â—ë–Ω (–Ω—É–∂–Ω–æ –±—ã—Ç—å –∞–¥–º–∏–Ω–æ–º).")
        args = (update.message.text or "").split()
        if len(args) < 2 or not args[1].isdigit():
            return await (update.message or update.effective_message).reply_text("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /grant <tg_id>")
        target = int(args[1])
        with SessionLocal() as db:
            uid = _exec_scalar(db, "SELECT id FROM users WHERE tg_user_id=:tg", tg=target)
            if not uid:
                uid = _exec_scalar(db, "INSERT INTO users (tg_user_id, is_admin, is_allowed, lang) VALUES (:tg,FALSE,TRUE,'ru') RETURNING id", tg=target)
            else:
                db.execute(sa_text("UPDATE users SET is_allowed=TRUE WHERE id=:id"), {"id": uid})
            db.commit()
        await (update.message or update.effective_message).reply_text(f"‚úÖ –í—ã–¥–∞–Ω –¥–æ—Å—Ç—É–ø –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {target}")
    except Exception:
        log.exception("grant failed")
        await (update.message or update.effective_message).reply_text("‚ö† –û—à–∏–±–∫–∞ grant")

async def revoke(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        if not _is_admin(update.effective_user.id):
            return await (update.message or update.effective_message).reply_text("‚õî –î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â—ë–Ω (–Ω—É–∂–Ω–æ –±—ã—Ç—å –∞–¥–º–∏–Ω–æ–º).")
        args = (update.message.text or "").split()
        if len(args) < 2 or not args[1].isdigit():
            return await (update.message or update.effective_message).reply_text("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /revoke <tg_id>")
        target = int(args[1])
        with SessionLocal() as db:
            uid = _exec_scalar(db, "SELECT id FROM users WHERE tg_user_id=:tg", tg=target)
            if uid:
                db.execute(sa_text("UPDATE users SET is_allowed=FALSE WHERE id=:id"), {"id": uid})
                db.commit()
        await (update.message or update.effective_message).reply_text(f"üö´ –î–æ—Å—Ç—É–ø –æ—Ç–æ–∑–≤–∞–Ω —É {target}")
    except Exception:
        log.exception("revoke failed")
        await (update.message or update.effective_message).reply_text("‚ö† –û—à–∏–±–∫–∞ revoke")
# ---------- commands ----------
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    await m.reply_text(
        "–ó–¥–æ—Ä–æ–≤! –Ø –ø–æ–º–æ–≥—É –∏—Å–∫–∞—Ç—å –æ—Ç–≤–µ—Ç—ã –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –∏–∑ –ë–ó –∏ –≤–µ—Å—Ç–∏ –¥–∏–∞–ª–æ–≥–∏ –≤ —Ä–∞–∑–Ω—ã—Ö —Å—Ç–∏–ª—è—Ö.\n"
        "–í—Å–µ –∫–æ–º–∞–Ω–¥—ã —Ç—É—Ç ‚Äî /help"
    )

async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    await m.reply_text(
        "/start ‚Äî –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ\n"
        "/help ‚Äî –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥\n"
        "/dialogs ‚Äî —Å–ø–∏—Å–æ–∫ –¥–∏–∞–ª–æ–≥–æ–≤ (–æ—Ç–∫—Ä—ã—Ç—å/–ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å/—ç–∫—Å–ø–æ—Ä—Ç/—É–¥–∞–ª–∏—Ç—å)\n"
        "/dialog_new ‚Äî —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥\n"
        "/kb ‚Äî –ø–æ–¥–∫–ª—é—á–∏—Ç—å/–æ—Ç–∫–ª—é—á–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –ë–ó\n"
        "/stats ‚Äî –∫–∞—Ä—Ç–æ—á–∫–∞ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞\n"
        "/model ‚Äî –≤—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å (–¢–û–ü-10 + –ü–æ–∫–∞–∑–∞—Ç—å –µ—â—ë)\n"
        "/mode ‚Äî —Å—Ç–∏–ª—å –æ—Ç–≤–µ—Ç–∞ (pro/expert/user/ceo)\n"
        "/img <–æ–ø–∏—Å–∞–Ω–∏–µ> ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–ø–æ–∫–∞–∂—É –∏—Ç–æ–≥–æ–≤—ã–π prompt)\n"
        "/web <–∑–∞–ø—Ä–æ—Å> ‚Äî (–∑–∞–≥–ª—É—à–∫–∞) –≤–µ–±-–ø–æ–∏—Å–∫\n"
        "/reset ‚Äî —Å–±—Ä–æ—Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞\n"
        "/whoami ‚Äî –º–æ–∏ –ø—Ä–∞–≤–∞\n"
    )

async def cmd_web(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    query = " ".join(context.args or [])
    if not query:
        return await m.reply_text("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /web <–∑–∞–ø—Ä–æ—Å>")
    await m.reply_text(
        "üîé –í–µ–±-–ø–æ–∏—Å–∫ –ø–æ–∫–∞ –æ—Ç–∫–ª—é—á—ë–Ω –≤ —ç—Ç–æ–π —Å–±–æ—Ä–∫–µ (–∫–ª—é—á–∏ –≤–Ω–µ—à–Ω–µ–≥–æ –ø–æ–∏—Å–∫–∞ –Ω–µ –∑–∞–¥–∞–Ω—ã).\n"
        "–Ø –º–æ–≥—É –æ—Ç–≤–µ—Ç–∏—Ç—å —Å–≤–æ–∏–º–∏ –∑–Ω–∞–Ω–∏—è–º–∏ –∏–ª–∏ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –Ω–∞–π—Ç–∏ –≤ –ë–ó —á–µ—Ä–µ–∑ /kb."
    )

async def on_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        voice = getattr(m, "voice", None)
        audio = getattr(m, "audio", None)
        tg_file = voice or audio
        if not tg_file:
            return await m.reply_text("–ì–æ–ª–æ—Å–æ–≤–æ–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        fobj = await tg_file.get_file()
        bio = BytesIO()
        await fobj.download_to_memory(out=bio)
        bio.seek(0)

        import tempfile
        with tempfile.NamedTemporaryFile(suffix=".ogg") as tmp:
            tmp.write(bio.getbuffer())
            tmp.flush()
            with open(tmp.name, "rb") as fh:
                try:
                    tr = _oa_client.audio.transcriptions.create(
                        model="gpt-4o-mini-transcribe", file=fh, language="ru"
                    )
                except Exception:
                    fh.seek(0)
                    tr = _oa_client.audio.transcriptions.create(
                        model="whisper-1", file=fh, language="ru"
                    )

        text = getattr(tr, "text", None) or (tr.get("text") if isinstance(tr, dict) else None) or ""
        if not text.strip():
            return await m.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
        q = text.strip()

        # –≥–æ–ª–æ—Å–æ–≤–∞—è –∫–æ–º–∞–Ω–¥–∞ "–ù–∞—Ä–∏—Å—É–π ..."
        if q.lower().startswith(("–Ω–∞—Ä–∏—Å—É–π", "—Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π –∫–∞—Ä—Ç–∏–Ω–∫—É")):
            prompt = q.split(":", 1)[1].strip() if ":" in q else q.split(maxsplit=1)[-1]
            if prompt:
                from bot.openai_helper import generate_image_bytes
                img_bytes, final_prompt = await generate_image_bytes(prompt)
                return await m.reply_photo(photo=img_bytes, caption=f"üñºÔ∏è –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –ø–æ –≥–æ–ª–æ—Å–æ–≤–æ–π –∫–æ–º–∞–Ω–¥–µ\nPrompt ‚Üí {final_prompt}")

        with SessionLocal() as db:
            uid = _ensure_user(db, update.effective_user.id)
            did = _ensure_dialog(db, uid)
            row = db.execute(sa_text("SELECT model, style FROM dialogs WHERE id=:d"), {"d": did}).first()
            dia_model = row[0] if row and row[0] else settings.openai_model
            dia_style = row[1] if row and row[1] else "pro"
            chunks = _retrieve_chunks(db, did, q, k=6)
            ctx_blocks = [c.get("content", "") for c in chunks] if chunks else []

        prompt = _build_prompt_with_style(ctx_blocks, q, dia_style) if ctx_blocks else q
        system = {"role": "system", "content": "RAG assistant"}
        user = {"role": "user", "content": prompt}
        answer = await _chat_full(dia_model, [system, user], temperature=0.3)
        if chunks:
            answer += _format_citations(chunks)

        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ —á–∞—Å—Ç—è–º
        try:
            with SessionLocal() as db:
                uid = _ensure_user(db, update.effective_user.id)
                did = _ensure_dialog(db, uid)
                db.execute(sa_text("INSERT INTO messages (dialog_id, role, content, created_at) VALUES (:d,'user',:c,now())"),
                           {"d": did, "c": q})
                db.execute(sa_text("INSERT INTO messages (dialog_id, role, content, created_at) VALUES (:d,'assistant',:c,now())"),
                           {"d": did, "c": answer})
                db.execute(sa_text("UPDATE dialogs SET last_message_at=now() WHERE id=:d"), {"d": did})
                db.commit()
        except Exception:
            log.exception("save voice messages failed")

        await _send_long(m, answer)

    except Exception:
        log.exception("on_voice failed")
        await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")

def ya_download(path: str) -> bytes:
    """
    –°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª —Å –Ø.–î–∏—Å–∫–∞ –ø–æ –∞–±—Å–æ–ª—é—Ç–Ω–æ–º—É –ø—É—Ç–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'disk:/–ë–∞–∑–∞ –ó–Ω–∞–Ω–∏–π/file.pdf').
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –±–∏–Ω–∞—Ä–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞.
    """
    import requests
    YA_API = "https://cloud-api.yandex.net/v1/disk"
    headers = {"Authorization": f"OAuth {settings.yandex_disk_token}"}

    # 1) –ø–æ–ª—É—á–∞–µ–º href –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    r = requests.get(
        f"{YA_API}/resources/download",
        headers=headers,
        params={"path": path},
        timeout=60,
    )
    r.raise_for_status()
    href = (r.json() or {}).get("href")
    if not href:
        raise RuntimeError("download href not returned by Yandex Disk")

    # 2) —Å–∫–∞—á–∏–≤–∞–µ–º —Å–∞–º —Ñ–∞–π–ª
    f = requests.get(href, timeout=300)
    f.raise_for_status()
    return f.content

async def rag_selftest(update, context):
    from sqlalchemy import text as sa_text
    m = update.effective_message or update.message
    try:
        with SessionLocal() as db:
            t = db.execute(sa_text("SELECT pg_typeof(embedding)::text FROM kb_chunks LIMIT 1")).scalar()
            d = db.execute(sa_text("SELECT (embedding <=> embedding) FROM kb_chunks LIMIT 1")).scalar()
        await m.reply_text(f"pg_typeof(embedding) = {t}\n(embedding <=> embedding) = {d}")
    except Exception as e:
        log.exception("rag_selftest failed")
        await m.reply_text(f"‚ùå rag_selftest: {e}")

# ---- RAG helpers ----
from typing import List, Tuple

def _vec_literal(vec: list[float]) -> tuple[dict, str]:
    # –ø–æ–¥–∞—ë–º —Å—Ç—Ä–æ–∫—É –≤–∏–¥–∞ "[0.1,0.2,...]" –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–µ q
    arr = "[" + ",".join(f"{x:.6f}" for x in (vec or [])) + "]"
    return {"q": arr}, "CAST(:q AS vector)"   # <- –≤–æ–∑–≤—Ä–∞—â–∞–µ–º params –∏ SQL-–≤—ã—Ä–∞–∂–µ–Ω–∏–µ

def _embed_query(text: str) -> List[float]:
    from openai import OpenAI
    client = OpenAI(api_key=settings.openai_api_key)
    return client.embeddings.create(model=settings.embedding_model, input=[text]).data[0].embedding

def _retrieve_chunks(db, dialog_id: int, question: str, k: int = 6) -> List[dict]:
    # –µ—Å–ª–∏ —Å—Ç–æ–ª–±–µ—Ü embedding –Ω–µ –≤ vector-—Ç–∏–ø–µ ‚Äî –ø—Ä–æ—Å—Ç–æ –≤–µ—Ä–Ω—ë–º –ø—É—Å—Ç–æ (RAG –æ—Ç–∫–ª—é—á–∏—Ç—Å—è)
    kind = _kb_embedding_column_kind(db)
    if kind != "vector":
        return []

    q = _embed_query(question)
    params, qexpr = _vec_literal(q)
    
    sql = f"""
        SELECT c.content, c.meta, d.path
        FROM kb_chunks c
        JOIN kb_documents d    ON d.id = c.document_id AND d.is_active = TRUE
        JOIN dialog_kb_links l ON l.document_id = c.document_id
        WHERE l.dialog_id = :did
        ORDER BY c.embedding <=> {qexpr}
        LIMIT :k
    """
    p = {"did": dialog_id, "k": k}
    p.update(params)
    rows = db.execute(sa_text(sql), p).mappings().all()
    return [dict(r) for r in rows]

_STYLE_EXAMPLES = {
    "pro":    "–ö—Ä–∞—Ç–∫–æ, –ø–æ —à–∞–≥–∞–º, —á–µ–∫-–ª–∏—Å—Ç. –ë–µ–∑ –≤–æ–¥—ã. –ü—Ä–∏–º–µ—Ä: ¬´–®–∞–≥–∏ 1‚Äì5, —Ä–∏—Å–∫–∏, KPI, –¥–µ–¥–ª–∞–π–Ω—ã¬ª.",
    "expert": "–ì–ª—É–±–æ–∫–æ –∏ –æ–±—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ: –ø—Ä–∏—á–∏–Ω—ã/—Å–ª–µ–¥—Å—Ç–≤–∏—è, –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã, —Å—Å—ã–ª–∫–∏. –ü—Ä–∏–º–µ—Ä: ¬´–ù–∞—á–Ω—ë–º —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π‚Ä¶¬ª.",
    "user":   "–ü—Ä–æ—Å—Ç–æ, –ø–æ–Ω—è—Ç–Ω—ã–º —è–∑—ã–∫–æ–º, —Å –º–µ—Ç–∞—Ñ–æ—Ä–∞–º–∏ –∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∏–∑ –∂–∏–∑–Ω–∏.",
    "ceo":    "–° —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –±–∏–∑–Ω–µ—Å–∞: —Ü–µ–Ω–Ω–æ—Å—Ç—å/—Å—Ç–æ–∏–º–æ—Å—Ç—å, —Ä–∏—Å–∫–∏, —Å—Ä–æ–∫–∏, —Ä–µ—à–µ–Ω–∏—è, –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏ trade-offs.",
}

def _build_prompt_with_style(ctx_blocks: List[str], user_q: str, dialog_style: str) -> str:
    style_map = {
        "pro":   "–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —ë–º–∫–æ –∏ –ø–æ –¥–µ–ª—É, —à–∞–≥–∏ –∏ —á–µ–∫-–ª–∏—Å—Ç.",
        "expert":"–≠–∫—Å–ø–µ—Ä—Ç: –ø–æ–¥—Ä–æ–±–Ω–æ, –ø—Ä–∏—á–∏–Ω—ã/—Å–ª–µ–¥—Å—Ç–≤–∏—è, –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã, –≤—ã–≤–æ–¥—ã. –¶–∏—Ç–∞—Ç—ã –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Ç–æ–ª—å–∫–æ –≤ –∫–æ–Ω—Ü–µ.",
        "user":  "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏, –ø—Ä–∏–º–µ—Ä—ã –∏ –∞–Ω–∞–ª–æ–≥–∏–∏.",
        "ceo":   "CEO: –±–∏–∑–Ω–µ—Å-—Ü–µ–Ω–Ω–æ—Å—Ç—å, ROI, —Ä–∏—Å–∫–∏, —Ä–µ—à–µ–Ω–∏—è –∏ –∫–æ–º–ø—Ä–æ–º–∏—Å—Å—ã.",
    }
    style_line = style_map.get(dialog_style or "pro", style_map["pro"])
    header = (
        "–¢—ã ‚Äî –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –ë–ó, –Ω–æ –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–π—Å—è —Ü–∏—Ç–∞—Ç–∞–º–∏: "
        "—Å–∏–Ω—Ç–µ–∑–∏—Ä—É–π —Ü–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —Å—Ç–∏–ª–µ. –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–µ—Ç ‚Äî —É—Ç–æ—á–Ω–∏."
    )
    ctx = "\n\n".join([f"[–§—Ä–∞–≥–º–µ–Ω—Ç #{i+1}]\n{t}" for i, t in enumerate(ctx_blocks)])
    return f"{header}\n–°—Ç–∏–ª—å: {style_line}\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{ctx}\n\n–í–æ–ø—Ä–æ—Å: {user_q}"

def _format_citations(chunks: List[dict]) -> str:
    # –ë–µ—Ä—ë–º –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
    def short(p: str) -> str:
        return (p or "").split("/")[-1].split("?")[0]
    uniq = []
    for r in chunks:
        name = short(r.get("path") or (r.get("meta") or {}).get("path", ""))
        if name and name not in uniq:
            uniq.append(name)
    if not uniq: 
        return ""
    return "\n\n–ò—Å—Ç–æ—á–Ω–∏–∫–∏: " + "; ".join(f"[{i+1}] {n}" for i, n in enumerate(uniq[:5]))

async def on_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    # –ø–µ—Ä–µ—Ö–≤–∞—Ç –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è
    if "rename_dialog_id" in context.user_data:
        dlg_id = context.user_data.pop("rename_dialog_id")
        new_title = (m.text or "").strip()[:100]
        if not new_title:
            return await m.reply_text("–ù–∞–∑–≤–∞–Ω–∏–µ –ø—É—Å—Ç–æ–µ. –û—Ç–º–µ–Ω–µ–Ω–æ.")
        try:
            with SessionLocal() as db:
                db.execute(sa_text("UPDATE dialogs SET title=:t WHERE id=:d"), {"t": new_title, "d": dlg_id})
                db.commit()
            return await m.reply_text("–ù–∞–∑–≤–∞–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ.")
        except Exception:
            log.exception("rename dialog title failed")
            return await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ.")

    q = (m.text or "").strip()
    if not q:
        return
    try:
        with SessionLocal() as db:
            uid = _ensure_user(db, update.effective_user.id)
            did = _ensure_dialog(db, uid)
            row = db.execute(sa_text("SELECT model, style FROM dialogs WHERE id=:d"), {"d": did}).first()
            dia_model = row[0] if row and row[0] else settings.openai_model
            dia_style = row[1] if row and row[1] else "pro"
            chunks = _retrieve_chunks(db, did, q, k=6)
            ctx_blocks = [r.get("content", "")[:1000] for r in chunks] if chunks else []

        # —Å—Ç—Ä–æ–∏–º –ø—Ä–æ–º–ø—Ç
        prompt = _build_prompt_with_style(ctx_blocks, q, dia_style) if ctx_blocks else q

        # –ü–û–õ–ù–´–ô –æ—Ç–≤–µ—Ç (–∞–≤—Ç–æ–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ)
        system = {"role": "system", "content": "RAG assistant"}
        user = {"role": "user", "content": prompt}
        answer = await _chat_full(dia_model, [system, user], temperature=0.3)

        if chunks:
            answer += _format_citations(chunks)

        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é (—Ü–µ–ª–∏–∫–æ–º)
        try:
            with SessionLocal() as db:
                uid = _ensure_user(db, update.effective_user.id)
                did = _ensure_dialog(db, uid)
                db.execute(sa_text("INSERT INTO messages (dialog_id, role, content, created_at) VALUES (:d,'user',:c,now())"),
                           {"d": did, "c": q})
                db.execute(sa_text("INSERT INTO messages (dialog_id, role, content, created_at) VALUES (:d,'assistant',:c,now())"),
                           {"d": did, "c": answer})
                db.execute(sa_text("UPDATE dialogs SET last_message_at=now() WHERE id=:d"), {"d": did})
                db.commit()
        except Exception:
            log.exception("save messages failed")

        # –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ —á–∞—Å—Ç—è–º
        await _send_long(m, answer)

    except Exception:
        log.exception("on_text failed")
        await m.reply_text("‚ö† –ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")

# === DIAG: –ø–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å –≤—Å–µ—Ö PDF –Ω–∞ –¥–∏—Å–∫–µ –∏ —á—Ç–æ —Å –Ω–∏–º–∏ –ø—Ä–∏ —Ä–∞–∑–±–æ—Ä–µ ===
async def kb_pdf_diag(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        if not _is_admin(update.effective_user.id):
            return await m.reply_text("–¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞.")

        root = settings.yandex_root_path
        files = [f for f in _ya_list_files(root) if (f.get("name") or "").lower().endswith(".pdf")]

        lines = []
        for it in files:
            path = it.get("path") or it.get("name")
            try:
                blob = ya_download(path)
                txt, pages, is_prot = _pdf_extract_text(blob)
                sample = (txt or "").strip().replace("\n", " ")
                sample = (sample[:120] + "‚Ä¶") if len(sample) > 120 else sample
                lines.append(f"‚Ä¢ {path.split('/')[-1]} | pages={pages} | prot={'yes' if is_prot else 'no'} | text_len={len(txt or '')} | sample='{sample}'")
            except Exception as e:
                lines.append(f"‚Ä¢ {path.split('/')[-1]} | ERROR: {e}")
        if not lines:
            lines = ["(PDF –Ω–µ –Ω–∞–π–¥–µ–Ω—ã)"]
        await m.reply_text("PDF DIAG:\n" + "\n".join(lines[:30]))
    except Exception:
        log.exception("kb_pdf_diag failed")
        await m.reply_text("‚ö† kb_pdf_diag: –æ—à–∏–±–∫–∞. –°–º–æ—Ç—Ä–∏ –ª–æ–≥–∏.")

async def rag_diag(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    q = " ".join(context.args) if context.args else ""
    if not q:
        return await m.reply_text("–ù–∞–ø–∏—à–∏—Ç–µ –∑–∞–ø—Ä–æ—Å: /rag_diag –≤–∞—à –≤–æ–ø—Ä–æ—Å")
    try:
        with SessionLocal() as db:
            uid = _ensure_user(db, update.effective_user.id)
            did = _ensure_dialog(db, uid)
            rows = _retrieve_chunks(db, did, q, k=5)
            if not rows:
                return await m.reply_text("–ù–∏—á–µ–≥–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –Ω–µ –Ω–∞—à–ª–∏ —Å—Ä–µ–¥–∏ –ø–æ–¥–∫–ª—é—á—ë–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.")
            out = []
            for i, r in enumerate(rows, 1):
                path = (r.get("path") or (r.get("meta") or {}).get("path", "")).split("/")[-1]
                sample = (r["content"] or "")[:140].replace("\n", " ")
                out.append(f"[{i}] {path} ‚Äî ‚Äú{sample}‚Ä¶‚Äù")
            await m.reply_text("\n".join(out))
    except Exception:
        log.exception("rag_diag failed")
        await m.reply_text("‚ö† rag_diag: –æ—à–∏–±–∫–∞. –°–º–æ—Ç—Ä–∏ –ª–æ–≥–∏.")

# ---- PDF helpers ----
def _pdf_extract_text(pdf_bytes: bytes) -> tuple[str, int, bool]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (—Ç–µ–∫—Å—Ç, pages, is_protected).
    1) PyMuPDF
    2) Fallback –Ω–∞ pdfminer.six, –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –ø—É—Å—Ç–æ–π –∏ –Ω–µ –∑–∞—â–∏—â—ë–Ω
    """
    import fitz  # PyMuPDF
    with fitz.open(stream=pdf_bytes, filetype="pdf") as doc:
        is_prot = bool(doc.is_encrypted)
        if is_prot:
            try:
                if doc.authenticate(""):
                    is_prot = False
            except Exception:
                pass
        if is_prot:
            return ("", 0, True)

        pages = doc.page_count
        out = []
        for i in range(pages):
            try:
                text = doc.load_page(i).get_text("text") or ""
            except Exception:
                text = ""
            out.append(text)
        txt = "\n".join(out)

    # Fallback: –µ—Å–ª–∏ –ø—É—Å—Ç–æ, –ø–æ–ø—Ä–æ–±—É–µ–º pdfminer
    if not txt.strip():
        try:
            from io import BytesIO
            from pdfminer.high_level import extract_text
            txt = extract_text(BytesIO(pdf_bytes)) or ""
        except Exception:
            pass

    return (txt, pages, False)


# 0) –∫–∞–∫–æ–≥–æ —Ç–∏–ø–∞ –∫–æ–ª–æ–Ω–∫–∞ embedding –≤ kb_chunks: 'vector' | 'bytea' | 'none'
try:
    _kb_embedding_column_kind
except NameError:
    def _kb_embedding_column_kind(db) -> str:
        try:
            t = db.execute(sa_text("SELECT pg_typeof(embedding)::text FROM kb_chunks LIMIT 1")).scalar()
            if t:
                t = str(t).lower()
                if "vector" in t:
                    return "vector"
                if "bytea" in t:
                    return "bytea"
            # fallback —á–µ—Ä–µ–∑ information_schema
            t = db.execute(sa_text("""
                SELECT COALESCE(udt_name, data_type)
                FROM information_schema.columns
                WHERE table_name='kb_chunks' AND column_name='embedding'
                LIMIT 1
            """)).scalar()
            t = (t or "").lower()
            if "vector" in t:
                return "vector"
            if "bytea" in t:
                return "bytea"
        except Exception:
            pass
        return "none"

# 1) upsert –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ kb_documents (–≤–æ–∑–≤—Ä–∞—â–∞–µ–º id)
try:
    _kb_upsert_document
except NameError:
    def _kb_upsert_document(db, path: str, mime: str, size: int, etag: str) -> int:
        sql = sa_text("""
            INSERT INTO kb_documents (path, mime, bytes, etag, updated_at, is_active)
            VALUES (:p, :m, :b, :e, now(), TRUE)
            ON CONFLICT (path) DO UPDATE
              SET mime = EXCLUDED.mime,
                  bytes = EXCLUDED.bytes,
                  etag  = EXCLUDED.etag,
                  updated_at = now(),
                  is_active = TRUE
            RETURNING id
        """)
        doc_id = db.execute(sql, {"p": path, "m": mime, "b": size, "e": etag}).scalar()
        db.commit()
        return int(doc_id)

# 2) –æ—á–∏—Å—Ç–∫–∞ —á–∞–Ω–∫–æ–≤ –ø–æ document_id
try:
    _kb_clear_chunks
except NameError:
    def _kb_clear_chunks(db, document_id: int):
        db.execute(sa_text("DELETE FROM kb_chunks WHERE document_id=:d"), {"d": document_id})
        db.commit()

# 3) –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —Å –Ø.–î–∏—Å–∫–∞ –ø–æ –ø—É—Ç–∏
try:
    _ya_download
except NameError:
    def _chunk_text(text: str, max_tokens: int = 2000, overlap: int = 0):
        """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –∫—É—Å–∫–∏ –ø–æ max_tokens –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º overlap"""
        enc = tiktoken.get_encoding("cl100k_base")
        tokens = enc.encode(text)
    
        chunks = []
        i = 0
        while i < len(tokens):
            chunk_tokens = tokens[i:i+max_tokens]
            chunk_text = enc.decode(chunk_tokens)
            chunks.append(chunk_text.strip())
            if overlap > 0:
                i += max_tokens - overlap
            else:
                i += max_tokens
    
        return chunks

# 4) –ø—Ä–æ—Å—Ç–∞—è —Ä–µ–∑–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞–Ω–∫–∏
try:
    _chunk_text
except NameError:
    def _chunk_text(text: str, max_tokens: int = 2000):
        """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –∫—É—Å–∫–∏ –ø–æ max_tokens –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        enc = tiktoken.get_encoding("cl100k_base")
        tokens = enc.encode(text)
    
        chunks = []
        for i in range(0, len(tokens), max_tokens):
            chunk_tokens = tokens[i:i+max_tokens]
            chunk_text = enc.decode(chunk_tokens)
            chunks.append(chunk_text.strip())
    
        return chunks

# 5) —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –ø–∞—á–∫–æ–π (OpenAI)
try:
    _get_embeddings
except NameError:
    def _get_embeddings(chunks: list[str]) -> list[list[float]]:
        """
        –°—á–∏—Ç–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ, –±–∞—Ç—á–∞–º–∏:
        - –ª–∏–º–∏—Ç –ø–æ —Å—É–º–º–∞—Ä–Ω—ã–º —Ç–æ–∫–µ–Ω–∞–º ~250k –Ω–∞ –∑–∞–ø—Ä–æ—Å (–∑–∞–ø–∞—Å –æ—Ç 300k);
        - –¥–æ–ø. –ª–∏–º–∏—Ç –Ω–∞ —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —ç–ª–µ–º–µ–Ω—Ç–æ–≤, —á—Ç–æ–±—ã –Ω–µ —Ä–∞–∑–¥—É–≤–∞—Ç—å payload.
        """
        if not chunks:
            return []
    
        enc = tiktoken.get_encoding("cl100k_base")
        from openai import OpenAI
        client = OpenAI(api_key=settings.openai_api_key)
    
        MAX_TOKENS_PER_REQ = 250_000   # –∑–∞–ø–∞—Å –æ—Ç –ª–∏–º–∏—Ç–∞ 300k
        MAX_ITEMS_PER_REQ  = 128       # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –æ–≥—Ä–∞–Ω–∏—á–∏–º –∏ –ø–æ —á–∏—Å–ª—É —Å—Ç—Ä–æ–∫
    
        out: list[list[float]] = []
        batch: list[str] = []
        batch_tok_sum = 0
    
        def flush_batch():
            nonlocal out, batch, batch_tok_sum
            if not batch:
                return
            resp = client.embeddings.create(model=settings.embedding_model, input=batch)
            data = getattr(resp, "data", None) or resp.get("data", [])
            # order –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω, –ø—Ä–æ—Å—Ç–æ –¥–æ–ø–∏—Å—ã–≤–∞–µ–º
            out.extend([item.embedding for item in data])
            batch = []
            batch_tok_sum = 0
    
        for ch in chunks:
            t = len(enc.encode(ch or ""))
            # –µ—Å–ª–∏ –æ–¥–∏–Ω–æ—á–Ω—ã–π —á–∞–Ω–∫ –≤–¥—Ä—É–≥ –±–æ–ª—å—à–µ –ª–∏–º–∏—Ç–∞ ‚Äî —É–∂–µ –ø–æ—Ä–µ–∑–∞–Ω —Ä–∞–Ω–µ–µ; –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π:
            if t > MAX_TOKENS_PER_REQ:
                # –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞—â–∏—Ç–∞: –¥–æ—Ä–µ–∑–∞—Ç—å –Ω–∞ –ø–æ–¥—á–∞–Ω–∫–∏ –ø–æ 2000 —Ç–æ–∫–µ–Ω–æ–≤
                subchunks = []
                toks = enc.encode(ch or "")
                for i in range(0, len(toks), 2000):
                    subchunks.append(enc.decode(toks[i:i+2000]))
                # —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø—Ä–æ–≥–æ–Ω—è–µ–º –ø–æ–¥—á–∞–Ω–∫–∏ —Ç–µ–º –∂–µ –º–µ—Ö–∞–Ω–∏–∑–º–æ–º
                out.extend(_get_embeddings(subchunks))
                continue
    
            # –µ—Å–ª–∏ —Ç–µ–∫—É—â–∏–π –Ω–µ –≤–ª–µ–∑–∞–µ—Ç –≤ –±–∞—Ç—á ‚Äî —à–ª—ë–º —Ç–æ, —á—Ç–æ –Ω–∞–∫–æ–ø–ª–µ–Ω–æ
            if batch and (batch_tok_sum + t > MAX_TOKENS_PER_REQ or len(batch) >= MAX_ITEMS_PER_REQ):
                flush_batch()
    
            batch.append(ch)
            batch_tok_sum += t
    
        flush_batch()
        return out

# 6) SQL-—Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
try:
    _format_vector_sql
except NameError:
    def _format_vector_sql(vec: list[float]) -> tuple[str, dict]:
        arr = "[" + ",".join(f"{x:.6f}" for x in (vec or [])) + "]"
        return " CAST(:emb AS vector) ", {"emb": arr}

try:
    _format_bytea_sql
except NameError:
    def _format_bytea_sql(vec: list[float]) -> tuple[str, dict]:
        try:
            import struct
            from psycopg2 import Binary
            b = struct.pack(f"{len(vec)}f", *vec) if vec else b""
            return " :emb ", {"emb": Binary(b)}
        except Exception:
            return " NULL ", {}
# ==== /KB RAG helpers ====

# --- Fallback –ª–∏—Å—Ç–∏–Ω–≥ –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–∞ (–µ—Å–ª–∏ –Ω–µ—Ç —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ö–µ–ª–ø–µ—Ä–∞) ---
def _ya_list_files(root_path: str):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ –Ø.–î–∏—Å–∫–∞ —á–µ—Ä–µ–∑ REST API.
    –≠–ª–µ–º–µ–Ω—Ç—ã: name, path, type, mime_type, size, md5.
    """
    import requests
    YA_API = "https://cloud-api.yandex.net/v1/disk"
    out = []
    limit, offset = 200, 0
    headers = {"Authorization": f"OAuth {settings.yandex_disk_token}"}
    while True:
        params = {
            "path": root_path,
            "limit": limit,
            "offset": offset,
            "fields": "_embedded.items.name,_embedded.items.path,_embedded.items.type,_embedded.items.mime_type,_embedded.items.size,_embedded.items.md5",
        }
        r = requests.get(f"{YA_API}/resources", headers=headers, params=params, timeout=30)
        r.raise_for_status()
        data = r.json()
        items = (data.get("_embedded") or {}).get("items") or []
        for it in items:
            if it.get("type") == "file":
                out.append(it)
        if len(items) < limit:
            break
        offset += limit
    return out


def _kb_update_pages(db, document_id: int, pages: int | None):
    if pages is None:
        return
    db.execute(sa_text("UPDATE kb_documents SET pages=:p, updated_at=now() WHERE id=:id"), {"p": pages, "id": document_id})
    db.commit()

# –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ PDF (–±–µ–∑ –ø–∞—Ä–æ–ª—è). –ó–∞—â–∏—â—ë–Ω–Ω—ã–µ PDF —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º, –Ω–æ –Ω–µ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º.

async def kb_sync_pdf(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        if not _is_admin(update.effective_user.id):
            return await m.reply_text("–¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞.")
        await m.reply_text("üìÑ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è PDF –Ω–∞—á–∞–ª–∞—Å—å‚Ä¶")

        root = settings.yandex_root_path
        files = [f for f in _ya_list_files(root) if (f.get("name") or "").lower().endswith(".pdf")]

        touched_docs = len(files)
        indexed_docs = 0
        indexed_chunks = 0

        with SessionLocal() as db:
            emb_kind = _kb_embedding_column_kind(db)  # 'vector' | 'bytea' | 'none'

            # –î–µ–∞–∫—Ç–∏–≤–∏—Ä—É–µ–º PDF, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –Ω–∞ –¥–∏—Å–∫–µ
            present = { (f.get("path") or f.get("name")) for f in files if (f.get("path") or f.get("name")) }
            rows = db.execute(sa_text("SELECT id, path, is_active FROM kb_documents WHERE mime LIKE 'application/pdf%'")).mappings().all()
            for r in rows:
                if r["path"] not in present and r["is_active"]:
                    db.execute(sa_text("UPDATE kb_documents SET is_active=FALSE, updated_at=now() WHERE id=:id"), {"id": r["id"]})
            db.commit()

            for it in files:
                path  = it.get("path") or it.get("name")
                mime  = it.get("mime_type") or "application/pdf"
                size  = int(it.get("size") or 0)
                etag  = it.get("md5") or ""
                if not path:
                    continue

                doc_id = _kb_upsert_document(db, path=path, mime=mime, size=size, etag=etag)

                # –°–∫–∞—á–∏–≤–∞–µ–º
                try:
                    blob = ya_download(path)
                except Exception as e:
                    log.exception("pdf download failed: %s (%s)", path, e)
                    continue

                # –ü–∞—Ä—Å–∏–º
                try:
                    txt, pages, is_prot = _pdf_extract_text(blob)
                except Exception as e:
                    log.exception("pdf parse failed: %s (%s)", path, e)
                    continue

                _kb_update_pages(db, doc_id, pages if pages else None)

                # –ó–∞—â–∏—â—ë–Ω–Ω—ã–π –∏–ª–∏ –ø—É—Å—Ç–æ–π PDF ‚Äî –Ω–µ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º
                if is_prot or not txt.strip():
                    log.info("pdf skipped (protected or empty): %s", path)
                    continue

                # –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Ü–µ–ª–∏–∫–æ–º –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
                _kb_clear_chunks(db, doc_id)

                chunks = _chunk_text(txt, settings.chunk_size, settings.chunk_overlap)
                embs = _get_embeddings(chunks) if emb_kind in ("vector","bytea") else [[] for _ in chunks]

                doc_failed = False
                inserted = 0
                for idx, (ch, ve) in enumerate(zip(chunks, embs)):
                    meta = {"path": path, "mime": mime}
                    if emb_kind == "vector":
                        place, params = _format_vector_sql(ve)
                    elif emb_kind == "bytea":
                        place, params = _format_bytea_sql(ve)
                    else:
                        place, params = " NULL ", {}

                    sql = f"""
                        INSERT INTO kb_chunks (document_id, chunk_index, content, meta, embedding)
                        VALUES (:d, :i, :c, :meta, {place})
                    """
                    p = {"d": doc_id, "i": idx, "c": ch, "meta": json.dumps(meta)}
                    p.update(params)
                    try:
                        db.execute(sa_text(sql), p)
                        inserted += 1
                        if inserted % 200 == 0:
                            db.commit()
                    except Exception as e:
                        log.exception("insert pdf chunk failed (doc_id=%s, idx=%s): %s", doc_id, idx, e)
                        doc_failed = True
                        continue

                db.commit()

                if not doc_failed and inserted > 0:
                    indexed_docs += 1
                    indexed_chunks += inserted

        await m.reply_text(
            "‚úÖ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è PDF –∑–∞–≤–µ—Ä—à–µ–Ω–∞.\n"
            f"–î–æ–∫—É–º–µ–Ω—Ç–æ–≤ —É—á—Ç–µ–Ω–æ: {touched_docs}\n"
            f"–ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ: {indexed_docs} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, {indexed_chunks} —á–∞–Ω–∫–æ–≤"
        )
    except Exception as e:
        log.exception("kb_sync_pdf failed")
        await (update.effective_message or update.message).reply_text(f"‚ö† kb_sync_pdf: {e}")

# --- KB sync (—É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–∑–æ–≤ indexer) ---
import os, re, inspect, asyncio

async def kb_sync(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    if not _is_admin(update.effective_user.id):
        return await m.reply_text("‚õî –î–æ—Å—Ç—É–ø —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∞–º.")

    await m.reply_text("üîÑ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–ø—É—â–µ–Ω–∞...")

    try:
        from bot.knowledge_base import indexer

        # 0) –Ø–≤–Ω—ã–π entrypoint —á–µ—Ä–µ–∑ settings/ENV (–µ—Å–ª–∏ –∑–∞–¥–∞–ª–∏)
        explicit = getattr(settings, "kb_sync_entrypoint", None) or os.getenv("KB_SYNC_ENTRYPOINT")
        fn = getattr(indexer, explicit, None) if explicit else None

        # 1) –û—Å–Ω–æ–≤–Ω—ã–µ –∏–º–µ–Ω–∞
        if not fn:
            for name in ("sync_kb","sync_all","sync_from_yandex","sync","run_sync","full_sync",
                         "reindex","index_all","ingest_all","ingest","main"):
                if hasattr(indexer, name) and callable(getattr(indexer, name)):
                    fn = getattr(indexer, name)
                    break

        # 2) –õ—é–±–∞—è –ø—É–±–ª–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –ø–æ–¥—Å—Ç—Ä–æ–∫–æ–π sync/index/ingest
        if not fn:
            for name in dir(indexer):
                if name.startswith("_"):
                    continue
                if re.search(r"(sync|index|ingest)", name, re.I) and callable(getattr(indexer, name)):
                    fn = getattr(indexer, name)
                    break

        if not fn:
            raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω entrypoint –≤ indexer.py. –ó–∞–¥–∞–π KB_SYNC_ENTRYPOINT –∏–ª–∏ –¥–æ–±–∞–≤—å —Ñ—É–Ω–∫—Ü–∏—é sync_kb().")

        # --- –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –ø–æ –∏–º–µ–Ω–∞–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (—á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–ø—É—Ç–∞—Ç—å –ø–æ—Ä—è–¥–æ–∫) ---
        sig = inspect.signature(fn)
        kwargs = {}
        session_to_close = None
        for p in sig.parameters.values():
            nm = p.name.lower()
            if nm in ("session", "db", "conn", "dbsession"):
                sess = SessionLocal()
                kwargs[p.name] = sess
                session_to_close = sess
            elif nm in ("sessionlocal", "session_factory", "factory"):
                kwargs[p.name] = SessionLocal
            elif nm in ("settings", "cfg", "config"):
                kwargs[p.name] = settings
            elif p.default is not inspect._empty:
                # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ ‚Äî –ø—Ä–æ—Å—Ç–æ –Ω–µ –ø–µ—Ä–µ–¥–∞—ë–º
                pass
            else:
                # –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–π ‚Äî –ø–æ–¥—Å—Ç–∞–≤–∏–º None
                kwargs[p.name] = None

        def _call():
            try:
                return fn(**kwargs)
            finally:
                if session_to_close is not None:
                    try:
                        session_to_close.close()
                    except Exception:
                        pass

        result = await asyncio.to_thread(_call)

        # --- –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é ---
        if isinstance(result, dict):
            upd = result.get("updated"); skp = result.get("skipped"); tot = result.get("total")
            msg = "‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞."
            if upd is not None or skp is not None or tot is not None:
                msg += f" –û–±–Ω–æ–≤–ª–µ–Ω–æ: {upd or 0}, –ø—Ä–æ–ø—É—â–µ–Ω–æ: {skp or 0}, –≤—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –Ω–∞ –¥–∏—Å–∫–µ: {tot or 0}."
            return await m.reply_text(msg)
        elif isinstance(result, (tuple, list)) and len(result) >= 2:
            return await m.reply_text(f"‚úÖ –ì–æ—Ç–æ–≤–æ: –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ {result[0]}, —á–∞–Ω–∫–æ–≤ {result[1]}")
        else:
            return await m.reply_text("‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
    except Exception as e:
        log.exception("kb_sync failed")
        return await m.reply_text(f"‚ö† –û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}")

async def kb_chunks_force(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        if not _is_admin(update.effective_user.id):
            return await m.reply_text("–¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞.")

        from sqlalchemy import text as sa_text
        notes = []

        with SessionLocal() as db:
            # 0) vector –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π (–±–µ–∑ –ø–∞–Ω–∏–∫–∏ –ø—Ä–∏ –æ—à–∏–±–∫–µ)
            try:
                db.execute(sa_text("CREATE EXTENSION IF NOT EXISTS vector;"))
                db.commit()
            except Exception:
                db.rollback()
                notes.append("[warn] CREATE EXTENSION vector failed")

            # 1) –°–æ–∑–¥–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É (–µ—Å–ª–∏ vector –µ—Å—Ç—å ‚Äî —Å vector(3072), –∏–Ω–∞—á–µ fallback BYTEA)
            has_vector_type = False
            try:
                has_vector_type = db.execute(sa_text(
                    "SELECT EXISTS(SELECT 1 FROM pg_type WHERE typname='vector')"
                )).scalar()
            except Exception:
                pass

            try:
                if has_vector_type:
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS kb_chunks (
                            id           BIGSERIAL PRIMARY KEY,
                            document_id  BIGINT NOT NULL,
                            chunk_index  INTEGER NOT NULL,
                            content      TEXT NOT NULL,
                            meta         JSON,
                            embedding    vector(3072)
                        );
                    """))
                else:
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS kb_chunks (
                            id           BIGSERIAL PRIMARY KEY,
                            document_id  BIGINT NOT NULL,
                            chunk_index  INTEGER NOT NULL,
                            content      TEXT NOT NULL,
                            meta         JSON,
                            embedding    BYTEA
                        );
                    """))
                    notes.append("[info] fallback: embedding BYTEA (–Ω–µ—Ç —Ç–∏–ø–∞ vector)")
                db.commit()
            except Exception as e:
                db.rollback()
                raise RuntimeError(f"CREATE TABLE failed: {e}")

            # 2) –ü—Ä–æ—Å—Ç–µ–π—à–∏–µ –∏–Ω–¥–µ–∫—Å—ã (–±–µ–∑ ivfflat) ‚Äî –æ—Ç–¥–µ–ª—å–Ω–∞—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è
            try:
                db.execute(sa_text("CREATE INDEX IF NOT EXISTS ix_kb_chunks_document_id ON kb_chunks(document_id);"))
                db.execute(sa_text("CREATE INDEX IF NOT EXISTS ix_kb_chunks_doc_chunk ON kb_chunks(document_id, chunk_index);"))
                db.commit()
            except Exception as e:
                db.rollback()
                notes.append(f"[warn] create simple indexes failed: {e}")

            # 3) –í–Ω–µ—à–Ω–∏–π –∫–ª—é—á –Ω–∞ kb_documents ‚Äî –æ—Ç–¥–µ–ª—å–Ω–∞—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è
            try:
                db.execute(sa_text("""
                    DO $$
                    BEGIN
                        IF NOT EXISTS (
                           SELECT 1 FROM pg_constraint WHERE conname='fk_kb_chunks_docs'
                        ) THEN
                           ALTER TABLE kb_chunks
                           ADD CONSTRAINT fk_kb_chunks_docs
                           FOREIGN KEY (document_id) REFERENCES kb_documents(id) ON DELETE CASCADE;
                        END IF;
                    END $$;
                """))
                db.commit()
            except Exception as e:
                db.rollback()
                notes.append(f"[warn] add FK failed: {e}")

        await m.reply_text("‚úÖ kb_chunks —Å–æ–∑–¥–∞–Ω–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–∞ (–±–µ–∑ ivfflat).\n" + ("\n".join(notes) if notes else ""))
    except Exception as e:
        import traceback
        tb = traceback.format_exc(limit=3)
        log.exception("kb_chunks_force failed")
        await m.reply_text(f"‚ö† kb_chunks_force: {e}\n{tb}")

# –î–æ–≤–µ–¥—ë–º kb_chunks: —É–±–µ—Ä—ë–º ivfflat, –¥–æ–±–∞–≤–∏–º FK –∏ —Ç–µ—Ö.–∏–Ω–¥–µ–∫—Å—ã
async def kb_chunks_fix(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        if not _is_admin(update.effective_user.id):
            return await m.reply_text("–¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞.")
        from sqlalchemy import text as sa_text
        with SessionLocal() as db:
            # —É–¥–∞–ª–∏—Ç—å ivfflat-–∏–Ω–¥–µ–∫—Å –µ—Å–ª–∏ –æ–Ω —É—Å–ø–µ–ª —Å–æ–∑–¥–∞—Ç—å—Å—è —á–∞—Å—Ç–∏—á–Ω–æ (–Ω–∞ –≤—Å—è–∫–∏–π)
            try:
                db.execute(sa_text("DROP INDEX IF EXISTS kb_chunks_embedding_idx;"))
                db.commit()
            except Exception:
                db.rollback()
            # –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º
            db.execute(sa_text("CREATE INDEX IF NOT EXISTS ix_kb_chunks_document_id ON kb_chunks(document_id);"))
            db.execute(sa_text("CREATE INDEX IF NOT EXISTS ix_kb_chunks_doc_chunk ON kb_chunks(document_id, chunk_index);"))
            # –¥–æ–±–∞–≤–∏—Ç—å FK –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
            try:
                db.execute(sa_text("""
                    DO $$
                    BEGIN
                        IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname='fk_kb_chunks_docs') THEN
                            ALTER TABLE kb_chunks
                            ADD CONSTRAINT fk_kb_chunks_docs
                            FOREIGN KEY (document_id) REFERENCES kb_documents(id) ON DELETE CASCADE;
                        END IF;
                    END $$;
                """))
            except Exception:
                pass
            db.commit()
        await m.reply_text("‚úÖ kb_chunks –ø–æ—á–∏–Ω–µ–Ω–∞: –±–µ–∑ ivfflat, —Å FK –∏ –∏–Ω–¥–µ–∫—Å–∞–º–∏.")
    except Exception:
        log.exception("kb_chunks_fix failed")
        await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—á–∏–Ω–∏—Ç—å kb_chunks. –°–º–æ—Ç—Ä–∏ –ª–æ–≥–∏.")

# –°–æ–∑–¥–∞—Ç—å kb_chunks –Ω–∞–¥—ë–∂–Ω–æ: —Å vector, –∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ ‚Äî fallback –±–µ–∑ vector
async def kb_chunks_create(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        if not _is_admin(update.effective_user.id):
            return await m.reply_text("–¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞.")

        from sqlalchemy import text as sa_text
        created_note = ""
        with SessionLocal() as db:
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è
            search_path = db.execute(sa_text("SHOW search_path")).scalar()
            has_tbl = db.execute(sa_text("SELECT to_regclass('public.kb_chunks') IS NOT NULL")).scalar()
            has_vector_ext = db.execute(sa_text(
                "SELECT EXISTS(SELECT 1 FROM pg_extension WHERE extname='vector')"
            )).scalar()
            has_vector_type = db.execute(sa_text(
                "SELECT EXISTS(SELECT 1 FROM pg_type WHERE typname='vector')"
            )).scalar()

            if has_tbl:
                return await m.reply_text("‚úÖ kb_chunks —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.")

            # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π ‚Äî —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
            if not has_vector_ext:
                try:
                    db.execute(sa_text("CREATE EXTENSION IF NOT EXISTS vector;"))
                    db.commit()
                    has_vector_ext = True
                except Exception as e:
                    db.rollback()
                    # –Ω–µ –ø–∞–¥–∞–µ–º ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º fallback
                    created_note += f"[warn] CREATE EXTENSION failed: {e}\n"

            # –û–±–Ω–æ–≤–∏–º –Ω–∞–ª–∏—á–∏–µ —Ç–∏–ø–∞
            if not has_vector_type:
                has_vector_type = db.execute(sa_text(
                    "SELECT EXISTS(SELECT 1 FROM pg_type WHERE typname='vector')"
                )).scalar()

            try:
                if has_vector_type:
                    # –û—Å–Ω–æ–≤–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç: —Å vector(3072)
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS kb_chunks (
                            id           BIGSERIAL PRIMARY KEY,
                            document_id  BIGINT NOT NULL,
                            chunk_index  INTEGER NOT NULL,
                            content      TEXT NOT NULL,
                            meta         JSON,
                            embedding    vector(3072)
                        );
                    """))
                    # –ò–Ω–¥–µ–∫—Å—ã –∏ FK (best-effort)
                    try:
                        db.execute(sa_text(
                            "CREATE INDEX IF NOT EXISTS ix_kb_chunks_document_id ON kb_chunks(document_id);"))
                        db.execute(sa_text("""
                            CREATE INDEX IF NOT EXISTS kb_chunks_embedding_idx
                            ON kb_chunks USING ivfflat (embedding vector_cosine_ops);
                        """))
                    except Exception as e:
                        created_note += f"[warn] index create failed: {e}\n"
                    try:
                        db.execute(sa_text("""
                            DO $$
                            BEGIN
                                IF NOT EXISTS (
                                   SELECT 1 FROM pg_constraint WHERE conname = 'fk_kb_chunks_docs'
                                ) THEN
                                   ALTER TABLE kb_chunks
                                   ADD CONSTRAINT fk_kb_chunks_docs
                                   FOREIGN KEY (document_id)
                                   REFERENCES kb_documents(id) ON DELETE CASCADE;
                                END IF;
                            END $$;
                        """))
                    except Exception as e:
                        created_note += f"[warn] FK create failed: {e}\n"

                    db.commit()
                    return await m.reply_text(
                        "‚úÖ kb_chunks —Å–æ–∑–¥–∞–Ω–∞ (vector). "
                        f"\nsearch_path={search_path}\n{created_note or ''}".strip()
                    )

                # Fallback: –±–µ–∑ vector ‚Äî embedding –∫–∞–∫ BYTEA, –±–µ–∑ ivfflat
                db.execute(sa_text("""
                    CREATE TABLE IF NOT EXISTS kb_chunks (
                        id           BIGSERIAL PRIMARY KEY,
                        document_id  BIGINT NOT NULL,
                        chunk_index  INTEGER NOT NULL,
                        content      TEXT NOT NULL,
                        meta         JSON,
                        embedding    BYTEA
                    );
                """))
                try:
                    db.execute(sa_text(
                        "CREATE INDEX IF NOT EXISTS ix_kb_chunks_document_id ON kb_chunks(document_id);"))
                except Exception as e:
                    created_note += f"[warn] fallback index failed: {e}\n"
                try:
                    db.execute(sa_text("""
                        DO $$
                        BEGIN
                            IF NOT EXISTS (
                               SELECT 1 FROM pg_constraint WHERE conname = 'fk_kb_chunks_docs'
                            ) THEN
                               ALTER TABLE kb_chunks
                               ADD CONSTRAINT fk_kb_chunks_docs
                               FOREIGN KEY (document_id)
                               REFERENCES kb_documents(id) ON DELETE CASCADE;
                            END IF;
                        END $$;
                    """))
                except Exception as e:
                    created_note += f"[warn] fallback FK failed: {e}\n"

                db.commit()
                return await m.reply_text(
                    "‚úÖ kb_chunks —Å–æ–∑–¥–∞–Ω–∞ (fallback –±–µ–∑ vector). "
                    f"\nsearch_path={search_path}\n{created_note or ''}".strip()
                )

            except Exception as e:
                db.rollback()
                raise e

    except Exception as e:
        log.exception("kb_chunks_create failed")
        await m.reply_text(f"‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å kb_chunks: {e}")

# —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥ –≤—Ä—É—á–Ω—É—é
async def dialog_new(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        tg = update.effective_user.id
        with SessionLocal() as db:
            did = _create_new_dialog_for_tg(db, tg)
        await m.reply_text(f"‚úÖ –°–æ–∑–¥–∞–Ω –¥–∏–∞–ª–æ–≥ #{did}")
    except Exception:
        log.exception("dialog_new failed")
        await m.reply_text("‚ö† –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞")

def _create_new_dialog_for_tg(db, tg_id: int) -> int:
    uid = _exec_scalar(db, "SELECT id FROM users WHERE tg_user_id=:tg ORDER BY id LIMIT 1", tg=tg_id)
    if not uid:
        uid = _ensure_user(db, tg_id)

    today = datetime.now().date().isoformat()
    cnt = _exec_scalar(db, """
        SELECT count(*) FROM dialogs d
        JOIN users u ON u.id = d.user_id
        WHERE u.tg_user_id = :tg AND d.is_deleted = FALSE
    """, tg=tg_id) or 0
    title = f"{today} | –¥–∏–∞–ª–æ–≥ {cnt+1}"

    did = _exec_scalar(db, """
        INSERT INTO dialogs (user_id, title, style, model, is_deleted, created_at, last_message_at)
        VALUES (:u, :t, :s, :m, FALSE, now(), NULL) RETURNING id
    """, u=uid, t=title, s="pro", m=settings.openai_model)
    db.commit()
    return did

async def pgvector_check(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        with SessionLocal() as db:
            avail = db.execute(sa_text(
                "SELECT EXISTS(SELECT 1 FROM pg_available_extensions WHERE name='vector')"
            )).scalar()
            installed = db.execute(sa_text(
                "SELECT EXISTS(SELECT 1 FROM pg_extension WHERE extname='vector')"
            )).scalar()
        await (update.effective_message or update.message).reply_text(
            f"pgvector –¥–æ—Å—Ç—É–ø–Ω–æ: {'‚úÖ' if avail else '‚ùå'}\n"
            f"pgvector —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ: {'‚úÖ' if installed else '‚ùå'}"
        )
    except Exception:
        log.exception("pgvector_check failed")
        await (update.effective_message or update.message).reply_text("‚ö† –û—à–∏–±–∫–∞ pgvector_check. –°–º–æ—Ç—Ä–∏ –ª–æ–≥–∏.")

async def repair_schema(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    –ß–∏–Ω–∏—Ç —Å—Ö–µ–º—É –ø–æ —à–∞–≥–∞–º –∏ —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ—Å–ª–µ –ö–ê–ñ–î–û–ô —Ç–∞–±–ª–∏—Ü—ã.
    –î–∞–∂–µ –µ—Å–ª–∏ –Ω–∞ kb_* —É–ø–∞–¥—ë—Ç, –±–∞–∑–æ–≤—ã–µ —Ç–∞–±–ª–∏—Ü—ã users/dialogs/messages –æ—Å—Ç–∞–Ω—É—Ç—Å—è.
    """
    m = update.effective_message or update.message
    try:
        if not _is_admin(update.effective_user.id):
            return await m.reply_text("–¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞.")

        await m.reply_text("üß∞ –†–µ–º–æ–Ω—Ç —Å—Ö–µ–º—ã –Ω–∞—á–∞—Ç. –ü–∏—à—É –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ –ª–æ–≥–∏...")

        from sqlalchemy import text as sa_text
        created = []
        with SessionLocal() as db:

            def has(table: str) -> bool:
                return bool(db.execute(sa_text("SELECT to_regclass(:t)"), {"t": f"public.{table}"}).scalar())

            # 0) vector extension ‚Äî –æ—Ç–¥–µ–ª—å–Ω–æ –∏ –±–µ–∑ –ø–∞–Ω–∏–∫–∏
            try:
                db.execute(sa_text("CREATE EXTENSION IF NOT EXISTS vector;"))
                db.commit()
                log.info("repair: extension vector OK (–∏–ª–∏ —É–∂–µ –±—ã–ª–æ)")
            except Exception:
                db.rollback()
                log.exception("repair: CREATE EXTENSION vector failed ‚Äî –ø—Ä–æ–¥–æ–ª–∂—É –±–µ–∑ –Ω–µ–≥–æ")

            # 1) USERS ‚Äî –°–ù–ê–ß–ê–õ–ê –ë–ê–ó–ê
            if not has("users"):
                db.execute(sa_text("""
                    CREATE TABLE IF NOT EXISTS users (
                        id           BIGSERIAL PRIMARY KEY,
                        tg_user_id   BIGINT UNIQUE NOT NULL,
                        is_admin     BOOLEAN NOT NULL DEFAULT FALSE,
                        is_allowed   BOOLEAN NOT NULL DEFAULT TRUE,
                        lang         TEXT,
                        created_at   TIMESTAMPTZ NOT NULL DEFAULT now()
                    );
                """))
                db.commit(); created.append("users"); log.info("repair: created users")

            # 2) DIALOGS
            if not has("dialogs"):
                db.execute(sa_text("""
                    CREATE TABLE IF NOT EXISTS dialogs (
                        id              BIGSERIAL PRIMARY KEY,
                        user_id         BIGINT NOT NULL,
                        title           TEXT,
                        style           VARCHAR(20) NOT NULL DEFAULT 'expert',
                        model           TEXT,
                        is_deleted      BOOLEAN NOT NULL DEFAULT FALSE,
                        created_at      TIMESTAMPTZ NOT NULL DEFAULT now(),
                        last_message_at TIMESTAMPTZ
                    );
                """))
                try:
                    db.execute(sa_text("""
                        DO $$
                        BEGIN
                            IF NOT EXISTS (
                               SELECT 1 FROM pg_constraint WHERE conname = 'fk_dialogs_users'
                            ) THEN
                               ALTER TABLE dialogs
                               ADD CONSTRAINT fk_dialogs_users
                               FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE;
                            END IF;
                        END $$;
                    """))
                except Exception:
                    log.exception("repair: FK dialogs->users skipped")
                db.commit(); created.append("dialogs"); log.info("repair: created dialogs")

            # 3) MESSAGES
            if not has("messages"):
                db.execute(sa_text("""
                    CREATE TABLE IF NOT EXISTS messages (
                        id         BIGSERIAL PRIMARY KEY,
                        dialog_id  BIGINT NOT NULL,
                        role       VARCHAR(20) NOT NULL,
                        content    TEXT NOT NULL,
                        tokens     INTEGER,
                        created_at TIMESTAMPTZ NOT NULL DEFAULT now()
                    );
                """))
                try:
                    db.execute(sa_text("""
                        DO $$
                        BEGIN
                            IF NOT EXISTS (
                               SELECT 1 FROM pg_constraint WHERE conname = 'fk_messages_dialogs'
                            ) THEN
                               ALTER TABLE messages
                               ADD CONSTRAINT fk_messages_dialogs
                               FOREIGN KEY (dialog_id) REFERENCES dialogs(id) ON DELETE CASCADE;
                            END IF;
                        END $$;
                    """))
                except Exception:
                    log.exception("repair: FK messages->dialogs skipped")
                db.commit(); created.append("messages"); log.info("repair: created messages")

            # --- –ë–ª–æ–∫ –ë–ó: –¥–µ–ª–∞–µ–º best-effort, –∫–∞–∂–¥—ã–π —à–∞–≥ –≤ —Å–≤–æ–µ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ ---

            # 4) KB_DOCUMENTS
            try:
                if not has("kb_documents"):
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS kb_documents (
                            id         BIGSERIAL PRIMARY KEY,
                            path       TEXT UNIQUE NOT NULL,
                            etag       TEXT,
                            mime       TEXT,
                            pages      INTEGER,
                            bytes      BIGINT,
                            updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
                            is_active  BOOLEAN NOT NULL DEFAULT TRUE
                        );
                    """))
                    db.commit(); created.append("kb_documents"); log.info("repair: created kb_documents")
            except Exception:
                db.rollback(); log.exception("repair: create kb_documents failed (–ø—Ä–æ–ø—É—Å–∫–∞—é)")

            # 5) KB_CHUNKS
            try:
                if not has("kb_chunks"):
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS kb_chunks (
                            id           BIGSERIAL PRIMARY KEY,
                            document_id  BIGINT NOT NULL,
                            chunk_index  INTEGER NOT NULL,
                            content      TEXT NOT NULL,
                            meta         JSON,
                            embedding    vector(3072)
                        );
                    """))
                    try:
                        db.execute(sa_text("CREATE INDEX IF NOT EXISTS ix_kb_chunks_document_id ON kb_chunks(document_id);"))
                        db.execute(sa_text("""
                            CREATE INDEX IF NOT EXISTS kb_chunks_embedding_idx
                            ON kb_chunks USING ivfflat (embedding vector_cosine_ops);
                        """))
                    except Exception:
                        log.exception("repair: kb_chunks indexes skipped")
                    try:
                        db.execute(sa_text("""
                            DO $$
                            BEGIN
                                IF NOT EXISTS (
                                   SELECT 1 FROM pg_constraint WHERE conname = 'fk_kb_chunks_docs'
                                ) THEN
                                   ALTER TABLE kb_chunks
                                   ADD CONSTRAINT fk_kb_chunks_docs
                                   FOREIGN KEY (document_id) REFERENCES kb_documents(id) ON DELETE CASCADE;
                                END IF;
                            END $$;
                        """))
                    except Exception:
                        log.exception("repair: FK kb_chunks->kb_documents skipped")
                    db.commit(); created.append("kb_chunks"); log.info("repair: created kb_chunks")
            except Exception:
                db.rollback(); log.exception("repair: create kb_chunks failed (–≤–æ–∑–º–æ–∂–Ω–æ, –Ω–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è vector)")

            # 6) DIALOG_KB_LINKS
            try:
                if not has("dialog_kb_links"):
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS dialog_kb_links (
                            id          BIGSERIAL PRIMARY KEY,
                            dialog_id   BIGINT NOT NULL,
                            document_id BIGINT NOT NULL,
                            created_at  TIMESTAMPTZ NOT NULL DEFAULT now()
                        );
                    """))
                    db.commit(); created.append("dialog_kb_links"); log.info("repair: created dialog_kb_links")
            except Exception:
                db.rollback(); log.exception("repair: create dialog_kb_links failed")

            # 7) PDF_PASSWORDS
            try:
                if not has("pdf_passwords"):
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS pdf_passwords (
                            id          BIGSERIAL PRIMARY KEY,
                            dialog_id   BIGINT NOT NULL,
                            document_id BIGINT NOT NULL,
                            pwd_hash    TEXT,
                            created_at  TIMESTAMPTZ NOT NULL DEFAULT now()
                        );
                    """))
                    db.commit(); created.append("pdf_passwords"); log.info("repair: created pdf_passwords")
            except Exception:
                db.rollback(); log.exception("repair: create pdf_passwords failed")

            # 8) AUDIT_LOG
            try:
                if not has("audit_log"):
                    db.execute(sa_text("""
                        CREATE TABLE IF NOT EXISTS audit_log (
                            id         BIGSERIAL PRIMARY KEY,
                            user_id    BIGINT,
                            action     TEXT,
                            meta       JSON,
                            created_at TIMESTAMPTZ NOT NULL DEFAULT now()
                        );
                    """))
                    db.commit(); created.append("audit_log"); log.info("repair: created audit_log")
            except Exception:
                db.rollback(); log.exception("repair: create audit_log failed")

        await m.reply_text("‚úÖ –ì–æ—Ç–æ–≤–æ. –°–æ–∑–¥–∞–Ω–æ: " + (", ".join(created) if created else "–Ω–∏—á–µ–≥–æ (–≤—Å—ë —É–∂–µ –±—ã–ª–æ)"))
    except Exception:
        log.exception("repair_schema failed (outer)")
        await m.reply_text("‚ö† –û—à–∏–±–∫–∞ repair_schema. –°–º–æ—Ç—Ä–∏ –ª–æ–≥–∏.")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ç–∞–±–ª–∏—Ü –≤ –ë–î
async def dbcheck(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        with SessionLocal() as db:
            rows = db.execute(sa_text("""
                select 'users' as t, to_regclass('public.users') is not null as ok
                union all select 'dialogs',          to_regclass('public.dialogs') is not null
                union all select 'messages',         to_regclass('public.messages') is not null
                union all select 'kb_documents',     to_regclass('public.kb_documents') is not null
                union all select 'kb_chunks',        to_regclass('public.kb_chunks') is not null
                union all select 'dialog_kb_links',  to_regclass('public.dialog_kb_links') is not null
                union all select 'pdf_passwords',    to_regclass('public.pdf_passwords') is not null
                union all select 'audit_log',        to_regclass('public.audit_log') is not null
            """)).all()
        lines = ["–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∞–±–ª–∏—Ü:"]
        for t, ok in rows:
            lines.append(f"{'‚úÖ' if ok else '‚ùå'} {t}")
        await (update.effective_message or update.message).reply_text("\n".join(lines))
    except Exception:
        log.exception("dbcheck failed")
        await (update.effective_message or update.message).reply_text("‚ö† –û—à–∏–±–∫–∞ dbcheck. –°–º–æ—Ç—Ä–∏ –ª–æ–≥–∏.")

# –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–≥–æ–Ω –º–∏–≥—Ä–∞—Ü–∏–π Alembic (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞)
async def migrate(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        if not _is_admin(update.effective_user.id):
            return await (update.effective_message or update.message).reply_text("–¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞.")
        await (update.effective_message or update.message).reply_text("üîß –ó–∞–ø—É—Å–∫–∞—é –º–∏–≥—Ä–∞—Ü–∏–∏...")
        # –ü—Ä–æ–≥—Ä–∞–º–º–Ω—ã–π –≤—ã–∑–æ–≤ Alembic
        import os
        from alembic.config import Config
        from alembic import command
        os.environ["DATABASE_URL"] = settings.database_url
        cfg = Config("alembic.ini")
        command.upgrade(cfg, "head")
        await (update.effective_message or update.message).reply_text("‚úÖ –ú–∏–≥—Ä–∞—Ü–∏–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã.")
    except Exception:
        log.exception("migrate failed")
        await (update.effective_message or update.message).reply_text("‚ö† –û—à–∏–±–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏. –°–º–æ—Ç—Ä–∏ –ª–æ–≥–∏.")

async def health(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        with SessionLocal() as db:
            db.execute(sa_text("SELECT 1"))
        await update.message.reply_text("‚úÖ OK: DB connection")
    except Exception:
        log.exception("health failed")
        await update.message.reply_text("‚ùå FAIL: DB connection")

async def stats(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        tg = update.effective_user.id
        with SessionLocal() as db:
            u = db.execute(sa_text(
                "SELECT id, is_admin, is_allowed, COALESCE(lang,'ru') "
                "FROM users WHERE tg_user_id=:tg ORDER BY id LIMIT 1"
            ), {"tg": tg}).first()
            if u:
                uid, is_admin, is_allowed, lang = u
            else:
                uid, is_admin, is_allowed, lang = (None, False, True if not getattr(settings, 'allowed_user_ids', '') else False, 'ru')
            role = "admin" if is_admin else ("allowed" if is_allowed or not getattr(settings, 'allowed_user_ids', '') else "guest")

            row = db.execute(sa_text("""
                SELECT d.id, d.title, d.model, d.style, d.created_at, d.last_message_at
                FROM dialogs d
                JOIN users u ON u.id = d.user_id
                WHERE u.tg_user_id = :tg AND d.is_deleted = FALSE
                ORDER BY COALESCE(d.created_at, to_timestamp(0)) DESC, d.id DESC
                LIMIT 1
            """), {"tg": tg}).first()

            if not row:
                return await m.reply_text(
                    f"whoami: tg={tg}, role={role}, lang={lang}\n\n"
                    "–ê–∫—Ç–∏–≤–Ω–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞ –Ω–µ—Ç. –°–æ–∑–¥–∞–π—Ç–µ /dialog_new."
                )

            did, title, model, style, created_dt, updated_dt = row
            if created_dt is None:
                db.execute(sa_text("UPDATE dialogs SET created_at=now() WHERE id=:d"), {"d": did})
                db.commit()
                created_dt = datetime.now()

            links = db.execute(sa_text("""
                SELECT kd.path
                FROM dialog_kb_links l
                JOIN kb_documents kd ON kd.id = l.document_id
                WHERE l.dialog_id = :d
                ORDER BY kd.path
            """), {"d": did}).fetchall()

            msg_count = _exec_scalar(db, "SELECT count(*) FROM messages WHERE dialog_id = :d", d=did) or 0
            total_dialogs = _exec_scalar(db, """
                SELECT count(*) FROM dialogs d
                JOIN users u ON u.id = d.user_id
                WHERE u.tg_user_id = :tg AND d.is_deleted = FALSE
            """, tg=tg) or 0

        created = created_dt.strftime("%Y-%m-%d %H:%M") if created_dt else "-"
        updated = updated_dt.strftime("%Y-%m-%d %H:%M") if updated_dt else "-"
        docs = [r[0] for r in links] if links else []

        await m.reply_text("\n".join([
            f"whoami: tg={tg}, role={role}, lang={lang}",
            "",
            f"–î–∏–∞–ª–æ–≥: {did} ‚Äî {title or ''}",
            f"–ú–æ–¥–µ–ª—å: {model or settings.openai_model} | –°—Ç–∏–ª—å: {style or '-'}",
            f"–°–æ–∑–¥–∞–Ω: {created} | –ò–∑–º–µ–Ω—ë–Ω: {updated}",
            f"–ü–æ–¥–∫–ª—é—á—ë–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã ({len(docs)}):",
            *([f"‚Ä¢ {p}" for p in docs] or ["‚Ä¢ ‚Äî"]),
            "",
            f"–í—Å–µ–≥–æ —Ç–≤–æ–∏—Ö –¥–∏–∞–ª–æ–≥–æ–≤: {total_dialogs} | –°–æ–æ–±—â–µ–Ω–∏–π –≤ —ç—Ç–æ–º –¥–∏–∞–ª–æ–≥–µ: {msg_count}",
        ]))
    except Exception:
        log.exception("stats failed")
        await m.reply_text("‚ö† –û—à–∏–±–∫–∞ /stats")

async def dialog_cb(update: Update, context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    await q.answer()
    try:
        data = q.data or ""
        if data.startswith("dlg:open:"):
            dlg_id = int(data.split(":")[-1])
            await q.edit_message_text(f"–û—Ç–∫—Ä—ã—Ç –¥–∏–∞–ª–æ–≥ #{dlg_id}")
            return

        if data == "dlg:nop" or data.startswith("dlg:page:"):
            # –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ—Ä–∏—Å—É–µ–º —Å–ø–∏—Å–æ–∫
            return await dialogs(update, context)

        if data.startswith("dlg:rename:"):
            dlg_id = int(data.split(":")[-1])
            context.user_data["rename_dialog_id"] = dlg_id
            await q.edit_message_text("–í–≤–µ–¥–∏—Ç–µ –Ω–æ–≤–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞:")
            return

        if data.startswith("dlg:export:"):
            dlg_id = int(data.split(":")[-1])
            with SessionLocal() as db:
                msgs = _exec_all(
                    db,
                    """
                    SELECT role, content, created_at
                    FROM messages
                    WHERE dialog_id=:d
                    ORDER BY created_at
                    """, d=dlg_id,
                )
            lines = ["# –≠–∫—Å–ø–æ—Ä—Ç –¥–∏–∞–ª–æ–≥–∞", ""]
            for role, content, _ in msgs:
                who = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if role == "user" else "–ë–æ—Ç"
                lines.append(f"**{who}:**\n{content}\n")
            data_bytes = "\n".join(lines).encode("utf-8")
            if HAS_BUFFERED:
                file = BufferedInputFile(data_bytes, filename=f"dialog_{dlg_id}.md")  # type: ignore
            else:
                file = InputFile(data_bytes, filename=f"dialog_{dlg_id}.md")  # type: ignore
            await q.message.reply_document(document=file, caption="–≠–∫—Å–ø–æ—Ä—Ç –≥–æ—Ç–æ–≤")
            return

        if data.startswith("dlg:delete:"):
            dlg_id = int(data.split(":")[-1])
            with SessionLocal() as db:
                db.execute(sa_text("UPDATE dialogs SET is_deleted=TRUE WHERE id=:d"), {"d": dlg_id})
                db.commit()
            await q.edit_message_text(f"–î–∏–∞–ª–æ–≥ #{dlg_id} —É–¥–∞–ª—ë–Ω")
            return
    except Exception:
        log.exception("dialog_cb failed")
        try:
            await q.message.reply_text("‚ö† –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ /dialogs. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
        except Exception:
            pass

async def text_router(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if "rename_dialog_id" in context.user_data:
        dlg_id = context.user_data.pop("rename_dialog_id")
        new_title = (update.message.text or "").strip()[:100]
        if not new_title:
            await update.message.reply_text("–ù–∞–∑–≤–∞–Ω–∏–µ –ø—É—Å—Ç–æ–µ. –û—Ç–º–µ–Ω–µ–Ω–æ.")
            return
        try:
            with SessionLocal() as db:
                db.execute(sa_text("UPDATE dialogs SET title=:t WHERE id=:d"), {"t": new_title, "d": dlg_id})
                db.commit()
            await update.message.reply_text("–ù–∞–∑–≤–∞–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ.")
        except Exception:
            log.exception("rename dialog title failed")
            await update.message.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ.")
        return
    await update.message.reply_text("–ü—Ä–∏–Ω—è—Ç–æ. (–¢–µ–∫—Å—Ç–æ–≤—ã–π —Ä–æ—É—Ç–µ—Ä –±—É–¥–µ—Ç –ø–æ–¥–∫–ª—é—á—ë–Ω –∫ RAG –ø–æ—Å–ª–µ —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ UI.)")

# ---------- KB ----------
PAGE_SIZE = 8

def _exec_page_count(total: int) -> int:
    return max(1, (total + PAGE_SIZE - 1) // PAGE_SIZE)

def _kb_keyboard(rows, page, pages, filter_name, admin: bool):
    nav = []
    if page > 1:
        nav.append(InlineKeyboardButton("¬´ –ù–∞–∑–∞–¥", callback_data=f"kb:list:{page-1}:{filter_name}"))
    nav.append(InlineKeyboardButton(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}/{pages}", callback_data="kb:nop"))
    if page < pages:
        nav.append(InlineKeyboardButton("–í–ø–µ—Ä—ë–¥ ¬ª", callback_data=f"kb:list:{page+1}:{filter_name}"))

    filter_row = [
        InlineKeyboardButton(("üîµ " if filter_name == "all" else "") + "–í—Å–µ", callback_data="kb:list:1:all"),
        InlineKeyboardButton(("üîµ " if filter_name == "connected" else "") + "–ü–æ–¥–∫–ª—é—á—ë–Ω–Ω—ã–µ", callback_data="kb:list:1:connected"),
        InlineKeyboardButton(("üîµ " if filter_name == "available" else "") + "–î–æ—Å—Ç—É–ø–Ω—ã–µ", callback_data="kb:list:1:available"),
    ]

    keyboard = []
    keyboard.extend(rows)
    if nav:
        keyboard.append(nav)
    keyboard.append(filter_row)
    if admin:
        keyboard.append([InlineKeyboardButton("üîÑ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è", callback_data="kb:sync")])
    keyboard.append([InlineKeyboardButton("üìÅ –°—Ç–∞—Ç—É—Å –ë–ó", callback_data="kb:status")])
    return InlineKeyboardMarkup(keyboard)

def _kb_fetch(db, user_id: int, page: int, filter_name: str):
    dlg_id = _exec_scalar(
        db,
        """
        SELECT d.id
        FROM dialogs d
        WHERE d.user_id=:u AND d.is_deleted=FALSE
        ORDER BY d.created_at DESC
        LIMIT 1
        """, u=user_id,
    )
    if not dlg_id:
        dlg_id = _ensure_dialog(db, user_id)

    conn_ids = {row[0] for row in _exec_all(db,
        "SELECT document_id FROM dialog_kb_links WHERE dialog_id=:d", d=dlg_id)}

    where = "WHERE is_active"
    params = {}
    if filter_name == "connected":
        if conn_ids:
            where += " AND id = ANY(:ids)"
            params["ids"] = list(conn_ids)
        else:
            return dlg_id, [], 1, 1, conn_ids
    elif filter_name == "available" and conn_ids:
        where += " AND NOT (id = ANY(:ids))"
        params["ids"] = list(conn_ids)

    total = _exec_scalar(db, f"SELECT COUNT(*) FROM kb_documents {where}", **params) or 0
    pages = _exec_page_count(total)
    page = max(1, min(page, pages))

    rows = _exec_all(
        db,
        f"""
        SELECT id, path
        FROM kb_documents
        {where}
        ORDER BY path
        OFFSET :off LIMIT :lim
        """,
        off=(page - 1) * PAGE_SIZE, lim=PAGE_SIZE, **params
    )
    return dlg_id, rows, page, pages, conn_ids

async def kb(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        tg_id = update.effective_user.id
        with SessionLocal() as db:
            uid = _ensure_user(db, tg_id)
            _ensure_dialog(db, uid)
            dlg_id, rows, page, pages, conn_ids = _kb_fetch(db, uid, 1, "all")
        buttons = []
        for d_id, path in rows:
            checked = "‚òë" if d_id in conn_ids else "‚òê"
            fname = path.split("/")[-1]
            buttons.append([InlineKeyboardButton(f"{checked} {fname}", callback_data=f"kb:toggle:{d_id}:{page}:all")])
        kb_markup = _kb_keyboard(buttons, page, pages, "all", admin=_is_admin(tg_id))
        await update.message.reply_text("–ú–µ–Ω—é –ë–ó: –≤—ã–±–µ—Ä–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –∞–∫—Ç–∏–≤–Ω–æ–º—É –¥–∏–∞–ª–æ–≥—É.", reply_markup=kb_markup)
    except Exception:
        log.exception("kb failed")
        await update.message.reply_text("‚ö† –ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")

async def kb_cb(update: Update, context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    await q.answer()
    try:
        data = q.data or ""
        tg_id = update.effective_user.id
        with SessionLocal() as db:
            uid = _ensure_user(db, tg_id)

            if data.startswith("kb:list:"):
                _, _, page, flt = data.split(":", 3)
                dlg_id, rows, page, pages, conn_ids = _kb_fetch(db, uid, int(page), flt)
                buttons = []
                for d_id, path in rows:
                    checked = "‚òë" if d_id in conn_ids else "‚òê"
                    fname = path.split("/")[-1]
                    buttons.append([InlineKeyboardButton(f"{checked} {fname}", callback_data=f"kb:toggle:{d_id}:{page}:{flt}")])
                kb_markup = _kb_keyboard(buttons, page, pages, flt, admin=_is_admin(tg_id))
                await q.edit_message_text("–ú–µ–Ω—é –ë–ó: –≤—ã–±–µ—Ä–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –∞–∫—Ç–∏–≤–Ω–æ–º—É –¥–∏–∞–ª–æ–≥—É.", reply_markup=kb_markup)
                return

            if data.startswith("kb:toggle:"):
                _, _, doc_id, page, flt = data.split(":", 4)
                doc_id = int(doc_id)
                dlg_id = _exec_scalar(db,
                    """
                    SELECT id FROM dialogs WHERE user_id=:u AND is_deleted=FALSE
                    ORDER BY created_at DESC LIMIT 1
                    """, u=uid)
                if not dlg_id:
                    dlg_id = _ensure_dialog(db, uid)

                exist = _exec_scalar(db,
                    "SELECT id FROM dialog_kb_links WHERE dialog_id=:d AND document_id=:doc",
                    d=dlg_id, doc=doc_id)
                if exist:
                    db.execute(sa_text("DELETE FROM dialog_kb_links WHERE id=:i"), {"i": exist})
                else:
                    db.execute(sa_text(
                        "INSERT INTO dialog_kb_links (dialog_id, document_id, created_at) VALUES (:d, :doc, now())"
                    ), {"d": dlg_id, "doc": doc_id})
                db.commit()

                dlg_id, rows, page, pages, conn_ids = _kb_fetch(db, uid, int(page), flt)
                buttons = []
                for d_id, path in rows:
                    checked = "‚òë" if d_id in conn_ids else "‚òê"
                    fname = path.split("/")[-1]
                    buttons.append([InlineKeyboardButton(f"{checked} {fname}", callback_data=f"kb:toggle:{d_id}:{page}:{flt}")])
                kb_markup = _kb_keyboard(buttons, page, pages, flt, admin=_is_admin(tg_id))
                await q.edit_message_text("–ú–µ–Ω—é –ë–ó: –≤—ã–±–µ—Ä–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –∞–∫—Ç–∏–≤–Ω–æ–º—É –¥–∏–∞–ª–æ–≥—É.", reply_markup=kb_markup)
                return

            if data == "kb:status":
                docs = _exec_scalar(db, "SELECT COUNT(*) FROM kb_documents WHERE is_active") or 0
                chunks = _exec_scalar(db, "SELECT COUNT(*) FROM kb_chunks") or 0
                await q.edit_message_text(f"–î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {docs}\n–ß–∞–Ω–∫–æ–≤: {chunks}")
                return

            if data in ("kb:sync", "kb:sync:run"):
                return await kb_sync(update, context)

            if data == "kb:nop":
                return
    except Exception:
        log.exception("kb_cb failed")
        try:
            await q.message.reply_text("‚ö† –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ /kb. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
        except Exception:
            pass

# ---------- service ----------
async def reset(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        with SessionLocal() as db:
            tg_id = update.effective_user.id
            uid = _ensure_user(db, tg_id)
            did = _ensure_dialog(db, uid)
            db.execute(sa_text("DELETE FROM messages WHERE dialog_id=:d"),   {"d": did})
            db.execute(sa_text("DELETE FROM dialog_kb_links WHERE dialog_id=:d"), {"d": did})
            db.execute(sa_text("DELETE FROM pdf_passwords WHERE dialog_id=:d"),   {"d": did})
            db.execute(sa_text("UPDATE dialogs SET last_message_at=NULL WHERE id=:d"), {"d": did})
            db.commit()
        context.user_data.clear()
        await m.reply_text("‚ôªÔ∏è –î–∏–∞–ª–æ–≥ –æ—á–∏—â–µ–Ω: –∏—Å—Ç–æ—Ä–∏—è, –ø—Ä–∏–≤—è–∑–∫–∏ –ë–ó –∏ –ø–∞—Ä–æ–ª–∏ PDF —Å–±—Ä–æ—à–µ–Ω—ã.")
    except Exception:
        log.exception("reset failed")
        await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å —Å–±—Ä–æ—Å–∏—Ç—å –¥–∏–∞–ª–æ–≥.")

async def error_handler(update: object, context: ContextTypes.DEFAULT_TYPE):
    log.exception("Unhandled error", exc_info=context.error)
    try:
        if hasattr(update, "message") and update.message:
            await update.message.reply_text("‚ö† –ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
        elif hasattr(update, "callback_query") and update.callback_query:
            await update.callback_query.message.reply_text("‚ö† –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
    except Exception:
        pass

# ---------- build ----------

# === /model: inline selector of available OpenAI models ===
def _model_score(mid: str) -> int:
    m = mid.lower()
    if any(x in m for x in ["dall-e", "whisper", "embedding", "text-embedding", "tts", "audio"]):
        return -100
    score = 0
    if "latest" in m: score += 10
    if "preview" in m: score += 6
    if any(x in m for x in ["o4", "4o"]): score += 100
    if "4.1" in m: score += 80
    if "4" in m: score += 60
    if "mini" in m: score += 8
    if "turbo" in m: score += 4
    if "3.5" in m: score += 1
    return score

# —Ñ–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —á–∞—Ç–æ–≤—ã–µ —Å–µ–º–µ–π—Å—Ç–≤–∞ –∏ –∏—Å–∫–ª—é—á–∞–µ–º –≤—Å—ë –ª–∏—à–Ω–µ–µ
def _keep_chat_model(mid: str) -> bool:
    m = mid.lower()
    if any(x in m for x in ["embedding", "text-embedding", "dall-e", "whisper", "tts", "audio", "moderation", "computer-use"]):
        return False
    # —Å–∫—Ä—ã–≤–∞–µ–º —è–≤–Ω—ã–π –º—É—Å–æ—Ä/–Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ
    if m.startswith("babbage") or m.startswith("davinci") or m.startswith("curie") or m.startswith("ada"):
        return False
    if m.startswith("gpt-5"):  # –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º
        return False
    # –æ—Å—Ç–∞–≤–ª—è–µ–º gpt-4/4o/4.1/o4, 3.5, chatgpt-4o-latest
    return any(x in m for x in ["gpt-4", "gpt-3.5", "chatgpt-4o", "o4"])

def _sort_models(models):
    # —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ created (desc), –µ—Å–ª–∏ –µ—Å—Ç—å; –∏–Ω–∞—á–µ –ø–æ —ç–≤—Ä–∏—Å—Ç–∏–∫–µ
    def score(item):
        mid = getattr(item, "id", "")
        created = getattr(item, "created", 0) or 0
        return (created, len(mid) * -1)
    return sorted(models, key=score, reverse=True)

async def model_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        client = OpenAI(api_key=settings.openai_api_key)
        res = client.models.list()
        models = [it for it in getattr(res, "data", []) if _keep_chat_model(getattr(it, "id", ""))]
        models = _sort_models(models)
        ids = [it.id for it in models]

        # —Å–æ—Ö—Ä–∞–Ω–∏–º –¥–ª—è "–ü–æ–∫–∞–∑–∞—Ç—å –µ—â—ë"
        context.user_data["all_models_sorted"] = ids

        top10 = ids[:10]
        buttons = [[InlineKeyboardButton(mid, callback_data=f"model:set:{mid}")] for mid in top10]
        if len(ids) > 10:
            buttons.append([InlineKeyboardButton("–ü–æ–∫–∞–∑–∞—Ç—å –µ—â—ë", callback_data="model:more:2")])
        buttons.append([InlineKeyboardButton("–ó–∞–∫—Ä—ã—Ç—å", callback_data="model:close")])
        await m.reply_text("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞:", reply_markup=InlineKeyboardMarkup(buttons))
    except Exception:
        log.exception("model_menu failed")
        await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π")

def _page_models(ids: list[str], page: int, page_size: int = 10):
    pages = max(1, (len(ids) + page_size - 1) // page_size)
    page = max(1, min(page, pages))
    beg = (page - 1) * page_size
    chunk = ids[beg:beg + page_size]
    rows = [[InlineKeyboardButton(mid, callback_data=f"model:set:{mid}")] for mid in chunk]
    nav = []
    if page > 1:
        nav.append(InlineKeyboardButton("¬´ –ù–∞–∑–∞–¥", callback_data=f"model:more:{page-1}"))
    nav.append(InlineKeyboardButton(f"{page}/{pages}", callback_data="model:nop"))
    if page < pages:
        nav.append(InlineKeyboardButton("–í–ø–µ—Ä—ë–¥ ¬ª", callback_data=f"model:more:{page+1}"))
    rows.append(nav)
    rows.append([InlineKeyboardButton("–ó–∞–∫—Ä—ã—Ç—å", callback_data="model:close")])
    return InlineKeyboardMarkup(rows)

async def model_cb(update: Update, context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    await q.answer()
    try:
        data = q.data or ""
        if data in ("model:close", "model:nop"):
            try: await q.delete_message()
            except Exception: pass
            return

        if data.startswith("model:more:"):
            page = int(data.split(":")[-1])
            ids = context.user_data.get("all_models_sorted") or []
            return await q.edit_message_reply_markup(reply_markup=_page_models(ids, page))

        if data.startswith("model:set:"):
            mid = data.split(":", 2)[-1]
            # –ø—Ä–æ–≤–µ—Ä–∏–º –±—ã—Å—Ç—Ä–æ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
            try:
                client = OpenAI(api_key=settings.openai_api_key)
                client.chat.completions.create(model=mid, messages=[{"role": "user", "content": "ping"}], max_tokens=1)
            except Exception:
                return await q.edit_message_text(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å ¬´{mid}¬ª. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é.")

            tg = update.effective_user.id
            with SessionLocal() as db:
                did = _exec_scalar(db, """
                    SELECT d.id
                    FROM dialogs d
                    JOIN users u ON u.id = d.user_id
                    WHERE u.tg_user_id = :tg AND d.is_deleted = FALSE
                    ORDER BY d.created_at DESC
                    LIMIT 1
                """, tg=tg)
                if not did:
                    return await q.edit_message_text("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞. –ù–∞–∂–º–∏ /dialog_new.")
                db.execute(sa_text("UPDATE dialogs SET model=:m WHERE id=:d"), {"m": mid, "d": did})
                db.commit()
            return await q.edit_message_text(f"‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å: {mid}")
    except Exception:
        log.exception("model_cb failed")
        try: await q.message.reply_text("‚ö† –û—à–∏–±–∫–∞ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏")
        except Exception: pass


def _send_model_page(all_ids, page: int, qmsg):
    PAGE = 10
    pages = max(1, (len(all_ids) + PAGE - 1) // PAGE)
    page = max(1, min(page, pages))
    beg = (page-1) * PAGE
    chunk = all_ids[beg:beg+PAGE]
    rows = [[InlineKeyboardButton(mid, callback_data=f"model:set:{mid}")] for mid in chunk]
    nav = []
    if page > 1:
        nav.append(InlineKeyboardButton("¬´ –ù–∞–∑–∞–¥", callback_data=f"model:more:{page-1}"))
    nav.append(InlineKeyboardButton(f"{page}/{pages}", callback_data="model:nop"))
    if page < pages:
        nav.append(InlineKeyboardButton("–í–ø–µ—Ä—ë–¥ ¬ª", callback_data=f"model:more:{page+1}"))
    rows.append(nav)
    rows.append([InlineKeyboardButton("–ó–∞–∫—Ä—ã—Ç—å", callback_data="model:close")])
    return InlineKeyboardMarkup(rows)

async def mode_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    kb = InlineKeyboardMarkup([
        [InlineKeyboardButton("–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª", callback_data="mode:set:pro")],
        [InlineKeyboardButton("–≠–∫—Å–ø–µ—Ä—Ç", callback_data="mode:set:expert")],
        [InlineKeyboardButton("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å", callback_data="mode:set:user")],
        [InlineKeyboardButton("–°–ï–û", callback_data="mode:set:ceo")],
        [InlineKeyboardButton("–ó–∞–∫—Ä—ã—Ç—å", callback_data="mode:close")],
    ])
    await m.reply_text("–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–∏–ª—å –æ—Ç–≤–µ—Ç–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞:", reply_markup=kb)

async def mode_cb(update: Update, context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    if not q: return
    await q.answer()
    data = q.data or ""
    if data == "mode:close":
        try:
            await q.message.edit_reply_markup(reply_markup=None)
        except Exception:
            pass
        return
    if data.startswith("mode:set:"):
        style = data.split(":", 2)[2]
        if style not in ("ceo","expert","pro","user"):
            return await q.message.reply_text("–ù–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–π —Å—Ç–∏–ª—å.")
        with SessionLocal() as db:
            uid = _ensure_user(db, q.from_user.id)
            did = _ensure_dialog(db, uid)
            db.execute(sa_text("UPDATE dialogs SET style=:s WHERE id=:d"), {"s": style, "d": did})
            db.commit()
        sample = _STYLE_EXAMPLES.get(style, "")
        await q.message.reply_text(f"‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Å—Ç–∏–ª—å: {style}\n–ü—Ä–∏–º–µ—Ä: {sample}")
        try:
            await q.message.edit_reply_markup(reply_markup=None)
        except Exception:
            pass

async def cmd_img(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    q = (m.text or "").split(maxsplit=1)
    if len(q) < 2:
        return await m.reply_text("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /img <–æ–ø–∏—Å–∞–Ω–∏–µ>")
    try:
        from bot.openai_helper import generate_image_bytes
        content, final_prompt = await generate_image_bytes(q[1])
        await m.reply_photo(photo=content, caption=f"üñºÔ∏è –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ DALL¬∑E 3\nPrompt ‚Üí {final_prompt}")
    except Exception:
        log.exception("img failed")
        await m.reply_text("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.")

DIALOGS_PAGE_SIZE = 6

DIALOGS_PAGE_SIZE = 6

async def dialogs(update: Update, context: ContextTypes.DEFAULT_TYPE):
    m = update.effective_message or update.message
    try:
        tg = update.effective_user.id
        with SessionLocal() as db:
            ds = _exec_all(db, """
                SELECT d.id, COALESCE(d.title,'')
                FROM dialogs d
                JOIN users u ON u.id = d.user_id
                WHERE u.tg_user_id = :tg AND d.is_deleted = FALSE
                ORDER BY d.created_at DESC
            """, tg=tg)

        if not ds:
            kb = [[InlineKeyboardButton("‚ûï –ù–æ–≤—ã–π –¥–∏–∞–ª–æ–≥", callback_data="dlg:new")]]
            return await m.reply_text("–î–∏–∞–ª–æ–≥–æ–≤ –Ω–µ—Ç.", reply_markup=InlineKeyboardMarkup(kb))

        page = 1
        pages = max(1, (len(ds) + DIALOGS_PAGE_SIZE - 1) // DIALOGS_PAGE_SIZE)
        beg = (page - 1) * DIALOGS_PAGE_SIZE
        chunk = ds[beg:beg + DIALOGS_PAGE_SIZE]

        rows = []
        for did, title in chunk:
            name = title or f"–î–∏–∞–ª–æ–≥ #{did}"
            rows.append([
                InlineKeyboardButton(name[:30] + ("‚Ä¶" if len(name) > 30 else ""), callback_data=f"dlg:open:{did}"),
                InlineKeyboardButton("‚úèÔ∏è", callback_data=f"dlg:rename:{did}"),
                InlineKeyboardButton("üì§", callback_data=f"dlg:export:{did}"),
                InlineKeyboardButton("üóëÔ∏è", callback_data=f"dlg:delete:{did}"),
            ])

        nav = []
        if pages > 1:
            nav.append(InlineKeyboardButton("–í–ø–µ—Ä—ë–¥ ¬ª", callback_data=f"dlg:page:{page+1}"))
        rows.append(nav or [InlineKeyboardButton(" ", callback_data="dlg:nop")])
        rows.append([InlineKeyboardButton("‚ûï –ù–æ–≤—ã–π –¥–∏–∞–ª–æ–≥", callback_data="dlg:new")])

        await m.reply_text("–ú–æ–∏ –¥–∏–∞–ª–æ–≥–∏:", reply_markup=InlineKeyboardMarkup(rows))
    except Exception:
        log.exception("dialogs failed")
        await m.reply_text("‚ö† –û—à–∏–±–∫–∞ /dialogs")

async def dialog_cb(update: Update, context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    await q.answer()
    try:
        data = q.data or ""
        tg = update.effective_user.id

        if data == "dlg:nop":
            return

        if data == "dlg:new":
            with SessionLocal() as db:
                did = _create_new_dialog_for_tg(db, tg)
            return await q.edit_message_text(f"‚úÖ –°–æ–∑–¥–∞–Ω –¥–∏–∞–ª–æ–≥ #{did}")

        if data.startswith("dlg:page:"):
            page = int(data.split(":")[-1])
            with SessionLocal() as db:
                ds = _exec_all(db, """
                    SELECT d.id, COALESCE(d.title,'')
                    FROM dialogs d
                    JOIN users u ON u.id = d.user_id
                    WHERE u.tg_user_id = :tg AND d.is_deleted = FALSE
                    ORDER BY d.created_at DESC
                """, tg=tg)
            total = len(ds)
            pages = max(1, (total + DIALOGS_PAGE_SIZE - 1) // DIALOGS_PAGE_SIZE)
            page = max(1, min(page, pages))
            beg = (page - 1) * DIALOGS_PAGE_SIZE
            chunk = ds[beg:beg + DIALOGS_PAGE_SIZE]

            rows = []
            for did, title in chunk:
                name = title or f"–î–∏–∞–ª–æ–≥ #{did}"
                rows.append([
                    InlineKeyboardButton(name[:30] + ("‚Ä¶" if len(name) > 30 else ""), callback_data=f"dlg:open:{did}"),
                    InlineKeyboardButton("‚úèÔ∏è", callback_data=f"dlg:rename:{did}"),
                    InlineKeyboardButton("üì§", callback_data=f"dlg:export:{did}"),
                    InlineKeyboardButton("üóëÔ∏è", callback_data=f"dlg:delete:{did}"),
                ])
            nav = []
            if page > 1:
                nav.append(InlineKeyboardButton("¬´ –ù–∞–∑–∞–¥", callback_data=f"dlg:page:{page-1}"))
            nav.append(InlineKeyboardButton(f"{page}/{pages}", callback_data="dlg:nop"))
            if page < pages:
                nav.append(InlineKeyboardButton("–í–ø–µ—Ä—ë–¥ ¬ª", callback_data=f"dlg:page:{page+1}"))
            rows.append(nav)
            rows.append([InlineKeyboardButton("‚ûï –ù–æ–≤—ã–π –¥–∏–∞–ª–æ–≥", callback_data="dlg:new")])

            return await q.edit_message_text("–ú–æ–∏ –¥–∏–∞–ª–æ–≥–∏:", reply_markup=InlineKeyboardMarkup(rows))

        if data.startswith("dlg:open:"):
            dlg_id = int(data.split(":")[-1])
            # –∞–∫—Ç–∏–≤–∏—Ä—É–µ–º –¥–∏–∞–ª–æ–≥, –ù–ï –º–µ–Ω—è—è created_at ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º last_message_at
            with SessionLocal() as db:
                db.execute(sa_text("UPDATE dialogs SET last_message_at = now() WHERE id = :d"), {"d": dlg_id})
                db.commit()
            return await q.edit_message_text(f"–û—Ç–∫—Ä—ã—Ç –¥–∏–∞–ª–æ–≥ #{dlg_id}")

        if data.startswith("dlg:rename:"):
            dlg_id = int(data.split(":")[-1])
            context.user_data["rename_dialog_id"] = dlg_id
            return await q.edit_message_text("–í–≤–µ–¥–∏—Ç–µ –Ω–æ–≤–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞:")

        if data.startswith("dlg:export:"):
            dlg_id = int(data.split(":")[-1])
            with SessionLocal() as db:
                msgs = _exec_all(db, """
                    SELECT role, content, created_at
                    FROM messages
                    WHERE dialog_id = :d
                    ORDER BY created_at
                """, d=dlg_id)
            lines = ["# –≠–∫—Å–ø–æ—Ä—Ç –¥–∏–∞–ª–æ–≥–∞", ""]
            for role, content, _ in msgs:
                who = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if role == "user" else "–ë–æ—Ç"
                lines.append(f"**{who}:**\n{content}\n")
            data_bytes = "\n".join(lines).encode("utf-8")
            file = (BufferedInputFile if HAS_BUFFERED else InputFile)(data_bytes, filename=f"dialog_{dlg_id}.md")  # type: ignore
            return await q.message.reply_document(document=file, caption="–≠–∫—Å–ø–æ—Ä—Ç –≥–æ—Ç–æ–≤")

        if data.startswith("dlg:delete:"):
            dlg_id = int(data.split(":")[-1])
            with SessionLocal() as db:
                db.execute(sa_text("UPDATE dialogs SET is_deleted = TRUE WHERE id = :d"), {"d": dlg_id})
                db.commit()
            return await q.edit_message_text(f"–î–∏–∞–ª–æ–≥ #{dlg_id} —É–¥–∞–ª—ë–Ω")

    except Exception:
        log.exception("dialog_cb failed")
        try:
            await q.message.reply_text("‚ö† –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ /dialogs. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
        except Exception:
            pass
        
def build_app() -> Application:
    apply_migrations_if_needed()
    app = ApplicationBuilder().token(settings.telegram_bot_token).build()
    app.add_error_handler(error_handler)
    app.add_handler(CallbackQueryHandler(model_cb, pattern=r"^model:"))
    app.add_handler(CallbackQueryHandler(mode_cb, pattern=r"^mode:"))
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("whoami", whoami))
    app.add_handler(CommandHandler("help", help_cmd))
    app.add_handler(CommandHandler("grant", grant))
    app.add_handler(CommandHandler("health", health))
    app.add_handler(CommandHandler("revoke", revoke))
    app.add_handler(CommandHandler("stats", stats))
    app.add_handler(CommandHandler("model", model_menu))
    app.add_handler(CommandHandler("reset", reset))
    app.add_handler(CommandHandler("mode", mode_menu))
    app.add_handler(CommandHandler("dialogs", dialogs))
    app.add_handler(CommandHandler("img", cmd_img))
    app.add_handler(CallbackQueryHandler(dialog_cb, pattern=r"^dlg:"))
    app.add_handler(CommandHandler("repair_schema", repair_schema))
    app.add_handler(CommandHandler("dbcheck", dbcheck))
    app.add_handler(CommandHandler("migrate", migrate))
    app.add_handler(CommandHandler("kb", kb))
    app.add_handler(CallbackQueryHandler(kb_cb, pattern=r"^kb:"))
    app.add_handler(CommandHandler("dialog_new", dialog_new))
    app.add_handler(CommandHandler("pgvector_check", pgvector_check))
    app.add_handler(CommandHandler("kb_chunks_create", kb_chunks_create))
    app.add_handler(CommandHandler("kb_chunks_fix", kb_chunks_fix))
    app.add_handler(CommandHandler("kb_chunks_force", kb_chunks_force))
    app.add_handler(CommandHandler("kb_sync", kb_sync))
    app.add_handler(CommandHandler("kb_sync_pdf", kb_sync_pdf))
    app.add_handler(CommandHandler("rag_diag", rag_diag))
    app.add_handler(CommandHandler("rag_selftest", rag_selftest))
    app.add_handler(CommandHandler("kb_pdf_diag", kb_pdf_diag))
    app.add_handler(CommandHandler("web", cmd_web))

    app.add_handler(MessageHandler(filters.VOICE, on_voice))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_text))

    return app
